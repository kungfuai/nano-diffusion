<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Compare VLMs – Nano Diffusion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Nano Diffusion</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/kungfuai/nano-diffusion.git" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Compare VLMs</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Generating a 2D Point Cloud</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Diffusion</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_Diffusion 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training a Diffusion Model on 2D Points</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_a_refactor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A refactoring exercise</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_b_Diffusion_2D_hyperparams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experiment with hyperparameters</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Flow Matching</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_2_Flow Matching 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training a Flow Matching Model for 2D Point Generation</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Generating Animal Face Images</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_1_nano_diffusion_afhq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training a Diffusion Model for Animal Face Images</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_1_fid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quality evaluation of an image generation model</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#install-dependencies" id="toc-install-dependencies" class="nav-link active" data-scroll-target="#install-dependencies">Install Dependencies</a></li>
  <li><a href="#load-images" id="toc-load-images" class="nav-link" data-scroll-target="#load-images">Load Images</a></li>
  <li><a href="#qwen-vl" id="toc-qwen-vl" class="nav-link" data-scroll-target="#qwen-vl">QWEN-VL</a></li>
  <li><a href="#cogvlm" id="toc-cogvlm" class="nav-link" data-scroll-target="#cogvlm">CogVLM</a></li>
  <li><a href="#try-blip-2" id="toc-try-blip-2" class="nav-link" data-scroll-target="#try-blip-2">Try Blip-2</a></li>
  <li><a href="#try-minicpm-v-2" id="toc-try-minicpm-v-2" class="nav-link" data-scroll-target="#try-minicpm-v-2">Try MiniCPM-V-2</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Compare VLMs</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The <a href="https://huggingface.co/spaces/opencompass/open_vlm_leaderboard">VLM dashboard</a> has a list of VLMs and their performance scores.</p>
<p>We want to pick a small-ish (under 8B) model that is sufficient to generate captions for animal face images in the AFHQ dataset.</p>
<section id="install-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="install-dependencies">Install Dependencies</h2>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext autoreload</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>autoreload <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install peft<span class="op">==</span><span class="fl">0.13.2</span> flash_attn<span class="op">==</span><span class="fl">2.7</span>.<span class="op">*</span> qwen_vl_utils<span class="op">==</span><span class="fl">0.0.8</span> transformers<span class="op">==</span><span class="fl">4.47</span>.<span class="op">*</span> autoawq<span class="op">==</span><span class="fl">0.2</span>.<span class="op">*</span> jinja2<span class="op">==</span><span class="fl">3.1.4</span> xformers<span class="op">==</span><span class="fl">0.0.28</span> bitsandbytes<span class="op">==</span><span class="fl">0.45.0</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Defaulting to user installation because normal site-packages is not writeable
WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
Requirement already satisfied: peft==0.13.2 in /home/ubuntu/.local/lib/python3.11/site-packages (0.13.2)
Requirement already satisfied: flash_attn==2.7.* in /home/ubuntu/.local/lib/python3.11/site-packages (2.7.0.post2)
Requirement already satisfied: qwen_vl_utils==0.0.8 in /home/ubuntu/.local/lib/python3.11/site-packages (0.0.8)
Requirement already satisfied: transformers==4.47.* in /home/ubuntu/.local/lib/python3.11/site-packages (4.47.0)
Requirement already satisfied: autoawq==0.2.* in /home/ubuntu/.local/lib/python3.11/site-packages (0.2.7.post2)
Requirement already satisfied: jinja2==3.1.4 in /home/ubuntu/.local/lib/python3.11/site-packages (3.1.4)
Collecting xformers==0.0.28
  Downloading xformers-0.0.28-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)
Requirement already satisfied: bitsandbytes==0.45.0 in /home/ubuntu/.local/lib/python3.11/site-packages (0.45.0)
Requirement already satisfied: numpy&gt;=1.17 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (1.26.4)
Requirement already satisfied: packaging&gt;=20.0 in /opt/miniconda/lib/python3.11/site-packages (from peft==0.13.2) (23.1)
Requirement already satisfied: psutil in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (5.9.8)
Requirement already satisfied: pyyaml in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (6.0.1)
Requirement already satisfied: torch&gt;=1.13.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (2.5.1)
Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (4.66.5)
Requirement already satisfied: accelerate&gt;=0.21.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (0.33.0)
Requirement already satisfied: safetensors in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (0.4.2)
Requirement already satisfied: huggingface-hub&gt;=0.17.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (0.24.5)
Requirement already satisfied: einops in /home/ubuntu/.local/lib/python3.11/site-packages (from flash_attn==2.7.*) (0.7.0)
Requirement already satisfied: av in /home/ubuntu/.local/lib/python3.11/site-packages (from qwen_vl_utils==0.0.8) (14.0.0)
Requirement already satisfied: pillow in /home/ubuntu/.local/lib/python3.11/site-packages (from qwen_vl_utils==0.0.8) (10.2.0)
Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.11/site-packages (from qwen_vl_utils==0.0.8) (2.32.3)
Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.11/site-packages (from transformers==4.47.*) (3.13.3)
Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.11/site-packages (from transformers==4.47.*) (2023.12.25)
Requirement already satisfied: tokenizers&lt;0.22,&gt;=0.21 in /home/ubuntu/.local/lib/python3.11/site-packages (from transformers==4.47.*) (0.21.0)
Requirement already satisfied: triton in /home/ubuntu/.local/lib/python3.11/site-packages (from autoawq==0.2.*) (3.1.0)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from autoawq==0.2.*) (4.10.0)
Requirement already satisfied: datasets&gt;=2.20 in /home/ubuntu/.local/lib/python3.11/site-packages (from autoawq==0.2.*) (2.21.0)
Requirement already satisfied: zstandard in /opt/miniconda/lib/python3.11/site-packages (from autoawq==0.2.*) (0.19.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from jinja2==3.1.4) (2.1.5)
Collecting torch&gt;=1.13.0 (from peft==0.13.2)
  Using cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)
Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.11/site-packages (from torch&gt;=1.13.0-&gt;peft==0.13.2) (1.13.1)
Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.11/site-packages (from torch&gt;=1.13.0-&gt;peft==0.13.2) (3.2.1)
Requirement already satisfied: fsspec in /home/ubuntu/.local/lib/python3.11/site-packages (from torch&gt;=1.13.0-&gt;peft==0.13.2) (2024.3.1)
Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.11/site-packages (from torch&gt;=1.13.0-&gt;peft==0.13.2) (9.1.0.70)
Collecting nvidia-cublas-cu12==12.1.3.1 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.0.2.54 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.2.106 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-nccl-cu12==2.20.5 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvtx-cu12==12.1.105 (from torch&gt;=1.13.0-&gt;peft==0.13.2)
  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)
Collecting triton (from autoawq==0.2.*)
  Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch&gt;=1.13.0-&gt;peft==0.13.2) (12.4.127)
Requirement already satisfied: pyarrow&gt;=15.0.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets&gt;=2.20-&gt;autoawq==0.2.*) (17.0.0)
Requirement already satisfied: dill&lt;0.3.9,&gt;=0.3.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets&gt;=2.20-&gt;autoawq==0.2.*) (0.3.8)
Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets&gt;=2.20-&gt;autoawq==0.2.*) (2.2.2)
Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets&gt;=2.20-&gt;autoawq==0.2.*) (3.5.0)
Requirement already satisfied: multiprocess in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets&gt;=2.20-&gt;autoawq==0.2.*) (0.70.16)
Requirement already satisfied: aiohttp in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets&gt;=2.20-&gt;autoawq==0.2.*) (3.10.5)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/miniconda/lib/python3.11/site-packages (from requests-&gt;qwen_vl_utils==0.0.8) (2.0.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/miniconda/lib/python3.11/site-packages (from requests-&gt;qwen_vl_utils==0.0.8) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/miniconda/lib/python3.11/site-packages (from requests-&gt;qwen_vl_utils==0.0.8) (1.26.18)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/miniconda/lib/python3.11/site-packages (from requests-&gt;qwen_vl_utils==0.0.8) (2023.7.22)
Requirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (2.4.0)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (1.3.1)
Requirement already satisfied: attrs&gt;=17.3.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (23.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (1.4.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (6.0.5)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (1.9.4)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /home/ubuntu/.local/lib/python3.11/site-packages (from pandas-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /home/ubuntu/.local/lib/python3.11/site-packages (from pandas-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /home/ubuntu/.local/lib/python3.11/site-packages (from pandas-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (2024.1)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from sympy-&gt;torch&gt;=1.13.0-&gt;peft==0.13.2) (1.3.0)
Requirement already satisfied: six&gt;=1.5 in /home/ubuntu/.local/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets&gt;=2.20-&gt;autoawq==0.2.*) (1.16.0)
Downloading xformers-0.0.28-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.7/16.7 MB 14.8 MB/s eta 0:00:00a 0:00:01
Using cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)
Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)
Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)
Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)
Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)
Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)
Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)
Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)
Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)
Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)
Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)
WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, xformers
  Attempting uninstall: triton
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: triton 3.1.0
    Uninstalling triton-3.1.0:
      Successfully uninstalled triton-3.1.0
  Attempting uninstall: nvidia-nvtx-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-nvtx-cu12 12.4.127
    Uninstalling nvidia-nvtx-cu12-12.4.127:
      Successfully uninstalled nvidia-nvtx-cu12-12.4.127
  Attempting uninstall: nvidia-nccl-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-nccl-cu12 2.21.5
    Uninstalling nvidia-nccl-cu12-2.21.5:
      Successfully uninstalled nvidia-nccl-cu12-2.21.5
  Attempting uninstall: nvidia-cusparse-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cusparse-cu12 12.3.1.170
    Uninstalling nvidia-cusparse-cu12-12.3.1.170:
      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170
  Attempting uninstall: nvidia-curand-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-curand-cu12 10.3.5.147
    Uninstalling nvidia-curand-cu12-10.3.5.147:
      Successfully uninstalled nvidia-curand-cu12-10.3.5.147
  Attempting uninstall: nvidia-cufft-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cufft-cu12 11.2.1.3
    Uninstalling nvidia-cufft-cu12-11.2.1.3:
      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3
  Attempting uninstall: nvidia-cuda-runtime-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127
    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:
      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127
  Attempting uninstall: nvidia-cuda-nvrtc-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127
    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:
      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127
  Attempting uninstall: nvidia-cuda-cupti-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127
    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:
      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127
  Attempting uninstall: nvidia-cublas-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cublas-cu12 12.4.5.8
    Uninstalling nvidia-cublas-cu12-12.4.5.8:
      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8
  Attempting uninstall: nvidia-cusolver-cu12
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: nvidia-cusolver-cu12 11.6.1.9
    Uninstalling nvidia-cusolver-cu12-11.6.1.9:
      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9
  Attempting uninstall: torch
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: torch 2.5.1
    Uninstalling torch-2.5.1:
      Successfully uninstalled torch-2.5.1
  Attempting uninstall: xformers
    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
    Found existing installation: xformers 0.0.28.post3
    Uninstalling xformers-0.0.28.post3:
      Successfully uninstalled xformers-0.0.28.post3
WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
torchvision 0.20.1 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.
Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0 xformers-0.0.28
WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)
WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)</code></pre>
</div>
</div>
<div id="cell-4" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jinja2</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> bitsandbytes</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(transformers.__version__)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(jinja2.__version__)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bitsandbytes.__version__)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>jinja2.parser</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.47.0
3.1.4
0.45.0</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>&lt;module 'jinja2.parser' from '/home/ubuntu/.local/lib/python3.11/site-packages/jinja2/parser.py'&gt;</code></pre>
</div>
</div>
</section>
<section id="load-images" class="level2">
<h2 class="anchored" data-anchor-id="load-images">Load Images</h2>
<div id="cell-6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModel, AutoTokenizer</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>dataset_name <span class="op">=</span> <span class="st">"zzsi/afhq64_16k"</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HuggingFaceDataset(Dataset):</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset_path: <span class="bu">str</span>, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> load_dataset(dataset_path, split<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_key <span class="op">=</span> <span class="va">self</span>.find_image_key()</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> find_image_key(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the dataset has the "image" key</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Can exapnd this to other common keys if needed</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"image"</span> <span class="kw">in</span> <span class="va">self</span>.dataset[<span class="dv">0</span>].keys():</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"image"</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">KeyError</span>(<span class="st">"Dataset does not have an 'image' key"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> <span class="va">self</span>.dataset[idx][<span class="va">self</span>.image_key]</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> image.convert(<span class="st">"RGB"</span>)  <span class="co"># Convert to RGB to ensure 3 channels</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># By default, set label to 0 to conform to current expected batch format</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, label</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>transforms_list <span class="op">=</span> [</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose(transforms_list)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>full_dataset <span class="op">=</span> HuggingFaceDataset(dataset_name, transform<span class="op">=</span>transform)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"dataset has </span><span class="sc">{</span><span class="bu">len</span>(full_dataset)<span class="sc">}</span><span class="ss"> images"</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"first image shape: </span><span class="sc">{</span>full_dataset[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dataset has 14630 images
first image shape: torch.Size([3, 64, 64])</code></pre>
</div>
</div>
<div id="cell-7" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>first_image <span class="op">=</span> full_dataset[<span class="dv">0</span>][<span class="dv">0</span>].permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).numpy()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(first_image)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="compare_vlms_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># normalize the image to [0, 1]</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>first_image <span class="op">=</span> (first_image <span class="op">-</span> first_image.<span class="bu">min</span>()) <span class="op">/</span> <span class="bu">max</span>(first_image.<span class="bu">max</span>() <span class="op">-</span> first_image.<span class="bu">min</span>(), <span class="fl">1e-6</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>pil_image <span class="op">=</span> Image.fromarray((first_image <span class="op">*</span> <span class="dv">255</span>).astype(np.uint8))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>pil_image.save(<span class="st">"first_image.jpg"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="qwen-vl" class="level2">
<h2 class="anchored" data-anchor-id="qwen-vl">QWEN-VL</h2>
<div id="cell-10" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qwen_vl_utils <span class="im">import</span> process_vision_info</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># default: Load the model on the available device(s)</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Qwen2VLForConditionalGeneration.from_pretrained(</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Qwen/Qwen2-VL-2B-Instruct-AWQ"</span>, torch_dtype<span class="op">=</span><span class="st">"auto"</span>, device_map<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># model = Qwen2VLForConditionalGeneration.from_pretrained(</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">#     "Qwen/Qwen2-VL-2B-Instruct-AWQ",</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">#     torch_dtype=torch.bfloat16,</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">#     attn_implementation="flash_attention_2",</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     device_map="auto",</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># default processer</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> AutoProcessor.from_pretrained(<span class="st">"Qwen/Qwen2-VL-2B-Instruct-AWQ"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co"># The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co"># min_pixels = 256*28*28</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co"># max_pixels = 1280*28*28</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="co"># processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct-AWQ", min_pixels=min_pixels, max_pixels=max_pixels)</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-12-06 14:56:55.329856: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-06 14:56:55.342432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-06 14:56:55.357560: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-06 14:56:55.362094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-06 14:56:55.373408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-06 14:56:56.085600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46</code></pre>
</div>
</div>
<div id="cell-11" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># base64 encoded image using jpeg</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> base64</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># first write the image to a bytes object</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>image_bytes <span class="op">=</span> io.BytesIO()</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>pil_image.save(image_bytes, <span class="bu">format</span><span class="op">=</span><span class="st">"JPEG"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>image_bytes <span class="op">=</span> image_bytes.getvalue()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>prefix <span class="op">=</span> <span class="st">"data:image/jpeg;base64,"</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>image_base64 <span class="op">=</span> prefix <span class="op">+</span> base64.b64encode(image_bytes).decode(<span class="st">'utf-8'</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: [</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>                <span class="st">"type"</span>: <span class="st">"image"</span>,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>                <span class="st">"image"</span>: image_base64,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>                <span class="co"># "image": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg",</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>            {<span class="st">"type"</span>: <span class="st">"text"</span>, <span class="st">"text"</span>: <span class="st">"Describe this image."</span>},</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocess the inputs</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparation for inference</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> processor.apply_chat_template(</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    messages, tokenize<span class="op">=</span><span class="va">False</span>, add_generation_prompt<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>image_inputs, video_inputs <span class="op">=</span> process_vision_info(messages)</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> processor(</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    text<span class="op">=</span>[text],</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    images<span class="op">=</span>image_inputs,</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    videos<span class="op">=</span>video_inputs,</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    padding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    return_tensors<span class="op">=</span><span class="st">"pt"</span>,</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> inputs.to(<span class="st">"cuda"</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference: Generation of the output</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>generated_ids <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">128</span>)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>generated_ids_trimmed <span class="op">=</span> [</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    out_ids[<span class="bu">len</span>(in_ids) :] <span class="cf">for</span> in_ids, out_ids <span class="kw">in</span> <span class="bu">zip</span>(inputs.input_ids, generated_ids)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>output_text <span class="op">=</span> processor.batch_decode(</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>    generated_ids_trimmed, skip_special_tokens<span class="op">=</span><span class="va">True</span>, clean_up_tokenization_spaces<span class="op">=</span><span class="va">False</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>["The image depicts a cat with a long, flowing coat that appears to be a Maine Coon breed. The cat has a fluffy, dense fur that is predominantly white with some darker markings, particularly around the eyes and around the neck. The cat's eyes are large and expressive, and it has a long, curved tail that is slightly curled. The cat's ears are pointed and have a distinct, fluffy texture. The overall appearance of the cat suggests it is well-groomed and healthy."]</code></pre>
</div>
</div>
</section>
<section id="cogvlm" class="level2">
<h2 class="anchored" data-anchor-id="cogvlm">CogVLM</h2>
<div id="cell-13" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>MODEL_PATH <span class="op">=</span> <span class="st">"THUDM/cogvlm2-llama3-chat-19B-int4"</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>DEVICE <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>TORCH_TYPE <span class="op">=</span> torch.bfloat16 <span class="cf">if</span> torch.cuda.is_available() <span class="kw">and</span> torch.cuda.get_device_capability()[</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>] <span class="op">&gt;=</span> <span class="dv">8</span> <span class="cf">else</span> torch.float16</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    MODEL_PATH,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    trust_remote_code<span class="op">=</span><span class="va">True</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    MODEL_PATH,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>TORCH_TYPE,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    trust_remote_code<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    low_cpu_mem_usage<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>).<span class="bu">eval</span>()</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>text_only_template <span class="op">=</span> <span class="st">"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: </span><span class="sc">{}</span><span class="st"> ASSISTANT:"</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"Describe this image."</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> []</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>input_by_model <span class="op">=</span> model.build_conversation_input_ids(</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>                tokenizer,</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>query,</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>                history<span class="op">=</span>history,</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>                images<span class="op">=</span>[pil_image],</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>                template_version<span class="op">=</span><span class="st">'chat'</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> {</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'input_ids'</span>: input_by_model[<span class="st">'input_ids'</span>].unsqueeze(<span class="dv">0</span>).to(DEVICE),</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'token_type_ids'</span>: input_by_model[<span class="st">'token_type_ids'</span>].unsqueeze(<span class="dv">0</span>).to(DEVICE),</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'attention_mask'</span>: input_by_model[<span class="st">'attention_mask'</span>].unsqueeze(<span class="dv">0</span>).to(DEVICE),</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">'images'</span>: [[input_by_model[<span class="st">'images'</span>][<span class="dv">0</span>].to(DEVICE).to(TORCH_TYPE)]] <span class="cf">if</span> pil_image <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>gen_kwargs <span class="op">=</span> {</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">"max_new_tokens"</span>: <span class="dv">128</span>,</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pad_token_id"</span>: <span class="dv">128002</span>,</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, <span class="op">**</span>gen_kwargs)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> outputs[:, inputs[<span class="st">'input_ids'</span>].shape[<span class="dv">1</span>]:]</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> tokenizer.decode(outputs[<span class="dv">0</span>])</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> response.split(<span class="st">"&lt;|end_of_text|&gt;"</span>)[<span class="dv">0</span>]</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">CogVLM2:"</span>, response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in &lt;class 'transformers.utils.quantization_config.BitsAndBytesConfig'&gt;.</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[9], line 44</span>
<span class="ansi-green-fg ansi-bold">     38</span> gen_kwargs <span style="color:rgb(98,98,98)">=</span> {
<span class="ansi-green-fg ansi-bold">     39</span>     <span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">max_new_tokens</span><span style="color:rgb(175,0,0)">"</span>: <span style="color:rgb(98,98,98)">128</span>,
<span class="ansi-green-fg ansi-bold">     40</span>     <span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">pad_token_id</span><span style="color:rgb(175,0,0)">"</span>: <span style="color:rgb(98,98,98)">128002</span>,
<span class="ansi-green-fg ansi-bold">     41</span> }
<span class="ansi-green-fg ansi-bold">     43</span> <span style="font-weight:bold;color:rgb(0,135,0)">with</span> torch<span style="color:rgb(98,98,98)">.</span>no_grad():
<span class="ansi-green-fg">---&gt; 44</span>     outputs <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">model</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">generate</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">gen_kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">     45</span>     outputs <span style="color:rgb(98,98,98)">=</span> outputs[:, inputs[<span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">input_ids</span><span style="color:rgb(175,0,0)">'</span>]<span style="color:rgb(98,98,98)">.</span>shape[<span style="color:rgb(98,98,98)">1</span>]:]
<span class="ansi-green-fg ansi-bold">     46</span>     response <span style="color:rgb(98,98,98)">=</span> tokenizer<span style="color:rgb(98,98,98)">.</span>decode(outputs[<span style="color:rgb(98,98,98)">0</span>])

File <span class="ansi-green-fg">~/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py:116</span>, in <span class="ansi-cyan-fg">context_decorator.&lt;locals&gt;.decorate_context</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">    113</span> <span style="color:rgb(175,0,255)">@functools</span><span style="color:rgb(98,98,98)">.</span>wraps(func)
<span class="ansi-green-fg ansi-bold">    114</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span> <span style="color:rgb(0,0,255)">decorate_context</span>(<span style="color:rgb(98,98,98)">*</span>args, <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>kwargs):
<span class="ansi-green-fg ansi-bold">    115</span>     <span style="font-weight:bold;color:rgb(0,135,0)">with</span> ctx_factory():
<span class="ansi-green-fg">--&gt; 116</span>         <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">func</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/.local/lib/python3.11/site-packages/transformers/generation/utils.py:2252</span>, in <span class="ansi-cyan-fg">GenerationMixin.generate</span><span class="ansi-blue-fg">(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">   2244</span>     input_ids, model_kwargs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_expand_inputs_for_generation(
<span class="ansi-green-fg ansi-bold">   2245</span>         input_ids<span style="color:rgb(98,98,98)">=</span>input_ids,
<span class="ansi-green-fg ansi-bold">   2246</span>         expand_size<span style="color:rgb(98,98,98)">=</span>generation_config<span style="color:rgb(98,98,98)">.</span>num_return_sequences,
<span class="ansi-green-fg ansi-bold">   2247</span>         is_encoder_decoder<span style="color:rgb(98,98,98)">=</span><span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>config<span style="color:rgb(98,98,98)">.</span>is_encoder_decoder,
<span class="ansi-green-fg ansi-bold">   2248</span>         <span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>model_kwargs,
<span class="ansi-green-fg ansi-bold">   2249</span>     )
<span class="ansi-green-fg ansi-bold">   2251</span>     <span style="font-style:italic;color:rgb(95,135,135)"># 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)</span>
<span class="ansi-green-fg">-&gt; 2252</span>     result <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_sample</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">   2253</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">input_ids</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2254</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">logits_processor</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">prepared_logits_processor</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2255</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">stopping_criteria</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">prepared_stopping_criteria</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2256</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">generation_config</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">generation_config</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2257</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">synced_gpus</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">synced_gpus</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2258</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">streamer</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">streamer</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2259</span> <span class="ansi-yellow-bg">        </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">model_kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   2260</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   2262</span> <span style="font-weight:bold;color:rgb(0,135,0)">elif</span> generation_mode <span style="font-weight:bold;color:rgb(175,0,255)">in</span> (GenerationMode<span style="color:rgb(98,98,98)">.</span>BEAM_SAMPLE, GenerationMode<span style="color:rgb(98,98,98)">.</span>BEAM_SEARCH):
<span class="ansi-green-fg ansi-bold">   2263</span>     <span style="font-style:italic;color:rgb(95,135,135)"># 11. prepare beam search scorer</span>
<span class="ansi-green-fg ansi-bold">   2264</span>     beam_scorer <span style="color:rgb(98,98,98)">=</span> BeamSearchScorer(
<span class="ansi-green-fg ansi-bold">   2265</span>         batch_size<span style="color:rgb(98,98,98)">=</span>batch_size,
<span class="ansi-green-fg ansi-bold">   2266</span>         num_beams<span style="color:rgb(98,98,98)">=</span>generation_config<span style="color:rgb(98,98,98)">.</span>num_beams,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-fg ansi-bold">   2271</span>         max_length<span style="color:rgb(98,98,98)">=</span>generation_config<span style="color:rgb(98,98,98)">.</span>max_length,
<span class="ansi-green-fg ansi-bold">   2272</span>     )

File <span class="ansi-green-fg">~/.local/lib/python3.11/site-packages/transformers/generation/utils.py:3257</span>, in <span class="ansi-cyan-fg">GenerationMixin._sample</span><span class="ansi-blue-fg">(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)</span>
<span class="ansi-green-fg ansi-bold">   3254</span>     outputs <span style="color:rgb(98,98,98)">=</span> model_forward(<span style="color:rgb(98,98,98)">*</span><span style="color:rgb(98,98,98)">*</span>model_inputs, return_dict<span style="color:rgb(98,98,98)">=</span><span style="font-weight:bold;color:rgb(0,135,0)">True</span>)
<span class="ansi-green-fg ansi-bold">   3256</span> <span style="font-style:italic;color:rgb(95,135,135)"># synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping</span>
<span class="ansi-green-fg">-&gt; 3257</span> model_kwargs <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_update_model_kwargs_for_generation</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">   3258</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">outputs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   3259</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">model_kwargs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   3260</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">is_encoder_decoder</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">config</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">is_encoder_decoder</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-fg ansi-bold">   3261</span> <span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">   3262</span> <span style="font-weight:bold;color:rgb(0,135,0)">if</span> synced_gpus <span style="font-weight:bold;color:rgb(175,0,255)">and</span> this_peer_finished:
<span class="ansi-green-fg ansi-bold">   3263</span>     <span style="font-weight:bold;color:rgb(0,135,0)">continue</span>

File <span class="ansi-green-fg">~/.cache/huggingface/modules/transformers_modules/THUDM/cogvlm2-llama3-chat-19B-int4/119df232ab9fca4a1be87f95c239d7b9a765032e/modeling_cogvlm.py:710</span>, in <span class="ansi-cyan-fg">CogVLMForCausalLM._update_model_kwargs_for_generation</span><span class="ansi-blue-fg">(self, outputs, model_kwargs, is_encoder_decoder, standardize_cache_format)</span>
<span class="ansi-green-fg ansi-bold">    702</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span> <span style="color:rgb(0,0,255)">_update_model_kwargs_for_generation</span>(
<span class="ansi-green-fg ansi-bold">    703</span>         <span style="color:rgb(0,135,0)">self</span>,
<span class="ansi-green-fg ansi-bold">    704</span>         outputs: <span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">ModelOutput</span><span style="color:rgb(175,0,0)">"</span>,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-fg ansi-bold">    708</span> ) <span style="color:rgb(98,98,98)">-</span><span style="color:rgb(98,98,98)">&gt;</span> Dict[<span style="color:rgb(0,135,0)">str</span>, Any]:
<span class="ansi-green-fg ansi-bold">    709</span>     <span style="font-style:italic;color:rgb(95,135,135)"># update past_key_values</span>
<span class="ansi-green-fg">--&gt; 710</span>     model_kwargs[<span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">past_key_values</span><span style="color:rgb(175,0,0)">"</span>] <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)" class="ansi-yellow-bg">self</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">_extract_past_from_model_output</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">    711</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">outputs</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">standardize_cache_format</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">standardize_cache_format</span>
<span class="ansi-green-fg ansi-bold">    712</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">    713</span>     <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="color:rgb(0,135,0)">getattr</span>(outputs, <span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">state</span><span style="color:rgb(175,0,0)">"</span>, <span style="font-weight:bold;color:rgb(0,135,0)">None</span>) <span style="font-weight:bold;color:rgb(175,0,255)">is</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>:
<span class="ansi-green-fg ansi-bold">    714</span>         model_kwargs[<span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">state</span><span style="color:rgb(175,0,0)">"</span>] <span style="color:rgb(98,98,98)">=</span> outputs<span style="color:rgb(98,98,98)">.</span>state

<span class="ansi-red-fg">TypeError</span>: GenerationMixin._extract_past_from_model_output() got an unexpected keyword argument 'standardize_cache_format'</pre>
</div>
</div>
</div>
</section>
<section id="try-blip-2" class="level2">
<h2 class="anchored" data-anchor-id="try-blip-2">Try Blip-2</h2>
</section>
<section id="try-minicpm-v-2" class="level2">
<h2 class="anchored" data-anchor-id="try-minicpm-v-2">Try MiniCPM-V-2</h2>
<div id="cell-16" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">'openbmb/MiniCPM-V-2'</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModel.from_pretrained(model_name, trust_remote_code<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    attn_implementation<span class="op">=</span><span class="st">'sdpa'</span>, torch_dtype<span class="op">=</span>torch.bfloat16) <span class="co"># sdpa or flash_attention_2, no eager</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For Nvidia GPUs support BF16 (like A100, H100, RTX3090)</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device<span class="op">=</span><span class="st">'cuda'</span>, dtype<span class="op">=</span>torch.bfloat16)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># For Nvidia GPUs do NOT support BF16 (like V100, T4, RTX2080)</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">#model = model.to(device='cuda', dtype=torch.float16)</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># For Mac with MPS (Apple silicon or AMD GPUs).</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Run with `PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py`</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">#model = model.to(device='mps', dtype=torch.float16)</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> model.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9aaeca35f34d404187f6002e1a46dc5f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="cell-17" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(first_image.shape, first_image.<span class="bu">max</span>() <span class="op">*</span> <span class="dv">255</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>pil_image <span class="op">=</span> Image.fromarray((first_image <span class="op">*</span> <span class="dv">255</span>).astype(np.uint8))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">'What is in the image?'</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">=</span> [{<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: question}]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>res, context, _ <span class="op">=</span> model.chat(</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    image<span class="op">=</span>pil_image,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    msgs<span class="op">=</span>msgs,</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    context<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sampling=True,</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># temperature=0.7</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(64, 64, 3) 166.00000530481339</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[19], line 11</span>
<span class="ansi-green-fg ansi-bold">      8</span> question <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">What is in the image?</span><span style="color:rgb(175,0,0)">'</span>
<span class="ansi-green-fg ansi-bold">      9</span> msgs <span style="color:rgb(98,98,98)">=</span> [{<span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">role</span><span style="color:rgb(175,0,0)">'</span>: <span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">user</span><span style="color:rgb(175,0,0)">'</span>, <span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">content</span><span style="color:rgb(175,0,0)">'</span>: question}]
<span class="ansi-green-fg">---&gt; 11</span> res, context, _ <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">model</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">chat</span>(
<span class="ansi-green-fg ansi-bold">     12</span>     image<span style="color:rgb(98,98,98)">=</span>pil_image,
<span class="ansi-green-fg ansi-bold">     13</span>     msgs<span style="color:rgb(98,98,98)">=</span>msgs,
<span class="ansi-green-fg ansi-bold">     14</span>     tokenizer<span style="color:rgb(98,98,98)">=</span>tokenizer,
<span class="ansi-green-fg ansi-bold">     15</span>     context<span style="color:rgb(98,98,98)">=</span><span style="font-weight:bold;color:rgb(0,135,0)">None</span>,
<span class="ansi-green-fg ansi-bold">     16</span>     <span style="font-style:italic;color:rgb(95,135,135)"># sampling=True,</span>
<span class="ansi-green-fg ansi-bold">     17</span>     <span style="font-style:italic;color:rgb(95,135,135)"># temperature=0.7</span>
<span class="ansi-green-fg ansi-bold">     18</span> )
<span class="ansi-green-fg ansi-bold">     19</span> <span style="color:rgb(0,135,0)">print</span>(res)

File <span class="ansi-green-fg">~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1729</span>, in <span class="ansi-cyan-fg">Module.__getattr__</span><span class="ansi-blue-fg">(self, name)</span>
<span class="ansi-green-fg ansi-bold">   1727</span>     <span style="font-weight:bold;color:rgb(0,135,0)">if</span> name <span style="font-weight:bold;color:rgb(175,0,255)">in</span> modules:
<span class="ansi-green-fg ansi-bold">   1728</span>         <span style="font-weight:bold;color:rgb(0,135,0)">return</span> modules[name]
<span class="ansi-green-fg">-&gt; 1729</span> <span style="font-weight:bold;color:rgb(0,135,0)">raise</span> <span style="font-weight:bold;color:rgb(215,95,95)">AttributeError</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">'</span><span style="font-weight:bold;color:rgb(175,95,135)">{</span><span style="color:rgb(0,135,0)">type</span>(<span style="color:rgb(0,135,0)">self</span>)<span style="color:rgb(98,98,98)">.</span><span style="color:rgb(0,0,135)">__name__</span><span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)"> object has no attribute </span><span style="color:rgb(175,0,0)">'</span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>name<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'Qwen2VLForConditionalGeneration' object has no attribute 'chat'</pre>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kungfuai\.github\.io\/nano-diffusion\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>