{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the files in the parent directory run this cell\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vqvae import VQVAE\n",
    "from src.models.var import VAR\n",
    "from src.datasets.hugging_face_dataset import HuggingFaceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"mnist\": {\n",
    "        \"VQVAE_DIM\": 64,\n",
    "        \"VOCAB_SIZE\": 32,\n",
    "        \"PATCH_SIZES\": [1, 2, 3, 4, 8],\n",
    "        \"VAR_DIM\": 64,\n",
    "        \"N_HEADS\": 4,\n",
    "        \"N_LAYERS\": 6,\n",
    "        \"channels\": 1,\n",
    "    },\n",
    "    \"cifar\": {\n",
    "        \"VQVAE_DIM\": 512,\n",
    "        \"VOCAB_SIZE\": 2048,\n",
    "        \"PATCH_SIZES\": [1, 2, 3, 4, 6, 8],\n",
    "        \"VAR_DIM\": 512,\n",
    "        \"N_HEADS\": 16,\n",
    "        \"N_LAYERS\": 12,\n",
    "        \"channels\": 3,\n",
    "    },\n",
    "    \"small\": {\n",
    "        \"VQVAE_DIM\": 512,\n",
    "        \"VOCAB_SIZE\": 1024,\n",
    "        \"PATCH_SIZES\": [1, 2, 3, 4, 6, 8],\n",
    "        \"VAR_DIM\": 512,\n",
    "        \"N_HEADS\": 16,\n",
    "        \"N_LAYERS\": 16,\n",
    "        \"channels\": 3,\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"VQVAE_DIM\": 512,\n",
    "        \"VOCAB_SIZE\": 2048,\n",
    "        \"PATCH_SIZES\": [1, 2, 3, 4, 6, 8],\n",
    "        \"VAR_DIM\": 512,\n",
    "        \"N_HEADS\": 32,\n",
    "        \"N_LAYERS\": 20,\n",
    "        \"channels\": 3,\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"VQVAE_DIM\": 512,\n",
    "        \"VOCAB_SIZE\": 4096,\n",
    "        \"PATCH_SIZES\": [1, 2, 3, 4, 6, 8],\n",
    "        \"VAR_DIM\": 512,\n",
    "        \"N_HEADS\": 64,\n",
    "        \"N_LAYERS\": 24,\n",
    "        \"channels\": 3,\n",
    "    },\n",
    "}\n",
    "\n",
    "training_params = {\n",
    "    \"mnist\": {\n",
    "        \"VQVAE\": {\n",
    "            \"batch_size\": 2048,\n",
    "            \"lr\": 3e-4,\n",
    "            \"epochs\": 40,\n",
    "        },\n",
    "        \"VAR\": {\n",
    "            \"batch_size\": 1024,\n",
    "            \"lr\": 1e-3,\n",
    "            \"epochs\": 100,\n",
    "        },\n",
    "    },\n",
    "    \"cifar\": {\n",
    "        \"VQVAE\": {\n",
    "            \"batch_size\": 512,\n",
    "            \"lr\": 3e-4,\n",
    "            \"epochs\": 100,\n",
    "        },\n",
    "        \"VAR\": {\n",
    "            \"batch_size\": 64,\n",
    "            \"lr\": 1e-4,\n",
    "            \"epochs\": 100,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def get_data(batch_size=1024, dataset=\"mnist\"):\n",
    "    if dataset == \"cifar\":\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.RandomCrop(32),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        )\n",
    "        train_ds = datasets.CIFAR10(\n",
    "            root=\"./data\", train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_ds = datasets.CIFAR10(\n",
    "            root=\"./data\", train=False, download=True, transform=transform\n",
    "        )\n",
    "    elif dataset == \"mnist\":\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Pad(2),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        )\n",
    "        train_ds = datasets.MNIST(\n",
    "            root=\"./data\", train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_ds = datasets.MNIST(\n",
    "            root=\"./data\", train=False, download=True, transform=transform\n",
    "        )\n",
    "    else:\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ]\n",
    "        )\n",
    "        # Use HuggingFace datasets\n",
    "        train_ds = HuggingFaceDataset(dataset_path=dataset, split=\"train\", transform=transform)\n",
    "        test_ds = HuggingFaceDataset(dataset_path=dataset, split=\"val\", transform=transform)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=False, drop_last=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    print(len(train_loader), len(test_loader))\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def plot_images(pred, original=None):\n",
    "    n = pred.size(0)\n",
    "    pred = pred * 0.5 + 0.5\n",
    "    pred = pred.clamp(0, 1)\n",
    "    img = pred.cpu().detach()\n",
    "\n",
    "    if original is not None:\n",
    "        original = original * 0.5 + 0.5\n",
    "        original = original.clamp(0, 1)\n",
    "        original = original.cpu().detach()\n",
    "        img = torch.cat([original, img], dim=0)\n",
    "\n",
    "    img_grid = make_grid(img, nrow=n)\n",
    "    img_grid = img_grid.permute(1, 2, 0).numpy()\n",
    "    img_grid = (img_grid * 255).astype(\"uint8\")\n",
    "    plt.imshow(img_grid)\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"zzsi/afhq64_16k\"\n",
    "model_params = model_params[\"small\"]\n",
    "training_params = training_params[\"cifar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Training VQVAE==========\n",
      "29 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 4.866057824471901, Recon Loss: 0.2037651019877401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:15<1:50:34, 135.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Test Loss: 3.8543347120285034, Test Recon Loss: 0.2917487621307373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [04:28<1:47:02, 133.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.544010181365342, Recon Loss: 0.16000377489575024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [06:40<1:44:22, 133.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.2832418890862629, Recon Loss: 0.11356585344363904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [08:53<1:42:03, 133.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.3485085064994878, Recon Loss: 0.08586812404723003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [11:06<1:39:44, 132.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.18769233982110844, Recon Loss: 0.0627873841801594\n",
      "Epoch: 5, Loss: 0.14358470614614158, Recon Loss: 0.055644100596164835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [13:22<1:38:16, 134.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Test Loss: 0.16564584523439407, Test Recon Loss: 0.055470388382673264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [15:35<1:35:49, 133.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.13170330534721242, Recon Loss: 0.05064002925465847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [17:48<1:33:27, 133.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.10611220963042357, Recon Loss: 0.046990403070532046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [20:01<1:31:05, 133.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.0958550356585404, Recon Loss: 0.04487122261318667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [22:14<1:28:49, 133.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.09425708677234321, Recon Loss: 0.04185084870149349\n",
      "Epoch: 10, Loss: 0.09060800178297634, Recon Loss: 0.04025830020164621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [24:30<1:27:04, 133.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Test Loss: 0.10135117545723915, Test Recon Loss: 0.04018284194171429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [26:43<1:24:41, 133.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.0886174812912941, Recon Loss: 0.03811735891062638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [28:56<1:22:19, 133.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.08969448326990523, Recon Loss: 0.038376129264461586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [31:09<1:20:07, 133.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.08487800277512648, Recon Loss: 0.03569597988550005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [33:22<1:17:49, 133.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.08499745279550552, Recon Loss: 0.040501814464042926\n",
      "Epoch: 15, Loss: 0.08797449053361497, Recon Loss: 0.03595935752422645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [35:39<1:16:05, 134.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Test Loss: 0.09106981009244919, Test Recon Loss: 0.035018209367990494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [37:52<1:13:42, 134.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.07861711958359027, Recon Loss: 0.032968056677230476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [40:06<1:11:24, 133.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.07785250593362184, Recon Loss: 0.03151722939620758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [42:19<1:09:02, 133.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.07636784325385916, Recon Loss: 0.030136421065906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [44:32<1:06:43, 133.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.07501227524259994, Recon Loss: 0.029429074248363232\n",
      "Epoch: 20, Loss: 0.07364063093374515, Recon Loss: 0.027916064421678412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [46:48<1:04:51, 134.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Test Loss: 0.08149045333266258, Test Recon Loss: 0.02744843065738678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [49:01<1:02:30, 133.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.07409323829001394, Recon Loss: 0.03050791658461094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [51:14<1:00:08, 133.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.07717355443485852, Recon Loss: 0.027840690045007343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [53:28<57:53, 133.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.07298342934970198, Recon Loss: 0.026266125062930173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [55:41<55:36, 133.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.07263677862697634, Recon Loss: 0.02677988993196652\n",
      "Epoch: 25, Loss: 0.07230470689206288, Recon Loss: 0.025101954310104764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [57:57<53:41, 134.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Test Loss: 0.07872357964515686, Test Recon Loss: 0.02432861551642418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [1:00:10<51:20, 133.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.07201809281932897, Recon Loss: 0.02500430719348891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [1:02:23<49:02, 133.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.07150217312677153, Recon Loss: 0.0235540849509938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [1:04:36<46:45, 133.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.07005925116867855, Recon Loss: 0.02338059856716929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:06:50<44:29, 133.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.06976968615219512, Recon Loss: 0.022256459848120295\n",
      "Epoch: 30, Loss: 0.06969840387845862, Recon Loss: 0.022317839657952046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:09:06<42:29, 134.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Test Loss: 0.07672495022416115, Test Recon Loss: 0.0212257606908679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:11:19<40:10, 133.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 0.06945623264744363, Recon Loss: 0.022399662126754892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:13:32<37:52, 133.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 0.06941864819362245, Recon Loss: 0.020924362257636827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:15:45<35:37, 133.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 0.06871920323063588, Recon Loss: 0.020831638240608675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:17:58<33:21, 133.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.06914223101118515, Recon Loss: 0.02090210313427037\n",
      "Epoch: 35, Loss: 0.06984086899921813, Recon Loss: 0.020252555544520247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:20:14<31:18, 134.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Test Loss: 0.07590556517243385, Test Recon Loss: 0.01940724067389965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:22:28<29:00, 133.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 0.06964375065832303, Recon Loss: 0.02327565116615131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:24:41<26:43, 133.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 0.0730013571165759, Recon Loss: 0.020531707860786338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:26:54<24:28, 133.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 0.06979389989684368, Recon Loss: 0.019396698680417292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:29:07<22:14, 133.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Loss: 0.06858309563891642, Recon Loss: 0.019280468916584706\n",
      "Epoch: 40, Loss: 0.06866673482903118, Recon Loss: 0.019353121262172174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:31:23<20:07, 134.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Test Loss: 0.0747237391769886, Test Recon Loss: 0.01894175447523594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:33:36<17:51, 133.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Loss: 0.06869632853516217, Recon Loss: 0.020744971160230965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:35:49<15:35, 133.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Loss: 0.07161692696912535, Recon Loss: 0.01933481345145867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:38:03<13:21, 133.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Loss: 0.06914105831549086, Recon Loss: 0.01909165110053687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:40:16<11:07, 133.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Loss: 0.06926265885603838, Recon Loss: 0.01853909157216549\n",
      "Epoch: 45, Loss: 0.06853570442261367, Recon Loss: 0.018559810994514103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:42:32<08:57, 134.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Test Loss: 0.07530079782009125, Test Recon Loss: 0.01822421234101057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:44:45<06:41, 134.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Loss: 0.06955526486552994, Recon Loss: 0.020134666356547124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [1:46:59<04:27, 133.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Loss: 0.06947716338367298, Recon Loss: 0.01871033449625147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [1:49:12<02:13, 133.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Loss: 0.06802729388763165, Recon Loss: 0.018576490981825466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:51:25<00:00, 133.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Loss: 0.06796855762087066, Recon Loss: 0.0177432169238555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\" * 10 + \"Training VQVAE\" + \"=\" * 10)\n",
    "vq_model = VQVAE(\n",
    "    model_params[\"VQVAE_DIM\"],\n",
    "    model_params[\"VOCAB_SIZE\"],\n",
    "    model_params[\"PATCH_SIZES\"],\n",
    "    num_channels=model_params[\"channels\"],\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    vq_model.parameters(), lr=training_params[\"VQVAE\"][\"lr\"]\n",
    ")\n",
    "\n",
    "train_loader, test_loader = get_data(\n",
    "    batch_size=training_params[\"VQVAE\"][\"batch_size\"], dataset=dataset\n",
    ")\n",
    "vq_model = vq_model.to(\"cuda\")\n",
    "\n",
    "# All epochs\n",
    "for epoch in tqdm(range(training_params[\"VQVAE\"][\"epochs\"])):\n",
    "    epoch_loss = 0\n",
    "    epoch_recon_loss = 0\n",
    "    # Single epochs\n",
    "    for i, (x, c) in enumerate(train_loader):\n",
    "        x, c = x.cuda(), c.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        xhat, r_maps, idxs, scales, q_loss = vq_model(x)\n",
    "        recon_loss = F.mse_loss(xhat, x)\n",
    "        loss = recon_loss + q_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_recon_loss += recon_loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_recon_loss /= len(train_loader)\n",
    "    print(f\"Epoch: {epoch}, Loss: {epoch_loss}, Recon Loss: {epoch_recon_loss}\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            total_recon_loss = 0\n",
    "            for i, (x, c) in enumerate(test_loader):\n",
    "                x, c = x.cuda(), c.cuda()\n",
    "                xhat, r_maps, idxs, scales, q_loss = vq_model(x)\n",
    "                recon_loss = F.mse_loss(xhat, x)\n",
    "                loss = recon_loss + q_loss\n",
    "                total_loss += loss.item()\n",
    "                total_recon_loss += recon_loss.item()\n",
    "\n",
    "            total_loss /= len(test_loader)\n",
    "            total_recon_loss /= len(test_loader)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, Test Loss: {total_loss}, Test Recon Loss: {total_recon_loss}\"\n",
    "            )\n",
    "\n",
    "            x = x[:10, :].cuda()\n",
    "            x_hat = vq_model(x)[0]\n",
    "\n",
    "            plot_images(pred=x_hat, original=x)\n",
    "            plt.savefig(f\"vqvae_{epoch}.png\")\n",
    "            plt.close()\n",
    "\n",
    "torch.save(vq_model.state_dict(), \"vqvae.pth\")\n",
    "del vq_model, optimizer, x, x_hat, train_loader, test_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Training VAR==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6209/1893514572.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vqvae.load_state_dict(torch.load(\"small_vqvae.pth\"))  # LOADS the trained VQVAE model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQVAE Parameters: 85.00M\n",
      "VAR Parameters: 178.97M\n",
      "229 23\n",
      "Epoch: 0, Loss: 4.210374780096862\n",
      "Epoch: 1, Loss: 4.026469395150264\n",
      "Epoch: 2, Loss: 3.9341810374280772\n",
      "Epoch: 3, Loss: 3.851914644241333\n",
      "Epoch: 4, Loss: 3.745109129160252\n",
      "Epoch: 5, Loss: 3.6351813031075824\n",
      "Epoch: 6, Loss: 3.5295720475209333\n",
      "Epoch: 7, Loss: 3.427367805914067\n",
      "Epoch: 8, Loss: 3.3203730312497335\n",
      "Epoch: 9, Loss: 3.2066679937870743\n",
      "Epoch: 10, Loss: 3.081625181514623\n",
      "Epoch: 11, Loss: 2.9439822003310425\n",
      "Epoch: 12, Loss: 2.7930768155635186\n",
      "Epoch: 13, Loss: 2.6147650490681675\n",
      "Epoch: 14, Loss: 2.43959974930276\n",
      "Epoch: 15, Loss: 2.241192906704532\n",
      "Epoch: 16, Loss: 2.0920631901145503\n",
      "Epoch: 17, Loss: 1.9529445371773566\n",
      "Epoch: 18, Loss: 1.8152784655708414\n",
      "Epoch: 19, Loss: 1.6868888712345773\n",
      "Epoch: 20, Loss: 1.5457673895306983\n",
      "Epoch: 21, Loss: 1.4383269316764897\n",
      "Epoch: 22, Loss: 1.3347437722714186\n",
      "Epoch: 23, Loss: 1.2131889936184779\n",
      "Epoch: 24, Loss: 1.1350385648194359\n",
      "Epoch: 25, Loss: 1.047056037265661\n",
      "Epoch: 26, Loss: 0.966550968750075\n",
      "Epoch: 27, Loss: 0.9136588495371123\n",
      "Epoch: 28, Loss: 0.8434017244645081\n",
      "Epoch: 29, Loss: 0.7849246492552445\n",
      "Epoch: 30, Loss: 0.7572188346146496\n",
      "Epoch: 31, Loss: 0.7092842149942723\n",
      "Epoch: 32, Loss: 0.6806259289318818\n",
      "Epoch: 33, Loss: 0.6640827759905154\n",
      "Epoch: 34, Loss: 0.6141958035626266\n",
      "Epoch: 35, Loss: 0.6062245102818876\n",
      "Epoch: 36, Loss: 0.5859922797268655\n",
      "Epoch: 37, Loss: 0.5586365849170102\n",
      "Epoch: 38, Loss: 0.5631688887895976\n",
      "Epoch: 39, Loss: 0.5494113136326902\n",
      "Epoch: 40, Loss: 0.5272899293483084\n",
      "Epoch: 41, Loss: 0.5316441231549567\n",
      "Epoch: 42, Loss: 0.5319354195131485\n",
      "Epoch: 43, Loss: 0.5297040052419146\n",
      "Epoch: 44, Loss: 0.501916189055776\n",
      "Epoch: 45, Loss: 0.5005710197197818\n",
      "Epoch: 46, Loss: 0.4946584939045677\n",
      "Epoch: 47, Loss: 0.4948659770223251\n",
      "Epoch: 48, Loss: 0.5002461966598919\n",
      "Epoch: 49, Loss: 0.5000344567553966\n",
      "Epoch: 50, Loss: 0.5067657910970621\n",
      "Epoch: 51, Loss: 0.5047541301063054\n",
      "Epoch: 52, Loss: 0.48415780047922674\n",
      "Epoch: 53, Loss: 0.48540887353722184\n",
      "Epoch: 54, Loss: 0.47871317138578173\n",
      "Epoch: 55, Loss: 0.498621100681838\n",
      "Epoch: 56, Loss: 0.4702313639321181\n",
      "Epoch: 57, Loss: 0.45352366072121664\n",
      "Epoch: 58, Loss: 0.4508914762058633\n",
      "Epoch: 59, Loss: 0.44769140362219\n",
      "Epoch: 60, Loss: 0.437688595082562\n",
      "Epoch: 61, Loss: 0.43243607273528667\n",
      "Epoch: 62, Loss: 0.4390038220642956\n",
      "Epoch: 63, Loss: 0.4367820168947028\n",
      "Epoch: 64, Loss: 0.4357858303462574\n",
      "Epoch: 65, Loss: 0.422029934140272\n",
      "Epoch: 66, Loss: 0.44050980310512944\n",
      "Epoch: 67, Loss: 0.4263673290024678\n",
      "Epoch: 68, Loss: 0.42691248329966347\n",
      "Epoch: 69, Loss: 0.42361048020129644\n",
      "Epoch: 70, Loss: 0.40996024227298505\n",
      "Epoch: 71, Loss: 0.4202991230128634\n",
      "Epoch: 72, Loss: 0.413461715959045\n",
      "Epoch: 73, Loss: 0.4164062709787527\n",
      "Epoch: 74, Loss: 0.41921532193125594\n",
      "Epoch: 75, Loss: 0.4111065519038246\n",
      "Epoch: 76, Loss: 0.4148808561558286\n",
      "Epoch: 77, Loss: 0.41260189364570715\n",
      "Epoch: 78, Loss: 0.4069012415851568\n",
      "Epoch: 79, Loss: 0.39940204637279675\n",
      "Epoch: 80, Loss: 0.3974037314866828\n",
      "Epoch: 81, Loss: 0.39479867014301917\n",
      "Epoch: 82, Loss: 0.38855153998953806\n",
      "Epoch: 83, Loss: 0.39252285874046094\n",
      "Epoch: 84, Loss: 0.3911732513311128\n",
      "Epoch: 85, Loss: 0.3787576046703164\n",
      "Epoch: 86, Loss: 0.3785138236903728\n",
      "Epoch: 87, Loss: 0.37262930125648797\n",
      "Epoch: 88, Loss: 0.36406170482458505\n",
      "Epoch: 89, Loss: 0.3741317962064493\n",
      "Epoch: 90, Loss: 0.36833507824672884\n",
      "Epoch: 91, Loss: 0.37608705402461723\n",
      "Epoch: 92, Loss: 0.36919091993284014\n",
      "Epoch: 93, Loss: 0.36889918076939976\n",
      "Epoch: 94, Loss: 0.3741550101984016\n",
      "Epoch: 95, Loss: 0.3744078678725588\n",
      "Epoch: 96, Loss: 0.36554370137281295\n",
      "Epoch: 97, Loss: 0.3661379842779001\n",
      "Epoch: 98, Loss: 0.3595298945773637\n",
      "Epoch: 99, Loss: 0.370525611930539\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 10 + \"Training VAR\" + \"=\" * 10)\n",
    "vqvae = VQVAE(\n",
    "    model_params[\"VQVAE_DIM\"],\n",
    "    model_params[\"VOCAB_SIZE\"],\n",
    "    model_params[\"PATCH_SIZES\"],\n",
    "    num_channels=model_params[\"channels\"],\n",
    ")\n",
    "vqvae.load_state_dict(torch.load(\"small_vqvae.pth\"))  # LOADS the trained VQVAE model\n",
    "vqvae = vqvae.to(\"cuda\")\n",
    "vqvae.eval()\n",
    "\n",
    "for param in vqvae.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "var_model = VAR(\n",
    "    vqvae=vqvae,\n",
    "    dim=model_params[\"VAR_DIM\"],\n",
    "    n_heads=model_params[\"N_HEADS\"],\n",
    "    n_layers=model_params[\"N_LAYERS\"],\n",
    "    patch_sizes=model_params[\"PATCH_SIZES\"],\n",
    "    n_classes=10,\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    var_model.parameters(), lr=training_params[\"VAR\"][\"lr\"]\n",
    ")\n",
    "\n",
    "print(f\"VQVAE Parameters: {sum(p.numel() for p in vqvae.parameters())/1e6:.2f}M\")\n",
    "print(f\"VAR Parameters: {sum(p.numel() for p in var_model.parameters())/1e6:.2f}M\")\n",
    "\n",
    "train_loader, test_loader = get_data(\n",
    "    batch_size=training_params[\"VAR\"][\"batch_size\"], dataset=dataset\n",
    ")\n",
    "var_model = var_model.to(\"cuda\")\n",
    "for epoch in range(training_params[\"VAR\"][\"epochs\"]):\n",
    "    epoch_loss = 0\n",
    "    for i, (x, c) in enumerate(train_loader):\n",
    "        x, c = x.cuda(), c.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _, _, idxs_R_BL, scales_BlC, _ = vqvae(x)\n",
    "        idx_BL = torch.cat(idxs_R_BL, dim=1)\n",
    "        scales_BlC = scales_BlC.cuda()\n",
    "        logits_BLV = var_model(scales_BlC, cond=c)\n",
    "        loss = F.cross_entropy(\n",
    "            logits_BLV.view(-1, logits_BLV.size(-1)), idx_BL.view(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f\"Epoch: {epoch}, Loss: {epoch_loss}\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            cond = torch.arange(10).cuda()\n",
    "            out_B3HW = var_model.generate(cond, 0)\n",
    "            plot_images(pred=out_B3HW)\n",
    "\n",
    "            plt.savefig(f\"var_{epoch}.png\")\n",
    "            plt.close()\n",
    "\n",
    "torch.save(var_model.state_dict(), \"var.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
