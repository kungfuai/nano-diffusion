{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89eeadb2",
   "metadata": {
    "papermill": {
     "duration": 0.002492,
     "end_time": "2025-01-09T03:50:17.166348",
     "exception": false,
     "start_time": "2025-01-09T03:50:17.163856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text conditioning for Flow Matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa4494",
   "metadata": {},
   "source": [
    "Similarly, we can add text conditioning to the flow matching algorithm. The modification to the training loop is small. Most of the code change is already done inside the denoising model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9371f9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T03:50:17.174510Z",
     "iopub.status.busy": "2025-01-09T03:50:17.174230Z",
     "iopub.status.idle": "2025-01-09T03:50:17.180400Z",
     "shell.execute_reply": "2025-01-09T03:50:17.180164Z"
    },
    "papermill": {
     "duration": 0.012017,
     "end_time": "2025-01-09T03:50:17.180486",
     "exception": false,
     "start_time": "2025-01-09T03:50:17.168469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f915cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T03:50:17.187757Z",
     "iopub.status.busy": "2025-01-09T03:50:17.187501Z",
     "iopub.status.idle": "2025-01-09T03:50:20.912349Z",
     "shell.execute_reply": "2025-01-09T03:50:20.912084Z"
    },
    "papermill": {
     "duration": 3.730055,
     "end_time": "2025-01-09T03:50:20.912443",
     "exception": false,
     "start_time": "2025-01-09T03:50:17.182388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 03:50:19.415450: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-09 03:50:19.428194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736394619.442354 3747064 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736394619.446563 3747064 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 03:50:19.462277: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.int = np.int32\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name: str, device: str):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = CLIPTextModel.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = CLIPTokenizer.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        # Get the text embedding dimension from the config\n",
    "        self.text_embed_dim = self.model.config.hidden_size\n",
    "\n",
    "    def forward(self, text: str) -> torch.Tensor:\n",
    "        tokens = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        return self.model(**tokens).pooler_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc5a8c",
   "metadata": {
    "papermill": {
     "duration": 0.002012,
     "end_time": "2025-01-09T03:50:20.916844",
     "exception": false,
     "start_time": "2025-01-09T03:50:20.914832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64401d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T03:50:20.949495Z",
     "iopub.status.busy": "2025-01-09T03:50:20.949193Z",
     "iopub.status.idle": "2025-01-09T03:50:21.915650Z",
     "shell.execute_reply": "2025-01-09T03:50:21.915313Z"
    },
    "papermill": {
     "duration": 0.996951,
     "end_time": "2025-01-09T03:50:21.915733",
     "exception": false,
     "start_time": "2025-01-09T03:50:20.918782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from lib_4_1.config import TrainingConfig\n",
    "from src.train_cfm import ExactOptimalTransportConditionalFlowMatcher, ConditionalFlowMatcher\n",
    "\n",
    "def train(\n",
    "    config: TrainingConfig,\n",
    "    model: nn.Module,\n",
    "    text_encoder: TextEncoder,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    steps: int=100,\n",
    "    silent: bool=False,\n",
    ") -> float:\n",
    "  device = config.device\n",
    "  # FM = ExactOptimalTransportConditionalFlowMatcher(sigma=0)\n",
    "  FM = ConditionalFlowMatcher(sigma=0)\n",
    "  \n",
    "  model.train()\n",
    "  if not silent:\n",
    "    print(\"Training on device:\", device)\n",
    "  max_train_steps = steps\n",
    "\n",
    "  loss = None\n",
    "  progress_bar = tqdm(itertools.cycle(train_dataloader), total=max_train_steps, disable=silent)\n",
    "  step = 0\n",
    "  criterion = MSELoss()\n",
    "  for batch in progress_bar:\n",
    "    x_1 = batch[0]  # x_0 is the clean image to teach the model to generate\n",
    "    text = batch[1][\"text\"]  # text is the caption of the image\n",
    "    assert len(text) == x_1.shape[0]\n",
    "    # assert the type of text is a list of strings\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Implement classifier-free guidance training\n",
    "    # Randomly drop out text conditioning with 10% probability\n",
    "    # The dropout is applied to the batch as a whole.\n",
    "    # Alternatively, we could apply it to each image in the batch.\n",
    "    text_drop_prob = 0.2\n",
    "    x_1 = x_1.to(device)\n",
    "    x_0 = torch.randn_like(x_1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_encoder(text)\n",
    "\n",
    "    t, x_t, u_t = FM.sample_location_and_conditional_flow(x0=x_0, x1=x_1)\n",
    "    # t, x_t, u_t, _, text_embeddings_t = FM.guided_sample_location_and_conditional_flow(x0=x_0, x1=x_1, y0=None, y1=text_embeddings)\n",
    "    \n",
    "    # A dropout is applied to the ``text_embeddings`` input:\n",
    "    #   This means `predicted_noise` will be computed with 20% probability of the text embeddings being dropped out.\n",
    "    #   The model learns to predict the noise both with and without the text embeddings.\n",
    "    v_t = model(t=t, x=x_t, text_embeddings=text_embeddings, p_uncond=text_drop_prob)\n",
    "\n",
    "    loss = criterion(u_t, v_t)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)  # try commenting it out\n",
    "    optimizer.step()\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    if not silent:\n",
    "      progress_bar.set_postfix({\"loss\": loss.cpu().item()})\n",
    "\n",
    "    if step >= max_train_steps:\n",
    "      break\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e434d72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T03:50:21.924087Z",
     "iopub.status.busy": "2025-01-09T03:50:21.923723Z",
     "iopub.status.idle": "2025-01-09T03:50:24.836673Z",
     "shell.execute_reply": "2025-01-09T03:50:24.836458Z"
    },
    "papermill": {
     "duration": 2.918639,
     "end_time": "2025-01-09T03:50:24.836741",
     "exception": false,
     "start_time": "2025-01-09T03:50:21.918102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 14.68 M\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from lib_4_1.data import load_data\n",
    "from lib_4_1.model import create_unet_model\n",
    "\n",
    "config = TrainingConfig(dataset=\"reese-green/afhq64_captions_64k\", caption_column=\"caption_blip2-opt-2.7b\", batch_size=16, resolution=32)\n",
    "text_encoder = TextEncoder(\"openai/clip-vit-large-patch14\", \"cuda:0\")\n",
    "text_encoder.eval()\n",
    "train_ds, val_ds = load_data(config)\n",
    "denoising_model = create_unet_model(config, config.device)\n",
    "optimizer = optim.AdamW(denoising_model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922398a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T03:50:24.843731Z",
     "iopub.status.busy": "2025-01-09T03:50:24.843471Z",
     "iopub.status.idle": "2025-01-09T03:50:24.883289Z",
     "shell.execute_reply": "2025-01-09T03:50:24.883046Z"
    },
    "papermill": {
     "duration": 0.044228,
     "end_time": "2025-01-09T03:50:24.883350",
     "exception": false,
     "start_time": "2025-01-09T03:50:24.839122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b700f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T03:50:24.889714Z",
     "iopub.status.busy": "2025-01-09T03:50:24.889453Z",
     "iopub.status.idle": "2025-01-09T04:00:08.353085Z",
     "shell.execute_reply": "2025-01-09T04:00:08.352806Z"
    },
    "papermill": {
     "duration": 583.467841,
     "end_time": "2025-01-09T04:00:08.353183",
     "exception": false,
     "start_time": "2025-01-09T03:50:24.885342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee089d4f09c41509d056f731777edba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1608, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    config=config,\n",
    "    model=denoising_model,\n",
    "    text_encoder=text_encoder,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    steps=8000,\n",
    "    silent=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d5fdc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T04:00:08.361243Z",
     "iopub.status.busy": "2025-01-09T04:00:08.360713Z",
     "iopub.status.idle": "2025-01-09T04:00:08.473120Z",
     "shell.execute_reply": "2025-01-09T04:00:08.472894Z"
    },
    "papermill": {
     "duration": 0.116889,
     "end_time": "2025-01-09T04:00:08.473178",
     "exception": false,
     "start_time": "2025-01-09T04:00:08.356289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(denoising_model.state_dict(), \"denoising_model_4_2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af1c0dd",
   "metadata": {},
   "source": [
    "In the next tutorial, we will use the trained flow matching model to generate images with text conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce8ecb",
   "metadata": {
    "papermill": {
     "duration": 0.002522,
     "end_time": "2025-01-09T04:00:08.477980",
     "exception": false,
     "start_time": "2025-01-09T04:00:08.475458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 595.318799,
   "end_time": "2025-01-09T04:00:11.795438",
   "environment_variables": {},
   "exception": null,
   "input_path": "4_2_text_conditioning_cfm.ipynb",
   "output_path": "4_2_text_conditioning_cfm.ipynb",
   "parameters": {},
   "start_time": "2025-01-09T03:50:16.476639",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2ee089d4f09c41509d056f731777edba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c36ea12562ed4879a43fdc349abfc7be",
        "IPY_MODEL_b9c05e34e17e45c98cd4cf5b6c2df416",
        "IPY_MODEL_6a16b1f91e74471d825984a4e0a433cd"
       ],
       "layout": "IPY_MODEL_895f6e8cb71945aa8555c99a056ef8eb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6a16b1f91e74471d825984a4e0a433cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d3acda833cd6400bbcaf0115f58a9679",
       "placeholder": "​",
       "style": "IPY_MODEL_f64c59fb5bae4f24b129ad8bee30f251",
       "tabbable": null,
       "tooltip": null,
       "value": " 7999/8000 [09:43&lt;00:00, 13.91it/s, loss=0.161]"
      }
     },
     "895f6e8cb71945aa8555c99a056ef8eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "999d6c883c8d4dceb087f819e015ba66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a63d7ba128c54dac89554a785a8a9392": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a9938e57cd5a46f0808a0cbbee5dba3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b9c05e34e17e45c98cd4cf5b6c2df416": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ebd91b64f5dc497eadc55975bdb82711",
       "max": 8000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a63d7ba128c54dac89554a785a8a9392",
       "tabbable": null,
       "tooltip": null,
       "value": 7999
      }
     },
     "c36ea12562ed4879a43fdc349abfc7be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_999d6c883c8d4dceb087f819e015ba66",
       "placeholder": "​",
       "style": "IPY_MODEL_a9938e57cd5a46f0808a0cbbee5dba3b",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "d3acda833cd6400bbcaf0115f58a9679": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebd91b64f5dc497eadc55975bdb82711": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f64c59fb5bae4f24b129ad8bee30f251": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
