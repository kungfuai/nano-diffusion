{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef53518",
   "metadata": {
    "papermill": {
     "duration": 0.00551,
     "end_time": "2024-12-30T22:02:04.893886",
     "exception": false,
     "start_time": "2024-12-30T22:02:04.888376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Conditioning (text2image)\n",
    "\n",
    "Conditioning means prompting. So far, we have been doing unconditional image generation from pure noise, or generation without prompting as any context information:\n",
    "\n",
    "$$\n",
    "\\textrm{noise} \\rightarrow \\textrm{image}\n",
    "$$\n",
    "\n",
    "Though it is cool to see the model generate interesting images like animal faces, it is not very useful yet as it lacks user control.\n",
    "\n",
    "In this tutorial, we will start to add text conditioning to the model:\n",
    "\n",
    "$$\n",
    "\\textrm{text} + \\textrm{noise} \\rightarrow \\textrm{image}\n",
    "$$\n",
    "\n",
    "so that a prompt like \"a black cat with lots of fur\" can actually trigger the model to follow the instruction and generate such an image.\n",
    "\n",
    "A popular approach to do text-to-Image generation is \"classifier-free guidance\". Historically, the first major technique along these lines was \"classifier guidance\", which relies on a separate classifier to steer image synthesis.\n",
    "\n",
    "Let $x$ be the image, and $y$ be the text prompt. There are 2 distributions we could sample from:\n",
    "\n",
    "- unconditional distribution $p_{\\theta}(x)$: \"what do images look like in general?\"\n",
    "- conditional distribution $p_{\\theta}(x \\mid y)$: \"what do images look like given a text prompt $y$?\"\n",
    "\n",
    "Applying the Bayes rule, we have:\n",
    "\n",
    "$$\n",
    "p_{\\theta}(x \\mid y) \\propto p_{\\theta}(x) \\cdot p_{\\theta}(y \\mid x)\n",
    "$$\n",
    "\n",
    "When we look at the gradient of the log-probability,\n",
    "\n",
    "$$\n",
    "\\nabla_{x} \\log p_{\\theta}(x \\mid y) = \\nabla_{x} \\log p_{\\theta}(x) + \\nabla_{x} \\log p_{\\theta}(y \\mid x)\n",
    "$$\n",
    "\n",
    "Note that $\\nabla_{x_t} \\log p_{\\theta}(x_t)$ is approximately the output of the denoising model (the noise prediction), up to a constant factor.\n",
    "\n",
    "Therefore, we can think of text-conditioned generation as taking the unconditional model \n",
    "and adjusting (\"tweaking\") it with $p_{\\theta}(y \\mid x)$, which is a \"classifier\" that predicts the label or text description given an image. When we add these two terms, we steer the generation toward images that are both likely under the unconditional model and consistent with the text $y$. This is the core idea behind classifier guidance.\n",
    "\n",
    "### Classifier Guidance\n",
    "\n",
    "With classifier guidance, there are 2 models:\n",
    "\n",
    "- a diffusion model trained to denoise images (learn $p_{\\theta}(x)$)\n",
    "- a separate classifier trained to predict the label or text (e.g. cat, dog, etc.) $y$ given an image $x$.\n",
    "\n",
    "During generation (the reverse diffusion process), at each step we:\n",
    "\n",
    "1. Take the partially denoised image $x_t$.\n",
    "2. Run it through the classifier to get a prediction $\\log p_{\\theta}(y \\mid x_t)$.\n",
    "3. Compute gradient of the log-probability $\\nabla_{\\theta} \\log p_{\\theta}(y \\mid x_t)$ that tells us how to tweak $x_t$ to be more consistent with the label $y$.\n",
    "4. Mix this gradient into the diffusion modelâ€™s own prediction to push the sample toward matching $y$.\n",
    "\n",
    "If $y$ is \"a cat sitting on a mat,\" the classifier $p_{\\theta}(y \\mid x_t)$ evaluates the likelihood of $x_t$ matching this description. The guidance term $\\nabla_{x} \\log p_{\\theta}(y \\mid x_t)$ nudges the model to refine samples towards features of a cat on a mat, while $\\nabla_{x} \\log p_{\\theta}(x)$ ensures the output remains realistic and coherent as an image.\n",
    "\n",
    "While it works, it requires training or fine-tuning a separate classifier that can handle noisy intermediate images. Usually the classifier is tied to specific labels or tasks, which limits its flexibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d64a26",
   "metadata": {},
   "source": [
    "\n",
    "### Classifier-Free Guidance\n",
    "\n",
    "Can we get the benefits of classifier guidance (steering images toward a text prompt) without needing a separate classifier? It turns out a clever trick can do this.\n",
    "\n",
    "The key idea is to train a single model that has two modes:\n",
    "\n",
    "- Conditional mode: Model sees the text prompt $y$.\n",
    "- Unconditional mode: Model receives a null or \"empty\" prompt.\n",
    "\n",
    "#### During Training\n",
    "\n",
    "We train **the same diffusion model** to handle both modes by randomly \"dropping out\" the text prompt some fraction of the time during training. This is so that we have a model is able to output both the unconditional noise prediction $\\epsilon_{\\theta}(x_t, t, \\emptyset)$ and the conditional noise prediction $\\epsilon_{\\theta}(x_t, t, y)$, where $y$ is the text prompt and $\\emptyset$ is the null text prompt.\n",
    "\n",
    "#### During Generation\n",
    "\n",
    "At each reverse diffusion step, we make two predictions:\n",
    "\n",
    "1. Unconditional noise prediction $\\mathbf\\epsilon_{\\theta}(x_t, t, \\emptyset)$ using the null text prompt $\\emptyset$. $t$ is the denoising time step.\n",
    "2. Conditional noise prediction: $\\mathbf\\epsilon_{\\theta}(x_t, t, y)$ using real text prompt $y$.\n",
    "\n",
    "We then mix them:\n",
    "\n",
    "$$\n",
    "\\mathbf\\epsilon = \\mathbf\\epsilon_{\\theta}(x_t, t, \\emptyset) + s \\cdot (\\mathbf\\epsilon_{\\theta}(x_t, t, y) - \\mathbf\\epsilon_{\\theta}(x_t, t, \\emptyset))\n",
    "$$\n",
    "\n",
    "where $s$ is the guidance scale that controls how strongly the final output is \"pushed\" toward matching the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d268d",
   "metadata": {
    "papermill": {
     "duration": 0.004564,
     "end_time": "2024-12-30T22:02:04.912668",
     "exception": false,
     "start_time": "2024-12-30T22:02:04.908104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Architecture Design choices for Text Conditioning\n",
    "\n",
    "Similar to the 2D point clouds, we are interested to experiment with different model architectures. Specifically for text conditioning (combining information from text and image), 3 approaches are in consideration:\n",
    "\n",
    "- Linear modulation\n",
    "    - Scale and shift other embeddings or intermediate representations based on the text embedding\n",
    "    - Can apply to time embedding, intermediate representations, or normalization layers.\n",
    "- Concatenation\n",
    "    - Concatenate the text embedding with other embeddings.\n",
    "- Cross attention\n",
    "    - Use the intermediate representations as queries to attend to the text embedding.\n",
    "\n",
    "The implementation also depends on whether we use the UNet or Transformer backbone. Let's focus from UNet and linear modulation. The modulation can be done by simply adding the text embedding to the time embedding:\n",
    "\n",
    "```diff\n",
    "# In UNetModel.__init__():\n",
    "+ self.text_proj = nn.Sequential(\n",
    "+                 linear(text_embed_dim, time_embed_dim),\n",
    "+                 nn.SiLU(),\n",
    "+                 linear(time_embed_dim, time_embed_dim),\n",
    "+             )\n",
    "...\n",
    "\n",
    "# In forward():\n",
    "emb = self.time_embed(timestep_embedding(t, self.model_channels))\n",
    "+ emb = emb + self.text_proj(text_embeddings)  # add the text embedding to the time embedding\n",
    "```\n",
    "\n",
    "Then both the time+text embedding `emb` and the intermediate hidden representations `h` passes through the regular UNet blocks (no changes to following UNet blocks):\n",
    "\n",
    "```python\n",
    "for module in self.input_blocks:\n",
    "    h = module(h, emb)\n",
    "    hs.append(h)\n",
    "h = self.middle_block(h, emb)\n",
    "for module in self.output_blocks:\n",
    "    h = th.cat([h, hs.pop()], dim=1)\n",
    "    h = module(h, emb)\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543b09d",
   "metadata": {},
   "source": [
    "### Text embedding \"dropout\"\n",
    "\n",
    "The recipe for classifier-free guidance requires us to randomly drop the text embedding some fraction of the time during training. This way we train a single model that can operates in both unconditional and conditional modes.\n",
    "\n",
    "When computing the training loss in the forward pass, we need to randomly drop the text embedding some fraction of the time:\n",
    "\n",
    "```diff\n",
    "# In forward() of the denoising model (UNetModel), do the dropout randomly based on the `p_uncond` parameter:\n",
    "# If p_uncond is 0.2, then 20% of the time we drop out the text embedding.\n",
    "+ unconditional_mask = (th.rand(text_embeddings.shape[0]) < p_uncond)  # this gets the indices of the texts that we want to drop out\n",
    "+ text_embeddings[unconditional_mask] = self.null_text_embed  # this sets the text embeddings to the null text embedding\n",
    "```\n",
    "\n",
    "And the `null_text_embed` is a learnable embedding for the null text prompt:\n",
    "\n",
    "```diff\n",
    "# In UNetModel.__init__():\n",
    "+ self.text_embed_dim = text_embed_dim\n",
    "+ self.null_text_embed = nn.Parameter(th.randn(1, text_embed_dim) * 0.02)\n",
    "```\n",
    "\n",
    "This way the model learns what the null text embedding means in the latent space. An alternative is simply setting `null_text_embed` to all zeros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee839440",
   "metadata": {},
   "source": [
    "## Text Encoder\n",
    "\n",
    "To produce the text embedding, we can use a pre-trained CLIP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c335045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:02:04.923392Z",
     "iopub.status.busy": "2024-12-30T22:02:04.922869Z",
     "iopub.status.idle": "2024-12-30T22:02:09.137977Z",
     "shell.execute_reply": "2024-12-30T22:02:09.137545Z"
    },
    "papermill": {
     "duration": 4.221995,
     "end_time": "2024-12-30T22:02:09.139270",
     "exception": false,
     "start_time": "2024-12-30T22:02:04.917275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 22:02:07.609824: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-30 22:02:07.622932: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-30 22:02:07.637863: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-30 22:02:07.642424: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-30 22:02:07.653395: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 22:02:08.358540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name: str, device: str):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.model = CLIPTextModel.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = CLIPTokenizer.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        # Get the text embedding dimension from the config\n",
    "        self.text_embed_dim = self.model.config.hidden_size\n",
    "\n",
    "    def forward(self, text: str) -> torch.Tensor:\n",
    "        tokens = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        return self.model(**tokens).pooler_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771b9fa",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now that the denoising model can handle text embeddings as an additional input, we also need to modify the training step to pass in the text embeddings. The main logic remains the same.\n",
    "\n",
    "### Classifier-Free Guidance in Training: Text Dropout\n",
    "\n",
    "With 20% of chance, the text embedding will be set to an empty embedding. The actual logic of dropout happens inside the denoising model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fa1857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:02:09.150110Z",
     "iopub.status.busy": "2024-12-30T22:02:09.149671Z",
     "iopub.status.idle": "2024-12-30T22:02:09.157619Z",
     "shell.execute_reply": "2024-12-30T22:02:09.157221Z"
    },
    "papermill": {
     "duration": 0.01422,
     "end_time": "2024-12-30T22:02:09.158390",
     "exception": false,
     "start_time": "2024-12-30T22:02:09.144170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "from lib_4_1.diffusion import forward_diffusion\n",
    "from lib_4_1.bookkeeping import Bookkeeping\n",
    "from lib_4_1.config import TrainingConfig\n",
    "\n",
    "def train(\n",
    "    config: TrainingConfig,\n",
    "    model: nn.Module,\n",
    "    text_encoder: TextEncoder,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "    noise_schedule: Dict,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    steps: int=100,\n",
    "    silent: bool=False,\n",
    "    bookkeeping: Bookkeeping=None\n",
    ") -> float:\n",
    "  device = config.device\n",
    "  num_denoising_steps = config.num_denoising_steps\n",
    "  \n",
    "  model.train()\n",
    "  if not silent:\n",
    "    print(\"Training on device:\", device)\n",
    "  max_train_steps = steps\n",
    "\n",
    "  loss = None\n",
    "  progress_bar = tqdm(itertools.cycle(train_dataloader), total=max_train_steps, disable=silent)\n",
    "  step = 0\n",
    "  criterion = MSELoss()\n",
    "  for batch in progress_bar:\n",
    "    x_0 = batch[0]  # x_0 is the clean image to teach the model to generate\n",
    "    text = batch[1][\"text\"]  # text is the caption of the image\n",
    "    assert len(text) == x_0.shape[0]\n",
    "    # assert the type of text is a list of strings\n",
    "    x_0 = x_0.float().to(device)  # x_0 is the clean data to teach the model to generate\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Implement classifier-free guidance training\n",
    "    # Randomly drop out text conditioning with 10% probability\n",
    "    # The dropout is applied to the batch as a whole.\n",
    "    # Alternatively, we could apply it to each image in the batch.\n",
    "    text_drop_prob = 0.2\n",
    "    true_noise = common_noise = torch.randn(x_0.shape).to(device)\n",
    "    t = torch.randint(0, num_denoising_steps, (x_0.shape[0],), device=device).long()\n",
    "    x_t, _ = forward_diffusion(x_0, t, noise_schedule, noise=common_noise)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_encoder(text)\n",
    "\n",
    "    # A dropout is applied to the ``text_embeddings`` input:\n",
    "    #   This means `predicted_noise` will be computed with 20% probability of the text embeddings being dropped out.\n",
    "    #   The model learns to predict the noise both with and without the text embeddings.\n",
    "    predicted_noise = model(t=t, x=x_t, text_embeddings=text_embeddings, p_uncond=text_drop_prob)\n",
    "\n",
    "    loss = criterion(predicted_noise, true_noise)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)  # try commenting it out\n",
    "    optimizer.step()\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    if not silent:\n",
    "      progress_bar.set_postfix({\"loss\": loss.cpu().item()})\n",
    "\n",
    "    if bookkeeping:\n",
    "      bookkeeping.run_callbacks(config=config, step=step, loss=loss, optimizer=optimizer, val_dataloader=val_dataloader)\n",
    "\n",
    "    if step >= max_train_steps:\n",
    "      break\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f239f",
   "metadata": {},
   "source": [
    "### Captioned Image Dataset and Text Encoder\n",
    "\n",
    "Let's create the main components of the model. Its has under 15M parameters, rather small.\n",
    "\n",
    "For text encoder, we are using CLIP.\n",
    "\n",
    "For the dataset of image-text pairs, we will use the dataset `reese-green/afhq64_captions_64k` generated by running the `blip2-opt-2.7b` model on the animal face images to extract the text description of the image. Here, we use a resolution of 32x32 pixels to make training faster.\n",
    "\n",
    "A good dataset is important for the performance of the model. To learn more about how to create a captioned image dataset, please refer to [this tutorial](Image%20Captioning%20Lesson.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54084219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:02:09.168447Z",
     "iopub.status.busy": "2024-12-30T22:02:09.168140Z",
     "iopub.status.idle": "2024-12-30T22:02:11.836651Z",
     "shell.execute_reply": "2024-12-30T22:02:11.836221Z"
    },
    "papermill": {
     "duration": 2.674574,
     "end_time": "2024-12-30T22:02:11.837530",
     "exception": false,
     "start_time": "2024-12-30T22:02:09.162956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 14.68 M\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from lib_4_1.data import load_data\n",
    "from lib_4_1.model import create_unet_model\n",
    "from lib_4_1.diffusion import create_noise_schedule\n",
    "\n",
    "config = TrainingConfig(dataset=\"reese-green/afhq64_captions_64k\", caption_column=\"caption_blip2-opt-2.7b\", batch_size=16, resolution=32)\n",
    "text_encoder = TextEncoder(\"openai/clip-vit-large-patch14\", \"cuda:0\")\n",
    "text_encoder.eval()\n",
    "train_ds, val_ds = load_data(config)\n",
    "noise_schedule = create_noise_schedule(n_T=config.num_denoising_steps, device=config.device)\n",
    "denoising_model = create_unet_model(config, config.device)\n",
    "optimizer = optim.AdamW(denoising_model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2703a",
   "metadata": {},
   "source": [
    "### A Quick Data Check\n",
    "\n",
    "A quick check that the inputs and targets of a training example look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814eccc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:02:11.848593Z",
     "iopub.status.busy": "2024-12-30T22:02:11.848119Z",
     "iopub.status.idle": "2024-12-30T22:02:11.852282Z",
     "shell.execute_reply": "2024-12-30T22:02:11.851916Z"
    },
    "papermill": {
     "duration": 0.010402,
     "end_time": "2024-12-30T22:02:11.853026",
     "exception": false,
     "start_time": "2024-12-30T22:02:11.842624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "{'label': 0, 'text': 'a large white dog with brown eyes sitting on the grass'}\n"
     ]
    }
   ],
   "source": [
    "for x in train_ds:\n",
    "    print(x[0].shape)\n",
    "    print(x[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882781d",
   "metadata": {},
   "source": [
    "Similarly, check to see if the mini-batch look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bfbbcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:02:11.863504Z",
     "iopub.status.busy": "2024-12-30T22:02:11.863236Z",
     "iopub.status.idle": "2024-12-30T22:02:12.249841Z",
     "shell.execute_reply": "2024-12-30T22:02:12.249410Z"
    },
    "papermill": {
     "duration": 0.392913,
     "end_time": "2024-12-30T22:02:12.250718",
     "exception": false,
     "start_time": "2024-12-30T22:02:11.857805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "['a gray cat with green eyes sitting on a table', 'a close up of a cat with a sad expression', 'a black cat with green eyes standing in front of a fence', 'a gray and white dog with an orange collar', 'a gray cat is sitting on a red blanket', 'a leopard walking through the grass in the wild', 'a white dog with its tongue out and its tongue hanging out', 'a cheetah with its tongue out in the grass', 'a gray and white cat laying on a couch', 'a black french bulldog sitting down with his ears up', 'a brown dog running on the ground', 'a cat is sitting on a branch with green leaves', 'a small black and white dog wearing a purple harness', 'a white dog with a collar on sitting on a bed', 'a lion cub is sitting in a zoo enclosure', 'a golden retriever sitting on a bench with its owner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 768])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False)\n",
    "for x in train_dataloader:\n",
    "    print(x[0].shape)\n",
    "    print(x[1][\"text\"])\n",
    "    text_embeddings = text_encoder(x[1][\"text\"])\n",
    "    print(text_embeddings.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0090bc",
   "metadata": {},
   "source": [
    "### We Train\n",
    "\n",
    "We train 20,000 steps. This can take 20~30 minutes on a A10 instance on Lambda Labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e286c632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:02:12.261985Z",
     "iopub.status.busy": "2024-12-30T22:02:12.261585Z",
     "iopub.status.idle": "2024-12-30T22:41:37.430563Z",
     "shell.execute_reply": "2024-12-30T22:41:37.430152Z"
    },
    "papermill": {
     "duration": 2365.175549,
     "end_time": "2024-12-30T22:41:37.431455",
     "exception": false,
     "start_time": "2024-12-30T22:02:12.255906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0001ff545d347f49b3b31bc6ea96da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    config=config,\n",
    "    model=denoising_model,\n",
    "    text_encoder=text_encoder,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    noise_schedule=noise_schedule,\n",
    "    optimizer=optimizer,\n",
    "    steps=20000,\n",
    "    silent=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af59d3",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "\n",
    "The checkpoint will be useful in the next tutorial, where we see our model it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7177d292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T22:41:37.442799Z",
     "iopub.status.busy": "2024-12-30T22:41:37.442472Z",
     "iopub.status.idle": "2024-12-30T22:41:37.544670Z",
     "shell.execute_reply": "2024-12-30T22:41:37.544230Z"
    },
    "papermill": {
     "duration": 0.109173,
     "end_time": "2024-12-30T22:41:37.545906",
     "exception": false,
     "start_time": "2024-12-30T22:41:37.436733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(denoising_model.state_dict(), \"denoising_model_4_1.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f779999",
   "metadata": {
    "papermill": {
     "duration": 0.005093,
     "end_time": "2024-12-30T22:41:37.585962",
     "exception": false,
     "start_time": "2024-12-30T22:41:37.580869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate images with text conditioning\n",
    "\n",
    "In the next tutorial, we will use the updated sampling code to generate images with text conditioning. By varying the `guidance_scale` parameter, we can see how the text conditioning affects the generated images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2429.471954,
   "end_time": "2024-12-30T22:42:33.686770",
   "environment_variables": {},
   "exception": null,
   "input_path": "4_1_text_conditioning.ipynb",
   "output_path": "4_1_text_conditioning.ipynb",
   "parameters": {},
   "start_time": "2024-12-30T22:02:04.214816",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0181919350934cae9b7d33fadd5469e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a21f79b84764fcaac9096fe29d5a64b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "14b71ca81fbf4c399ff59356f7d0506c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1dd54616408640d198208efbf9adf1c4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e6135d29e4d146438386a9f81869010b",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1000/1000â€‡[00:27&lt;00:00,â€‡37.06it/s,â€‡std=0.482]"
      }
     },
     "1dd54616408640d198208efbf9adf1c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20833c93be1f4cbca6aa279c84f16697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2919fc9d804e475a944a89d606f2a352": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78370056fbb646f089ba670c9600f59e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f9c343ddebee4719b6016c3b3af12429",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡19999/20000â€‡[39:25&lt;00:00,â€‡â€‡9.37it/s,â€‡loss=0.0426]"
      }
     },
     "338230f290c949e4a0ce7d9f6bdfaa6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "37a559e7d1684bb78b01aac014a152a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf413ee0b12e42439bdcaaec195cb98c",
        "IPY_MODEL_d2fcd1a4b9fe47f99ab3d54a7b28bf0f",
        "IPY_MODEL_14b71ca81fbf4c399ff59356f7d0506c"
       ],
       "layout": "IPY_MODEL_cc9d22e17000479daf1fed95291b429f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "37dde65475714a48812888ee8af62e2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3c379b43ba6845af9e0a634aa4f5c751": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ea5982ea568447dba0c2911cd5b0ad5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68f1f5ca2c9d4f0db53ff9a7e6c64fc1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78370056fbb646f089ba670c9600f59e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "875a2df22a7a41e2b70b98c7fd0bfd6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8af98e660e1e4e3ba5fa2a2ef572cd13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "94b088cef5f440568104d62591006202": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff477848c8c34557875c9ad2eea61c1b",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_37dde65475714a48812888ee8af62e2b",
       "tabbable": null,
       "tooltip": null,
       "value": 1000
      }
     },
     "9f5ef060da794c0a998366c18540677c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_875a2df22a7a41e2b70b98c7fd0bfd6d",
       "max": 20000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8af98e660e1e4e3ba5fa2a2ef572cd13",
       "tabbable": null,
       "tooltip": null,
       "value": 19999
      }
     },
     "a1fc476c922b4accbca6771f47a30fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0181919350934cae9b7d33fadd5469e9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_20833c93be1f4cbca6aa279c84f16697",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "b0de37de80ce4e84a3afd793089df2e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb4b842ad9fa463da5767e5d87636851": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf413ee0b12e42439bdcaaec195cb98c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fbc0dc888c2b48559d4c743f79b94f9a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3c379b43ba6845af9e0a634aa4f5c751",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "c0591cab0cdc495e9df3b8d2f7a91863": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ea5982ea568447dba0c2911cd5b0ad5",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_338230f290c949e4a0ce7d9f6bdfaa6c",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1000/1000â€‡[00:26&lt;00:00,â€‡37.55it/s,â€‡std=0.579]"
      }
     },
     "cc9d22e17000479daf1fed95291b429f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2fcd1a4b9fe47f99ab3d54a7b28bf0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b0de37de80ce4e84a3afd793089df2e6",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a21f79b84764fcaac9096fe29d5a64b",
       "tabbable": null,
       "tooltip": null,
       "value": 1000
      }
     },
     "e6135d29e4d146438386a9f81869010b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e8776afcfd114d5eb20e7e53b5ea161d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68f1f5ca2c9d4f0db53ff9a7e6c64fc1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ea87b4bf7d6044dcbdf0564e0617fe8c",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "ea87b4bf7d6044dcbdf0564e0617fe8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f0001ff545d347f49b3b31bc6ea96da7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e8776afcfd114d5eb20e7e53b5ea161d",
        "IPY_MODEL_9f5ef060da794c0a998366c18540677c",
        "IPY_MODEL_2919fc9d804e475a944a89d606f2a352"
       ],
       "layout": "IPY_MODEL_f54c68529c0d437f8de37c6ab6b50d75",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f54c68529c0d437f8de37c6ab6b50d75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9c343ddebee4719b6016c3b3af12429": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f9e290853a454b5ca348bf44f71189a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a1fc476c922b4accbca6771f47a30fc7",
        "IPY_MODEL_94b088cef5f440568104d62591006202",
        "IPY_MODEL_c0591cab0cdc495e9df3b8d2f7a91863"
       ],
       "layout": "IPY_MODEL_bb4b842ad9fa463da5767e5d87636851",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fbc0dc888c2b48559d4c743f79b94f9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff477848c8c34557875c9ad2eea61c1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
