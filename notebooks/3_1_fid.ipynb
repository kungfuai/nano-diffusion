{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality evaluation of an image generation model\n",
    "\n",
    "(under construction)\n",
    "\n",
    "## FID\n",
    "\n",
    "The Chamfer distance that we used in the previous notebook is a distance between point clouds. It is based on Euclidean distance, which works for low-dimensional data such as 2D points. For high-dimensional data such as images, the Euclidean distance is not a good measure, because the distance between two images can be high even if they are very similar.\n",
    "\n",
    "The Fréchet Inception Distance (FID) is a metric that measures the distance between two distributions of images. A lower score means better quality. It is based on the Fréchet distance, which is a distance between Gaussian distributions. \"Inception\" here refers to a pre-trained Inception-v3 model, which is a convolutional neural network that was trained to classify images into 1000 categories. We can use the intermediate features of this model to measure the distance between two distributions of images.\n",
    "\n",
    "The limitations of FID include:\n",
    "- It assumes Gaussian distribution of features.\n",
    "- It is sensitive to sample size and requires large sample sizes for stable estimates, which means it is computationally expensive.\n",
    "\n",
    "Other metrics include:\n",
    "- Inception Score (IS): measures both the diversity and quality of generated images. It may give misleading scores for specialized datasets (e.g., medical images, abstract art).\n",
    "- LPIPS (Learned Perceptual Image Patch Similarity). It is good at measureing individual image quality, and more suitable for tasks like style transfer, image reconstruction.\n",
    "- PSNR (Peak Signal-to-Noise Ratio). It measures pixel-level reconstruction quality,and does not measure perceptual quality.\n",
    "- SSIM (Structural Similarity Index). It measures image quality based on luminance and contrast, and does not measure perceptual quality.\n",
    "- Arena-style human evaluation: compare generated images from different models side by side, and ask human experts to choose the better one.\n",
    "\n",
    "We are going to use the package`clean-fid`. As a santity check for the metric, let's take a pre-trained model from huggingface with known good quality, and see what the FID score looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
