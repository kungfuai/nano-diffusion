{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from nanodiffusion.config.diffusion_training_config import DiffusionTrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DiffusionTrainingConfig(\n",
    "    dataset=\"valhalla/emoji-dataset\",  # 256x256 is the original resolution\n",
    "    caption_column=\"text\",\n",
    "    # Conditioning\n",
    "    conditional=False,\n",
    "    cond_embed_dim=768,\n",
    "    cond_drop_prob=0.2,\n",
    "    guidance_scale=4.5,\n",
    "    # Model\n",
    "    net=\"unet\",\n",
    "    # Training loop\n",
    "    batch_size=128,\n",
    "    resolution=64,  # resize to 64x64\n",
    "    logger=\"wandb\",  # None,\n",
    "    sample_every=1000,\n",
    "    validate_every=1000,\n",
    "    fid_every=-1,  # disable FID logging\n",
    "    total_steps=100000,\n",
    "    num_samples_for_logging=8,\n",
    "    num_samples_for_fid=1000,\n",
    "    num_real_samples_for_fid=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add text embeddings to the dataset and cache them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from nanodiffusion.models.text_encoder import TextEncoder\n",
    "\n",
    "\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "text_encoder = TextEncoder(\"openai/clip-vit-large-patch14\", device=\"cuda:0\")\n",
    "text_encoder.eval()\n",
    "def get_text_embeddings(text: str):\n",
    "    with torch.no_grad():\n",
    "        return text_encoder([text])[0]\n",
    "\n",
    "for split in [\"train\"]:\n",
    "    dst_path = f\"data/emoji_w_text_emb_{split}\"\n",
    "    if os.path.exists(dst_path):\n",
    "        continue\n",
    "    captioned_emoji_train = load_dataset(\"valhalla/emoji-dataset\", split=split)\n",
    "    captioned_emoji_train_w_text_emb = captioned_emoji_train.map(\n",
    "        lambda x: {\n",
    "            \"text\": x[\"text\"],\n",
    "            \"text_emb\": get_text_embeddings(x[\"text\"]),\n",
    "            \"image\": x[\"image\"].resize((config.resolution, config.resolution))\n",
    "        },\n",
    "        batched=False,\n",
    "    )\n",
    "    # save to disk\n",
    "    captioned_emoji_train_w_text_emb.save_to_disk(dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "ds = load_from_disk(\"data/emoji_w_text_emb_train\")\n",
    "# Normalize image pixels\n",
    "# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "normalize_op = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "normalize_img = lambda x: {\"image\": normalize_op(x[\"image\"]).float(), \n",
    "                      \"text\": x[\"text\"],\n",
    "                      \"text_emb\": x[\"text_emb\"]}\n",
    "\n",
    "# randomly shuffle and split into train and val\n",
    "ds = ds.map(normalize_img).with_format(\"torch\")\n",
    "ds = ds.shuffle()\n",
    "ds_train = ds.select(range(int(len(ds) * 0.8)))\n",
    "ds_val = ds.select(range(int(len(ds) * 0.2)))\n",
    "\n",
    "# create dataloader\n",
    "train_loader = DataLoader(ds_train, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(ds_val, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 0.9922,  0.9843,  0.9843,  ...,  0.8980,  1.0000,  1.0000],\n",
       "           [ 1.0000,  0.9922,  0.9843,  ...,  0.9843,  0.9686,  0.9686],\n",
       "           [ 1.0000,  1.0000,  0.9922,  ...,  0.9529,  0.9529,  0.9529]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  0.8824,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  0.8588,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0000,  1.0000,  1.0000,  ...,  0.9843,  0.9843,  0.9843],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  0.9843,  0.9843,  0.9843],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  0.9843,  0.9843,  0.9843],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 0.5373, -0.4824, -0.4667,  ..., -0.5529, -0.4980,  0.6941],\n",
       "           [ 0.4980, -0.5059, -0.4824,  ..., -0.5373, -0.5373, -0.0980],\n",
       "           [-0.2235, -0.4980, -0.4824,  ..., -0.5216, -0.5216, -0.5686]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 0.4510, -0.7804, -0.7725,  ..., -0.7647, -0.6784,  0.6863],\n",
       "           [ 0.4196, -0.8275, -0.7882,  ..., -0.7490, -0.7333, -0.1922],\n",
       "           [-0.4510, -0.8039, -0.7882,  ..., -0.7412, -0.7255, -0.7804]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 0.6000, -0.3098, -0.3020,  ..., -0.3725, -0.3882,  0.7412],\n",
       "           [ 0.5765, -0.3412, -0.3098,  ..., -0.3412, -0.3804,  0.0275],\n",
       "           [-0.0510, -0.3176, -0.3098,  ..., -0.3098, -0.3333, -0.4196]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0000,  1.0000,  0.9843,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  0.9843,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  0.9922,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "          [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           ...,\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "           [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]]]),\n",
       " 'text': ['speedboat',\n",
       "  'merman light skin tone',\n",
       "  'man superhero medium light skin tone',\n",
       "  'female technologist type 6',\n",
       "  'man doing cartwheel type 6',\n",
       "  'female judge',\n",
       "  'male guard',\n",
       "  'information desk person',\n",
       "  'flag for san marino',\n",
       "  'coconut',\n",
       "  'mother christmas',\n",
       "  'pregnant woman',\n",
       "  'clock face nine thirty',\n",
       "  'man swimming',\n",
       "  'carousel horse',\n",
       "  'skull'],\n",
       " 'text_emb': tensor([[ 1.2169,  0.1448,  0.4831,  ..., -1.3956,  0.2159, -0.6084],\n",
       "         [-0.2782, -1.3833,  0.3981,  ..., -1.3548,  0.6298, -1.1570],\n",
       "         [-0.5081, -0.9513,  0.5431,  ..., -1.8470,  0.4317, -0.2616],\n",
       "         ...,\n",
       "         [-1.1382, -0.7428, -0.3356,  ..., -0.3461, -0.3641,  0.0070],\n",
       "         [-1.7759,  0.6317,  0.6745,  ..., -0.5598,  0.7400, -1.2065],\n",
       "         [-1.4814, -0.2856, -0.4493,  ..., -0.5833, -0.3302, -0.0858]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model unet with resolution 64 and in_channels 3 and cond_embed_dim 768\n",
      "model params: 33.11 M\n"
     ]
    }
   ],
   "source": [
    "from nanodiffusion.diffusion.diffusion_model_components import create_diffusion_model_components\n",
    "\n",
    "model_components = create_diffusion_model_components(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "Creating checkpoint directory: logs/train/2025-04-15_16-37-39\n",
      "Setting up logger: wandb\n",
      "Logging to Weights & Biases project: nano-diffusion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5bg4aa8z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43a4ee858cc44ddbaa98532b0a3f976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='126.542 MB of 126.542 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██████████</td></tr><tr><td>loss</td><td>███▇▆▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>num_batches_trained</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>num_examples_trained</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>test_samples_step</td><td>▁█</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>loss</td><td>0.03747</td></tr><tr><td>num_batches_trained</td><td>1400</td></tr><tr><td>num_examples_trained</td><td>179328</td></tr><tr><td>test_samples_step</td><td>1000</td></tr><tr><td>val_loss</td><td>0.03146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">snowy-frog-206</strong> at: <a href='https://wandb.ai/zzsi_kungfu/nano-diffusion/runs/5bg4aa8z' target=\"_blank\">https://wandb.ai/zzsi_kungfu/nano-diffusion/runs/5bg4aa8z</a><br/> View project at: <a href='https://wandb.ai/zzsi_kungfu/nano-diffusion' target=\"_blank\">https://wandb.ai/zzsi_kungfu/nano-diffusion</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_163044-5bg4aa8z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5bg4aa8z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/zz/nano-diffusion/notebooks/wandb/run-20250415_163741-zvbvsjr6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zzsi_kungfu/nano-diffusion/runs/zvbvsjr6' target=\"_blank\">pious-plant-207</a></strong> to <a href='https://wandb.ai/zzsi_kungfu/nano-diffusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zzsi_kungfu/nano-diffusion' target=\"_blank\">https://wandb.ai/zzsi_kungfu/nano-diffusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zzsi_kungfu/nano-diffusion/runs/zvbvsjr6' target=\"_blank\">https://wandb.ai/zzsi_kungfu/nano-diffusion/runs/zvbvsjr6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Examples: 128, Loss: 0.9972, LR: 0.000000\n",
      "Sampling a torch.Size([8, 3, 64, 64]) array in 1000 steps. Initial avg: -0.0024878503754734993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.61it/s, std=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at logs/train/2025-04-15_16-37-39/model_checkpoint_step_0.pth\n",
      "Step: 50, Examples: 6528, Loss: 0.9923, LR: 0.000005\n",
      "Step: 100, Examples: 12928, Loss: 0.9566, LR: 0.000010\n",
      "Step: 150, Examples: 19328, Loss: 0.8870, LR: 0.000015\n",
      "Step: 200, Examples: 25728, Loss: 0.7636, LR: 0.000020\n",
      "Step: 250, Examples: 32128, Loss: 0.6393, LR: 0.000025\n",
      "Step: 300, Examples: 38528, Loss: 0.5131, LR: 0.000030\n",
      "Step: 350, Examples: 44928, Loss: 0.3998, LR: 0.000035\n",
      "Step: 400, Examples: 51328, Loss: 0.3162, LR: 0.000040\n",
      "Step: 450, Examples: 57728, Loss: 0.2282, LR: 0.000045\n",
      "Step: 500, Examples: 64128, Loss: 0.1461, LR: 0.000050\n",
      "Step: 550, Examples: 70528, Loss: 0.0916, LR: 0.000055\n",
      "Step: 600, Examples: 76928, Loss: 0.0680, LR: 0.000060\n",
      "Step: 650, Examples: 83328, Loss: 0.0468, LR: 0.000065\n",
      "Step: 700, Examples: 89728, Loss: 0.0412, LR: 0.000070\n",
      "Step: 750, Examples: 96128, Loss: 0.0564, LR: 0.000075\n",
      "Step: 800, Examples: 102528, Loss: 0.0238, LR: 0.000080\n",
      "Step: 850, Examples: 108928, Loss: 0.0476, LR: 0.000085\n",
      "Step: 900, Examples: 115328, Loss: 0.0264, LR: 0.000090\n",
      "Step: 950, Examples: 121728, Loss: 0.0310, LR: 0.000095\n",
      "Step: 1000, Examples: 128128, Loss: 0.0129, LR: 0.000100\n",
      "Sampling a torch.Size([8, 3, 64, 64]) array in 1000 steps. Initial avg: -0.0024878503754734993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.42it/s, std=0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1050, Examples: 134528, Loss: 0.0219, LR: 0.000100\n",
      "Step: 1100, Examples: 140928, Loss: 0.0357, LR: 0.000100\n",
      "Step: 1150, Examples: 147328, Loss: 0.0672, LR: 0.000100\n",
      "Step: 1200, Examples: 153728, Loss: 0.0329, LR: 0.000100\n",
      "Step: 1250, Examples: 160128, Loss: 0.0244, LR: 0.000100\n",
      "Step: 1300, Examples: 166528, Loss: 0.0143, LR: 0.000100\n",
      "Step: 1350, Examples: 172928, Loss: 0.0178, LR: 0.000100\n",
      "Step: 1400, Examples: 179328, Loss: 0.0160, LR: 0.000100\n",
      "Step: 1450, Examples: 185728, Loss: 0.0282, LR: 0.000100\n",
      "Step: 1500, Examples: 192128, Loss: 0.0147, LR: 0.000100\n",
      "Step: 1550, Examples: 198528, Loss: 0.0355, LR: 0.000100\n",
      "Step: 1600, Examples: 204928, Loss: 0.0219, LR: 0.000100\n",
      "Step: 1650, Examples: 211328, Loss: 0.0159, LR: 0.000100\n",
      "Step: 1700, Examples: 217728, Loss: 0.0219, LR: 0.000100\n",
      "Step: 1750, Examples: 224128, Loss: 0.0255, LR: 0.000100\n",
      "Step: 1800, Examples: 230528, Loss: 0.0347, LR: 0.000100\n",
      "Step: 1850, Examples: 236928, Loss: 0.0235, LR: 0.000100\n",
      "Step: 1900, Examples: 243328, Loss: 0.0135, LR: 0.000100\n",
      "Step: 1950, Examples: 249728, Loss: 0.0161, LR: 0.000100\n",
      "Step: 2000, Examples: 256128, Loss: 0.0085, LR: 0.000100\n",
      "Sampling a torch.Size([8, 3, 64, 64]) array in 1000 steps. Initial avg: -0.0024878503754734993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.57it/s, std=0.679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2050, Examples: 262528, Loss: 0.0145, LR: 0.000100\n",
      "Step: 2100, Examples: 268928, Loss: 0.0523, LR: 0.000100\n",
      "Step: 2150, Examples: 275328, Loss: 0.0459, LR: 0.000100\n",
      "Step: 2200, Examples: 281728, Loss: 0.0178, LR: 0.000100\n",
      "Step: 2250, Examples: 288128, Loss: 0.0230, LR: 0.000100\n",
      "Step: 2300, Examples: 294528, Loss: 0.0101, LR: 0.000100\n",
      "Step: 2350, Examples: 300928, Loss: 0.0243, LR: 0.000100\n",
      "Step: 2400, Examples: 307328, Loss: 0.0118, LR: 0.000100\n",
      "Step: 2450, Examples: 313728, Loss: 0.0142, LR: 0.000100\n",
      "Step: 2500, Examples: 320128, Loss: 0.0169, LR: 0.000100\n",
      "Step: 2550, Examples: 326528, Loss: 0.0355, LR: 0.000100\n",
      "Step: 2600, Examples: 332928, Loss: 0.0181, LR: 0.000100\n",
      "Step: 2650, Examples: 339328, Loss: 0.0241, LR: 0.000100\n",
      "Step: 2700, Examples: 345728, Loss: 0.0176, LR: 0.000100\n",
      "Step: 2750, Examples: 352128, Loss: 0.0198, LR: 0.000100\n",
      "Step: 2800, Examples: 358528, Loss: 0.0245, LR: 0.000100\n",
      "Step: 2850, Examples: 364928, Loss: 0.0168, LR: 0.000100\n",
      "Step: 2900, Examples: 371328, Loss: 0.0256, LR: 0.000100\n",
      "Step: 2950, Examples: 377728, Loss: 0.0090, LR: 0.000100\n",
      "Step: 3000, Examples: 384128, Loss: 0.0117, LR: 0.000100\n",
      "Sampling a torch.Size([8, 3, 64, 64]) array in 1000 steps. Initial avg: -0.0024878503754734993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.53it/s, std=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3050, Examples: 390528, Loss: 0.0156, LR: 0.000100\n",
      "Step: 3100, Examples: 396928, Loss: 0.0419, LR: 0.000100\n",
      "Step: 3150, Examples: 403328, Loss: 0.0517, LR: 0.000100\n",
      "Step: 3200, Examples: 409728, Loss: 0.0305, LR: 0.000100\n",
      "Step: 3250, Examples: 416128, Loss: 0.0156, LR: 0.000100\n",
      "Step: 3300, Examples: 422528, Loss: 0.0151, LR: 0.000100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nanodiffusion.diffusion.diffusion_training_loop import training_loop\n",
    "\n",
    "num_examples_trained = training_loop(\n",
    "    model_components, train_loader, val_loader, config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
