{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare VLMs\n",
    "\n",
    "The [VLM dashboard](https://huggingface.co/spaces/opencompass/open_vlm_leaderboard) has a list of VLMs and their performance scores.\n",
    "\n",
    "We want to pick a small-ish (under 8B) model that is sufficient to generate captions for animal face images in the AFHQ dataset.\n",
    "\n",
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft==0.13.2 in /home/ubuntu/.local/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: flash_attn==2.7.* in /home/ubuntu/.local/lib/python3.11/site-packages (2.7.0.post2)\n",
      "Requirement already satisfied: qwen_vl_utils==0.0.8 in /home/ubuntu/.local/lib/python3.11/site-packages (0.0.8)\n",
      "Requirement already satisfied: transformers==4.47.* in /home/ubuntu/.local/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: autoawq==0.2.* in /home/ubuntu/.local/lib/python3.11/site-packages (0.2.7.post2)\n",
      "Requirement already satisfied: jinja2==3.1.4 in /home/ubuntu/.local/lib/python3.11/site-packages (3.1.4)\n",
      "Collecting xformers==0.0.28\n",
      "  Downloading xformers-0.0.28-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: bitsandbytes==0.45.0 in /home/ubuntu/.local/lib/python3.11/site-packages (0.45.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.11/site-packages (from peft==0.13.2) (23.1)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (2.5.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (0.33.0)\n",
      "Requirement already satisfied: safetensors in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from peft==0.13.2) (0.24.5)\n",
      "Requirement already satisfied: einops in /home/ubuntu/.local/lib/python3.11/site-packages (from flash_attn==2.7.*) (0.7.0)\n",
      "Requirement already satisfied: av in /home/ubuntu/.local/lib/python3.11/site-packages (from qwen_vl_utils==0.0.8) (14.0.0)\n",
      "Requirement already satisfied: pillow in /home/ubuntu/.local/lib/python3.11/site-packages (from qwen_vl_utils==0.0.8) (10.2.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.11/site-packages (from qwen_vl_utils==0.0.8) (2.32.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.11/site-packages (from transformers==4.47.*) (3.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.11/site-packages (from transformers==4.47.*) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.11/site-packages (from transformers==4.47.*) (0.21.0)\n",
      "Requirement already satisfied: triton in /home/ubuntu/.local/lib/python3.11/site-packages (from autoawq==0.2.*) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from autoawq==0.2.*) (4.10.0)\n",
      "Requirement already satisfied: datasets>=2.20 in /home/ubuntu/.local/lib/python3.11/site-packages (from autoawq==0.2.*) (2.21.0)\n",
      "Requirement already satisfied: zstandard in /opt/miniconda/lib/python3.11/site-packages (from autoawq==0.2.*) (0.19.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from jinja2==3.1.4) (2.1.5)\n",
      "Collecting torch>=1.13.0 (from peft==0.13.2)\n",
      "  Using cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.13.2)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton (from autoawq==0.2.*)\n",
      "  Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.13.2) (12.4.127)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.*) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.*) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.*) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.*) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.*) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/.local/lib/python3.11/site-packages (from datasets>=2.20->autoawq==0.2.*) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda/lib/python3.11/site-packages (from requests->qwen_vl_utils==0.0.8) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.11/site-packages (from requests->qwen_vl_utils==0.0.8) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda/lib/python3.11/site-packages (from requests->qwen_vl_utils==0.0.8) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.11/site-packages (from requests->qwen_vl_utils==0.0.8) (2023.7.22)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.*) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.*) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.*) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.*) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.*) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.*) (1.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.11/site-packages (from pandas->datasets>=2.20->autoawq==0.2.*) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.11/site-packages (from pandas->datasets>=2.20->autoawq==0.2.*) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.11/site-packages (from pandas->datasets>=2.20->autoawq==0.2.*) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.13.2) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.20->autoawq==0.2.*) (1.16.0)\n",
      "Downloading xformers-0.0.28-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
      "Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, xformers\n",
      "  Attempting uninstall: triton\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: torch\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: xformers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: xformers 0.0.28.post3\n",
      "    Uninstalling xformers-0.0.28.post3:\n",
      "      Successfully uninstalled xformers-0.0.28.post3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.20.1 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0 xformers-0.0.28\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusparse-cu12 (/home/ubuntu/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.13.2 flash_attn==2.7.* qwen_vl_utils==0.0.8 transformers==4.47.* autoawq==0.2.* jinja2==3.1.4 xformers==0.0.28 bitsandbytes==0.45.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47.0\n",
      "3.1.4\n",
      "0.45.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'jinja2.parser' from '/home/ubuntu/.local/lib/python3.11/site-packages/jinja2/parser.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import jinja2\n",
    "import bitsandbytes\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(jinja2.__version__)\n",
    "print(bitsandbytes.__version__)\n",
    "jinja2.parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 14630 images\n",
      "first image shape: torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "dataset_name = \"zzsi/afhq64_16k\"\n",
    "\n",
    "\n",
    "class HuggingFaceDataset(Dataset):\n",
    "    def __init__(self, dataset_path: str, transform=None):\n",
    "        self.dataset = load_dataset(dataset_path, split=\"train\")\n",
    "        self.transform = transform\n",
    "        self.image_key = self.find_image_key()\n",
    "\n",
    "    def find_image_key(self) -> str:\n",
    "        # Check if the dataset has the \"image\" key\n",
    "        # NOTE: Can exapnd this to other common keys if needed\n",
    "        if \"image\" in self.dataset[0].keys():\n",
    "            return \"image\"\n",
    "        raise KeyError(\"Dataset does not have an 'image' key\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx][self.image_key]\n",
    "        image = image.convert(\"RGB\")  # Convert to RGB to ensure 3 channels\n",
    "        # By default, set label to 0 to conform to current expected batch format\n",
    "        label = 0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "transforms_list = [\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "    \n",
    "transform = transforms.Compose(transforms_list)\n",
    "full_dataset = HuggingFaceDataset(dataset_name, transform=transform)\n",
    "\n",
    "\n",
    "print(f\"dataset has {len(full_dataset)} images\")\n",
    "print(f\"first image shape: {full_dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(3, 3))\n",
    "first_image = full_dataset[0][0].permute(1, 2, 0).numpy()\n",
    "plt.imshow(first_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the image to [0, 1]\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "first_image = (first_image - first_image.min()) / max(first_image.max() - first_image.min(), 1e-6)\n",
    "pil_image = Image.fromarray((first_image * 255).astype(np.uint8))\n",
    "pil_image.save(\"first_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QWEN-VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 14:56:55.329856: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-06 14:56:55.342432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-06 14:56:55.357560: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-06 14:56:55.362094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 14:56:55.373408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-06 14:56:56.085600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct-AWQ\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2-VL-2B-Instruct-AWQ\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct-AWQ\")\n",
    "\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct-AWQ\", min_pixels=min_pixels, max_pixels=max_pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The image depicts a cat with a long, flowing coat that appears to be a Maine Coon breed. The cat has a fluffy, dense fur that is predominantly white with some darker markings, particularly around the eyes and around the neck. The cat's eyes are large and expressive, and it has a long, curved tail that is slightly curled. The cat's ears are pointed and have a distinct, fluffy texture. The overall appearance of the cat suggests it is well-groomed and healthy.\"]\n"
     ]
    }
   ],
   "source": [
    "# base64 encoded image using jpeg\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# first write the image to a bytes object\n",
    "image_bytes = io.BytesIO()\n",
    "\n",
    "pil_image.save(image_bytes, format=\"JPEG\")\n",
    "image_bytes = image_bytes.getvalue()\n",
    "prefix = \"data:image/jpeg;base64,\"\n",
    "image_base64 = prefix + base64.b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_base64,\n",
    "                # \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preprocess the inputs\n",
    "\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CogVLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GenerationMixin._extract_past_from_model_output() got an unexpected keyword argument 'standardize_cache_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m\n\u001b[1;32m     38\u001b[0m gen_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_token_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128002\u001b[39m,\n\u001b[1;32m     41\u001b[0m }\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 44\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs[:, inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:]\n\u001b[1;32m     46\u001b[0m     response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/generation/utils.py:2252\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2245\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2246\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2247\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2248\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2249\u001b[0m     )\n\u001b[1;32m   2251\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2253\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2265\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2266\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2272\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/generation/utils.py:3257\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3254\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m-> 3257\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_model_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3258\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3263\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/cogvlm2-llama3-chat-19B-int4/119df232ab9fca4a1be87f95c239d7b9a765032e/modeling_cogvlm.py:710\u001b[0m, in \u001b[0;36mCogVLMForCausalLM._update_model_kwargs_for_generation\u001b[0;34m(self, outputs, model_kwargs, is_encoder_decoder, standardize_cache_format)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_model_kwargs_for_generation\u001b[39m(\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    704\u001b[0m         outputs: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# update past_key_values\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_past_from_model_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandardize_cache_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardize_cache_format\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    714\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mstate\n",
      "\u001b[0;31mTypeError\u001b[0m: GenerationMixin._extract_past_from_model_output() got an unexpected keyword argument 'standardize_cache_format'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_PATH = \"THUDM/cogvlm2-llama3-chat-19B-int4\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TORCH_TYPE = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[\n",
    "    0] >= 8 else torch.float16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=TORCH_TYPE,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    ").eval()\n",
    "\n",
    "text_only_template = \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {} ASSISTANT:\"\n",
    "\n",
    "query = \"Describe this image.\"\n",
    "history = []\n",
    "\n",
    "input_by_model = model.build_conversation_input_ids(\n",
    "                tokenizer,\n",
    "                query=query,\n",
    "                history=history,\n",
    "                images=[pil_image],\n",
    "                template_version='chat'\n",
    "            )\n",
    "\n",
    "inputs = {\n",
    "    'input_ids': input_by_model['input_ids'].unsqueeze(0).to(DEVICE),\n",
    "    'token_type_ids': input_by_model['token_type_ids'].unsqueeze(0).to(DEVICE),\n",
    "    'attention_mask': input_by_model['attention_mask'].unsqueeze(0).to(DEVICE),\n",
    "    'images': [[input_by_model['images'][0].to(DEVICE).to(TORCH_TYPE)]] if pil_image is not None else None,\n",
    "}\n",
    "gen_kwargs = {\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"pad_token_id\": 128002,\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "    response = tokenizer.decode(outputs[0])\n",
    "    response = response.split(\"<|end_of_text|>\")[0]\n",
    "    print(\"\\nCogVLM2:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Blip-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try MiniCPM-V-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaeca35f34d404187f6002e1a46dc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'openbmb/MiniCPM-V-2'\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True,\n",
    "    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager\n",
    "# For Nvidia GPUs support BF16 (like A100, H100, RTX3090)\n",
    "model = model.to(device='cuda', dtype=torch.bfloat16)\n",
    "# For Nvidia GPUs do NOT support BF16 (like V100, T4, RTX2080)\n",
    "#model = model.to(device='cuda', dtype=torch.float16)\n",
    "# For Mac with MPS (Apple silicon or AMD GPUs).\n",
    "# Run with `PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py`\n",
    "#model = model.to(device='mps', dtype=torch.float16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) 166.00000530481339\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Qwen2VLForConditionalGeneration' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is in the image?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m msgs \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: question}]\n\u001b[0;32m---> 11\u001b[0m res, context, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m(\n\u001b[1;32m     12\u001b[0m     image\u001b[38;5;241m=\u001b[39mpil_image,\n\u001b[1;32m     13\u001b[0m     msgs\u001b[38;5;241m=\u001b[39mmsgs,\n\u001b[1;32m     14\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     15\u001b[0m     context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# sampling=True,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# temperature=0.7\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Qwen2VLForConditionalGeneration' object has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "print(first_image.shape, first_image.max() * 255)\n",
    "\n",
    "pil_image = Image.fromarray((first_image * 255).astype(np.uint8))\n",
    "\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': question}]\n",
    "\n",
    "res, context, _ = model.chat(\n",
    "    image=pil_image,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    context=None,\n",
    "    # sampling=True,\n",
    "    # temperature=0.7\n",
    ")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
