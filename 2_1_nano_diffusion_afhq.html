<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Training a Diffusion Model for Animal Face Images – Nano Diffusion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./2_1_nano_diffusion_afhq.html">2.1 Diffusion for Animal Face Images</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Nano Diffusion</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/kungfuai/nano-diffusion.git" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_Diffusion 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1 Diffusion for a 2D Point Cloud</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_a_refactor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1a Refactor</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_b_Diffusion_2D_hyperparams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1b Experimenting with diffusion recipes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_2_Flow Matching 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.2 Flow Matching for a 2D Point Cloud</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_1_nano_diffusion_afhq.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2.1 Diffusion for Animal Face Images</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_1_fid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.1 Evaluation: FID</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#training-configuration" id="toc-training-configuration" class="nav-link active" data-scroll-target="#training-configuration">Training Configuration</a></li>
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data">Load data</a></li>
  <li><a href="#create-model-components-for-diffusion" id="toc-create-model-components-for-diffusion" class="nav-link" data-scroll-target="#create-model-components-for-diffusion">Create model components for diffusion</a>
  <ul class="collapse">
  <li><a href="#library-code-for-model-architecture" id="toc-library-code-for-model-architecture" class="nav-link" data-scroll-target="#library-code-for-model-architecture">Library code for model architecture</a></li>
  <li><a href="#create-model-the-user-logic" id="toc-create-model-the-user-logic" class="nav-link" data-scroll-target="#create-model-the-user-logic">Create model (the user logic)</a></li>
  <li><a href="#optimizer" id="toc-optimizer" class="nav-link" data-scroll-target="#optimizer">Optimizer</a></li>
  <li><a href="#diffusion-noise-schedule" id="toc-diffusion-noise-schedule" class="nav-link" data-scroll-target="#diffusion-noise-schedule">Diffusion noise schedule</a></li>
  </ul></li>
  <li><a href="#train" id="toc-train" class="nav-link" data-scroll-target="#train">Train</a>
  <ul class="collapse">
  <li><a href="#forward-diffusion" id="toc-forward-diffusion" class="nav-link" data-scroll-target="#forward-diffusion">Forward diffusion</a></li>
  <li><a href="#visualizing-forward-diffusion-on-an-image" id="toc-visualizing-forward-diffusion-on-an-image" class="nav-link" data-scroll-target="#visualizing-forward-diffusion-on-an-image">Visualizing forward diffusion on an image</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training loop</a></li>
  </ul></li>
  <li><a href="#generate" id="toc-generate" class="nav-link" data-scroll-target="#generate">Generate</a>
  <ul class="collapse">
  <li><a href="#the-sampling-algo" id="toc-the-sampling-algo" class="nav-link" data-scroll-target="#the-sampling-algo">The sampling algo</a></li>
  <li><a href="#visualize-sampled-images" id="toc-visualize-sampled-images" class="nav-link" data-scroll-target="#visualize-sampled-images">Visualize sampled images</a></li>
  <li><a href="#train-some-more" id="toc-train-some-more" class="nav-link" data-scroll-target="#train-some-more">Train some more</a></li>
  <li><a href="#train-even-more" id="toc-train-even-more" class="nav-link" data-scroll-target="#train-even-more">Train even more</a></li>
  <li><a href="#and-some-more" id="toc-and-some-more" class="nav-link" data-scroll-target="#and-some-more">And, some more</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Training a Diffusion Model for Animal Face Images</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>(under construction)</p>
<div id="cell-2" class="cell" data-outputid="d2b5c8c3-27e8-442b-9f9f-cb83297d0063" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install datasets==3.0.2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> MSELoss</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> make_grid</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Tuple</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="training-configuration" class="level2">
<h2 class="anchored" data-anchor-id="training-configuration">Training Configuration</h2>
<div id="cell-5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrainingConfig:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    dataset: <span class="bu">str</span> <span class="op">=</span> <span class="st">"zzsi/afhq64_16k"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model architecture</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    resolution: <span class="bu">int</span> <span class="op">=</span> <span class="dv">64</span> <span class="co"># resolution of the image</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    num_denoising_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span> <span class="co"># number of timesteps</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop and optimizer</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    total_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100000</span>  <span class="co"># total number of training steps</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span> <span class="co"># batch size</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    learning_rate: <span class="bu">float</span> <span class="op">=</span> <span class="fl">5e-4</span> <span class="co"># initial learning rate</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-6</span> <span class="co"># weight decay</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data augmentation</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    random_flip: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span> <span class="co"># randomly flip images horizontally</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> TrainingConfig(resolution<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-data" class="level2">
<h2 class="anchored" data-anchor-id="load-data">Load data</h2>
<div id="cell-7" class="cell" data-outputid="ebcded33-8efd-4e60-d5ef-caf0ecd87062" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HuggingFaceDataset(Dataset):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset_path: <span class="bu">str</span>, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> load_dataset(dataset_path, split<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_key <span class="op">=</span> <span class="va">self</span>.find_image_key()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> find_image_key(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the dataset has the "image" key</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Can exapnd this to other common keys if needed</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"image"</span> <span class="kw">in</span> <span class="va">self</span>.dataset[<span class="dv">0</span>].keys():</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"image"</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">KeyError</span>(<span class="st">"Dataset does not have an 'image' key"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> <span class="va">self</span>.dataset[idx][<span class="va">self</span>.image_key]</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> image.convert(<span class="st">"RGB"</span>)  <span class="co"># Convert to RGB to ensure 3 channels</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># By default, set label to 0 to conform to current expected batch format</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, label</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(config: TrainingConfig) <span class="op">-&gt;</span> Tuple[DataLoader, DataLoader]:</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    resolution <span class="op">=</span> config.resolution</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    transforms_list <span class="op">=</span> [</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((resolution, resolution)),</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)),</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> config.random_flip:</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        transforms_list.insert(<span class="dv">0</span>, transforms.RandomHorizontalFlip())</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose(transforms_list)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    full_dataset <span class="op">=</span> HuggingFaceDataset(config.dataset, transform<span class="op">=</span>transform)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.9</span> <span class="op">*</span> <span class="bu">len</span>(full_dataset))</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    val_size <span class="op">=</span> <span class="bu">len</span>(full_dataset) <span class="op">-</span> train_size</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    train_dataset, val_dataset <span class="op">=</span> random_split(full_dataset, [train_size, val_size])</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    train_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        train_dataset, batch_size<span class="op">=</span>config.batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    val_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>        val_dataset, batch_size<span class="op">=</span>config.batch_size, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_dataloader, val_dataloader</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>train_dataloader, val_dataloader <span class="op">=</span> load_data(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell" data-outputid="fd4bd221-815c-45dd-bc10-da980d048d3d" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dataloader))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>grid_img <span class="op">=</span> make_grid(x[<span class="dv">0</span>]).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>grid_img <span class="op">=</span> (grid_img <span class="op">-</span> grid_img.<span class="bu">min</span>()) <span class="op">/</span> (grid_img.<span class="bu">max</span>() <span class="op">-</span> grid_img.<span class="bu">min</span>())</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(grid_img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="create-model-components-for-diffusion" class="level2">
<h2 class="anchored" data-anchor-id="create-model-components-for-diffusion">Create model components for diffusion</h2>
<section id="library-code-for-model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="library-code-for-model-architecture">Library code for model architecture</h3>
<div id="cell-11" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">From: https://github.com/VSehwag/minimal-diffusion/blob/main/unets.py</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> abc <span class="im">import</span> abstractmethod</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch <span class="im">as</span> th</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GroupNorm32(nn.GroupNorm):</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">super</span>().forward(x.<span class="bu">float</span>()).<span class="bu">type</span>(x.dtype)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conv_nd(dims, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a 1D, 2D, or 3D convolution module.</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dims <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv1d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv3d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported dimensions: </span><span class="sc">{</span>dims<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a linear module.</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nn.Linear(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> avg_pool_nd(dims, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a 1D, 2D, or 3D average pooling module.</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dims <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool1d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool3d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported dimensions: </span><span class="sc">{</span>dims<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_ema(target_params, source_params, rate<span class="op">=</span><span class="fl">0.99</span>):</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a><span class="co">    Update target parameters to be closer to those of source parameters using</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a><span class="co">    an exponential moving average.</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co">    :param target_params: the target parameter sequence.</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="co">    :param source_params: the source parameter sequence.</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="co">    :param rate: the EMA rate (closer to 1 means slower).</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> targ, src <span class="kw">in</span> <span class="bu">zip</span>(target_params, source_params):</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>        targ.detach().mul_(rate).add_(src, alpha<span class="op">=</span><span class="dv">1</span> <span class="op">-</span> rate)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_module(module):</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a><span class="co">    Zero out the parameters of a module and return it.</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> module.parameters():</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>        p.detach().zero_()</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> module</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalization(channels):</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a><span class="co">    Make a standard normalization layer.</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: number of input channels.</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: an nn.Module for normalization.</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> GroupNorm32(<span class="dv">32</span>, channels)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> timestep_embedding(timesteps, dim, max_period<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a><span class="co">    Create sinusoidal timestep embeddings.</span></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a><span class="co">    :param timesteps: a 1-D Tensor of N indices, one per batch element.</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a><span class="co">                      These may be fractional.</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dim: the dimension of the output.</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a><span class="co">    :param max_period: controls the minimum frequency of the embeddings.</span></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: an [N x dim] Tensor of positional embeddings.</span></span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>    half <span class="op">=</span> dim <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> th.exp(</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>        <span class="op">-</span>math.log(max_period) <span class="op">*</span> th.arange(start<span class="op">=</span><span class="dv">0</span>, end<span class="op">=</span>half, dtype<span class="op">=</span>th.float32) <span class="op">/</span> half</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>    ).to(device<span class="op">=</span>timesteps.device)</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> timesteps.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> timesteps[:, <span class="va">None</span>].<span class="bu">float</span>() <span class="op">*</span> freqs[<span class="va">None</span>]</span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> timesteps.<span class="bu">float</span>() <span class="op">*</span> freqs[<span class="va">None</span>]</span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>    embedding <span class="op">=</span> th.cat([th.cos(args), th.sin(args)], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dim <span class="op">%</span> <span class="dv">2</span>:</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>        embedding <span class="op">=</span> th.cat([embedding, th.zeros_like(embedding[:, :<span class="dv">1</span>])], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embedding</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> checkpoint(func, inputs, params, flag):</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a><span class="co">    Evaluate a function without caching intermediate activations, allowing for</span></span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a><span class="co">    reduced memory at the expense of extra compute in the backward pass.</span></span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a><span class="co">    :param func: the function to evaluate.</span></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="co">    :param inputs: the argument sequence to pass to `func`.</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a><span class="co">    :param params: a sequence of parameters `func` depends on but does not</span></span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a><span class="co">                   explicitly take as arguments.</span></span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a><span class="co">    :param flag: if False, disable gradient checkpointing.</span></span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> flag:</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> <span class="bu">tuple</span>(inputs) <span class="op">+</span> <span class="bu">tuple</span>(params)</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> CheckpointFunction.<span class="bu">apply</span>(func, <span class="bu">len</span>(inputs), <span class="op">*</span>args)</span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> func(<span class="op">*</span>inputs)</span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CheckpointFunction(th.autograd.Function):</span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(ctx, run_function, length, <span class="op">*</span>args):</span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a>        ctx.run_function <span class="op">=</span> run_function</span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>        ctx.input_tensors <span class="op">=</span> <span class="bu">list</span>(args[:length])</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a>        ctx.input_params <span class="op">=</span> <span class="bu">list</span>(args[length:])</span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> th.no_grad():</span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>            output_tensors <span class="op">=</span> ctx.run_function(<span class="op">*</span>ctx.input_tensors)</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output_tensors</span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(ctx, <span class="op">*</span>output_grads):</span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a>        ctx.input_tensors <span class="op">=</span> [x.detach().requires_grad_(<span class="va">True</span>) <span class="cf">for</span> x <span class="kw">in</span> ctx.input_tensors]</span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> th.enable_grad():</span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fixes a bug where the first op in run_function modifies the</span></span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tensor storage in place, which is not allowed for detach()'d</span></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tensors.</span></span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a>            shallow_copies <span class="op">=</span> [x.view_as(x) <span class="cf">for</span> x <span class="kw">in</span> ctx.input_tensors]</span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a>            output_tensors <span class="op">=</span> ctx.run_function(<span class="op">*</span>shallow_copies)</span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a>        input_grads <span class="op">=</span> th.autograd.grad(</span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a>            output_tensors,</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a>            ctx.input_tensors <span class="op">+</span> ctx.input_params,</span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a>            output_grads,</span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a>            allow_unused<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> ctx.input_tensors</span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> ctx.input_params</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> output_tensors</span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">None</span>, <span class="va">None</span>) <span class="op">+</span> input_grads</span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionPool2d(nn.Module):</span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a><span class="co">    Adapted from CLIP: https://github.com/openai/CLIP/blob/main/clip/model.py</span></span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a>        spacial_dim: <span class="bu">int</span>,</span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a>        embed_dim: <span class="bu">int</span>,</span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a>        num_heads_channels: <span class="bu">int</span>,</span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a>        output_dim: <span class="bu">int</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positional_embedding <span class="op">=</span> nn.Parameter(</span>
<span id="cb6-170"><a href="#cb6-170" aria-hidden="true" tabindex="-1"></a>            th.randn(embed_dim, spacial_dim <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> embed_dim <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qkv_proj <span class="op">=</span> conv_nd(<span class="dv">1</span>, embed_dim, <span class="dv">3</span> <span class="op">*</span> embed_dim, <span class="dv">1</span>)</span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj <span class="op">=</span> conv_nd(<span class="dv">1</span>, embed_dim, output_dim <span class="kw">or</span> embed_dim, <span class="dv">1</span>)</span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> embed_dim <span class="op">//</span> num_heads_channels</span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> QKVAttention(<span class="va">self</span>.num_heads)</span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>        b, c, <span class="op">*</span>_spatial <span class="op">=</span> x.shape</span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(b, c, <span class="op">-</span><span class="dv">1</span>)  <span class="co"># NC(HW)</span></span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> th.cat([x.mean(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>), x], dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># NC(HW+1)</span></span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.positional_embedding[<span class="va">None</span>, :, :].to(x.dtype)  <span class="co"># NC(HW+1)</span></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.qkv_proj(x)</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attention(x)</span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.c_proj(x)</span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x[:, :, <span class="dv">0</span>]</span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimestepBlock(nn.Module):</span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a><span class="co">    Any module where forward() takes timestep embeddings as a second argument.</span></span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a>    <span class="at">@abstractmethod</span></span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the module to `x` given `emb` timestep embeddings.</span></span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimestepEmbedSequential(nn.Sequential, TimestepBlock):</span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a><span class="co">    A sequential module that passes timestep embeddings to the children that</span></span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a><span class="co">    support it as an extra input.</span></span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>:</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, TimestepBlock):</span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x, emb)</span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x)</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Upsample(nn.Module):</span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a><span class="co">    An upsampling layer with an optional convolution.</span></span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: channels in the inputs and outputs.</span></span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: a bool determining if a convolution is applied.</span></span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then</span></span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a><span class="co">                 upsampling occurs in the inner-two dimensions.</span></span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, use_conv, dims<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dims <span class="op">=</span> dims</span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_conv:</span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.conv <span class="op">=</span> conv_nd(dims, <span class="va">self</span>.channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> x.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="va">self</span>.channels</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.interpolate(</span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a>                x, (x.shape[<span class="dv">2</span>], x.shape[<span class="dv">3</span>] <span class="op">*</span> <span class="dv">2</span>, x.shape[<span class="dv">4</span>] <span class="op">*</span> <span class="dv">2</span>), mode<span class="op">=</span><span class="st">"nearest"</span></span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.interpolate(x, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">"nearest"</span>)</span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> x.shape[<span class="op">-</span><span class="dv">2</span>] <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>            <span class="co"># upsampling layer transform [3x3] to [6x6]. Manually paddding it to make [7x7]</span></span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.pad(out, (<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.use_conv:</span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.conv(out)</span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Downsample(nn.Module):</span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a><span class="co">    A downsampling layer with an optional convolution.</span></span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: channels in the inputs and outputs.</span></span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: a bool determining if a convolution is applied.</span></span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then</span></span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a><span class="co">                 downsampling occurs in the inner-two dimensions.</span></span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, use_conv, dims<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dims <span class="op">=</span> dims</span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> <span class="dv">2</span> <span class="cf">if</span> dims <span class="op">!=</span> <span class="dv">3</span> <span class="cf">else</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_conv:</span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.op <span class="op">=</span> conv_nd(</span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a>                dims, <span class="va">self</span>.channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, stride<span class="op">=</span>stride, padding<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> <span class="va">self</span>.channels <span class="op">==</span> <span class="va">self</span>.out_channels</span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.op <span class="op">=</span> avg_pool_nd(dims, kernel_size<span class="op">=</span>stride, stride<span class="op">=</span>stride)</span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> x.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="va">self</span>.channels</span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.op(x)</span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResBlock(TimestepBlock):</span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a><span class="co">    A residual block that can optionally change the number of channels.</span></span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: the number of input channels.</span></span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a><span class="co">    :param emb_channels: the number of timestep embedding channels.</span></span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dropout: the rate of dropout.</span></span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a><span class="co">    :param out_channels: if specified, the number of out channels.</span></span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: if True and out_channels is specified, use a spatial</span></span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a><span class="co">        convolution instead of a smaller 1x1 convolution to change the</span></span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a><span class="co">        channels in the skip connection.</span></span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D.</span></span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_checkpoint: if True, use gradient checkpointing on this module.</span></span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a><span class="co">    :param up: if True, use this block for upsampling.</span></span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a><span class="co">    :param down: if True, use this block for downsampling.</span></span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a>        channels,</span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a>        emb_channels,</span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a>        dropout,</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a>        use_conv<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a>        dims<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a>        up<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a>        down<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emb_channels <span class="op">=</span> emb_channels</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_scale_shift_norm <span class="op">=</span> use_scale_shift_norm</span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a>            normalization(channels),</span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a>            conv_nd(dims, channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.updown <span class="op">=</span> up <span class="kw">or</span> down</span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> up:</span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> Upsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.x_upd <span class="op">=</span> Upsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> down:</span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> Downsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.x_upd <span class="op">=</span> Downsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> <span class="va">self</span>.x_upd <span class="op">=</span> nn.Identity()</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emb_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a>            linear(</span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a>                emb_channels,</span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a>                <span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.out_channels <span class="cf">if</span> use_scale_shift_norm <span class="cf">else</span> <span class="va">self</span>.out_channels,</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a>            normalization(<span class="va">self</span>.out_channels),</span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span>dropout),</span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a>            zero_module(</span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a>                conv_nd(dims, <span class="va">self</span>.out_channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.out_channels <span class="op">==</span> channels:</span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> nn.Identity()</span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> use_conv:</span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> conv_nd(</span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a>                dims, channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> conv_nd(dims, channels, <span class="va">self</span>.out_channels, <span class="dv">1</span>)</span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the block to a Tensor, conditioned on a timestep embedding.</span></span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a><span class="co">        :param x: an [N x C x ...] Tensor of features.</span></span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a><span class="co">        :param emb: an [N x emb_channels] Tensor of timestep embeddings.</span></span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x C x ...] Tensor of outputs.</span></span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint(</span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._forward, (x, emb), <span class="va">self</span>.parameters(), <span class="va">self</span>.use_checkpoint</span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-370"><a href="#cb6-370" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.updown:</span>
<span id="cb6-371"><a href="#cb6-371" aria-hidden="true" tabindex="-1"></a>            in_rest, in_conv <span class="op">=</span> <span class="va">self</span>.in_layers[:<span class="op">-</span><span class="dv">1</span>], <span class="va">self</span>.in_layers[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> in_rest(x)</span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.h_upd(h)</span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.x_upd(x)</span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> in_conv(h)</span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.in_layers(x)</span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a>        emb_out <span class="op">=</span> <span class="va">self</span>.emb_layers(emb).<span class="bu">type</span>(h.dtype)</span>
<span id="cb6-379"><a href="#cb6-379" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="bu">len</span>(emb_out.shape) <span class="op">&lt;</span> <span class="bu">len</span>(h.shape):</span>
<span id="cb6-380"><a href="#cb6-380" aria-hidden="true" tabindex="-1"></a>            emb_out <span class="op">=</span> emb_out[..., <span class="va">None</span>]</span>
<span id="cb6-381"><a href="#cb6-381" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.use_scale_shift_norm:</span>
<span id="cb6-382"><a href="#cb6-382" aria-hidden="true" tabindex="-1"></a>            out_norm, out_rest <span class="op">=</span> <span class="va">self</span>.out_layers[<span class="dv">0</span>], <span class="va">self</span>.out_layers[<span class="dv">1</span>:]</span>
<span id="cb6-383"><a href="#cb6-383" aria-hidden="true" tabindex="-1"></a>            scale, shift <span class="op">=</span> th.chunk(emb_out, <span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-384"><a href="#cb6-384" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> out_norm(h) <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> scale) <span class="op">+</span> shift</span>
<span id="cb6-385"><a href="#cb6-385" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> out_rest(h)</span>
<span id="cb6-386"><a href="#cb6-386" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-387"><a href="#cb6-387" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> h <span class="op">+</span> emb_out</span>
<span id="cb6-388"><a href="#cb6-388" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.out_layers(h)</span>
<span id="cb6-389"><a href="#cb6-389" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.skip_connection(x) <span class="op">+</span> h</span>
<span id="cb6-390"><a href="#cb6-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-391"><a href="#cb6-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-392"><a href="#cb6-392" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(nn.Module):</span>
<span id="cb6-393"><a href="#cb6-393" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-394"><a href="#cb6-394" aria-hidden="true" tabindex="-1"></a><span class="co">    An attention block that allows spatial positions to attend to each other.</span></span>
<span id="cb6-395"><a href="#cb6-395" aria-hidden="true" tabindex="-1"></a><span class="co">    Originally ported from here, but adapted to the N-d case.</span></span>
<span id="cb6-396"><a href="#cb6-396" aria-hidden="true" tabindex="-1"></a><span class="co">    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.</span></span>
<span id="cb6-397"><a href="#cb6-397" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-398"><a href="#cb6-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-399"><a href="#cb6-399" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-400"><a href="#cb6-400" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-401"><a href="#cb6-401" aria-hidden="true" tabindex="-1"></a>        channels,</span>
<span id="cb6-402"><a href="#cb6-402" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-403"><a href="#cb6-403" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-404"><a href="#cb6-404" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-405"><a href="#cb6-405" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-406"><a href="#cb6-406" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-407"><a href="#cb6-407" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-408"><a href="#cb6-408" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-409"><a href="#cb6-409" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_head_channels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb6-410"><a href="#cb6-410" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb6-411"><a href="#cb6-411" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-412"><a href="#cb6-412" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> (</span>
<span id="cb6-413"><a href="#cb6-413" aria-hidden="true" tabindex="-1"></a>                channels <span class="op">%</span> num_head_channels <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb6-414"><a href="#cb6-414" aria-hidden="true" tabindex="-1"></a>            ), <span class="ss">f"q,k,v channels </span><span class="sc">{</span>channels<span class="sc">}</span><span class="ss"> is not divisible by num_head_channels </span><span class="sc">{</span>num_head_channels<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb6-415"><a href="#cb6-415" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_heads <span class="op">=</span> channels <span class="op">//</span> num_head_channels</span>
<span id="cb6-416"><a href="#cb6-416" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb6-417"><a href="#cb6-417" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> normalization(channels)</span>
<span id="cb6-418"><a href="#cb6-418" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qkv <span class="op">=</span> conv_nd(<span class="dv">1</span>, channels, channels <span class="op">*</span> <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb6-419"><a href="#cb6-419" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_new_attention_order:</span>
<span id="cb6-420"><a href="#cb6-420" aria-hidden="true" tabindex="-1"></a>            <span class="co"># split qkv before split heads</span></span>
<span id="cb6-421"><a href="#cb6-421" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attention <span class="op">=</span> QKVAttention(<span class="va">self</span>.num_heads)</span>
<span id="cb6-422"><a href="#cb6-422" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-423"><a href="#cb6-423" aria-hidden="true" tabindex="-1"></a>            <span class="co"># split heads before split qkv</span></span>
<span id="cb6-424"><a href="#cb6-424" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attention <span class="op">=</span> QKVAttentionLegacy(<span class="va">self</span>.num_heads)</span>
<span id="cb6-425"><a href="#cb6-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-426"><a href="#cb6-426" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_out <span class="op">=</span> zero_module(conv_nd(<span class="dv">1</span>, channels, channels, <span class="dv">1</span>))</span>
<span id="cb6-427"><a href="#cb6-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-428"><a href="#cb6-428" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-429"><a href="#cb6-429" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint(<span class="va">self</span>._forward, (x,), <span class="va">self</span>.parameters(), <span class="va">True</span>)</span>
<span id="cb6-430"><a href="#cb6-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-431"><a href="#cb6-431" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward(<span class="va">self</span>, x):</span>
<span id="cb6-432"><a href="#cb6-432" aria-hidden="true" tabindex="-1"></a>        b, c, <span class="op">*</span>spatial <span class="op">=</span> x.shape</span>
<span id="cb6-433"><a href="#cb6-433" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(b, c, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb6-434"><a href="#cb6-434" aria-hidden="true" tabindex="-1"></a>        qkv <span class="op">=</span> <span class="va">self</span>.qkv(<span class="va">self</span>.norm(x))</span>
<span id="cb6-435"><a href="#cb6-435" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.attention(qkv)</span>
<span id="cb6-436"><a href="#cb6-436" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.proj_out(h)</span>
<span id="cb6-437"><a href="#cb6-437" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (x <span class="op">+</span> h).reshape(b, c, <span class="op">*</span>spatial)</span>
<span id="cb6-438"><a href="#cb6-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-439"><a href="#cb6-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-440"><a href="#cb6-440" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_flops_attn(model, _x, y):</span>
<span id="cb6-441"><a href="#cb6-441" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-442"><a href="#cb6-442" aria-hidden="true" tabindex="-1"></a><span class="co">    A counter for the `thop` package to count the operations in an</span></span>
<span id="cb6-443"><a href="#cb6-443" aria-hidden="true" tabindex="-1"></a><span class="co">    attention operation.</span></span>
<span id="cb6-444"><a href="#cb6-444" aria-hidden="true" tabindex="-1"></a><span class="co">    Meant to be used like:</span></span>
<span id="cb6-445"><a href="#cb6-445" aria-hidden="true" tabindex="-1"></a><span class="co">        macs, params = thop.profile(</span></span>
<span id="cb6-446"><a href="#cb6-446" aria-hidden="true" tabindex="-1"></a><span class="co">            model,</span></span>
<span id="cb6-447"><a href="#cb6-447" aria-hidden="true" tabindex="-1"></a><span class="co">            inputs=(inputs, timestamps),</span></span>
<span id="cb6-448"><a href="#cb6-448" aria-hidden="true" tabindex="-1"></a><span class="co">            custom_ops={QKVAttention: QKVAttention.count_flops},</span></span>
<span id="cb6-449"><a href="#cb6-449" aria-hidden="true" tabindex="-1"></a><span class="co">        )</span></span>
<span id="cb6-450"><a href="#cb6-450" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-451"><a href="#cb6-451" aria-hidden="true" tabindex="-1"></a>    b, c, <span class="op">*</span>spatial <span class="op">=</span> y[<span class="dv">0</span>].shape</span>
<span id="cb6-452"><a href="#cb6-452" aria-hidden="true" tabindex="-1"></a>    num_spatial <span class="op">=</span> <span class="bu">int</span>(np.prod(spatial))</span>
<span id="cb6-453"><a href="#cb6-453" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We perform two matmuls with the same number of ops.</span></span>
<span id="cb6-454"><a href="#cb6-454" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The first computes the weight matrix, the second computes</span></span>
<span id="cb6-455"><a href="#cb6-455" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the combination of the value vectors.</span></span>
<span id="cb6-456"><a href="#cb6-456" aria-hidden="true" tabindex="-1"></a>    matmul_ops <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> b <span class="op">*</span> (num_spatial <span class="op">**</span> <span class="dv">2</span>) <span class="op">*</span> c</span>
<span id="cb6-457"><a href="#cb6-457" aria-hidden="true" tabindex="-1"></a>    model.total_ops <span class="op">+=</span> th.DoubleTensor([matmul_ops])</span>
<span id="cb6-458"><a href="#cb6-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-459"><a href="#cb6-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-460"><a href="#cb6-460" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QKVAttentionLegacy(nn.Module):</span>
<span id="cb6-461"><a href="#cb6-461" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-462"><a href="#cb6-462" aria-hidden="true" tabindex="-1"></a><span class="co">    A module which performs QKV attention. Matches legacy QKVAttention + input/ouput heads shaping</span></span>
<span id="cb6-463"><a href="#cb6-463" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-464"><a href="#cb6-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-465"><a href="#cb6-465" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_heads):</span>
<span id="cb6-466"><a href="#cb6-466" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-467"><a href="#cb6-467" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb6-468"><a href="#cb6-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-469"><a href="#cb6-469" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, qkv):</span>
<span id="cb6-470"><a href="#cb6-470" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-471"><a href="#cb6-471" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply QKV attention.</span></span>
<span id="cb6-472"><a href="#cb6-472" aria-hidden="true" tabindex="-1"></a><span class="co">        :param qkv: an [N x (H * 3 * C) x T] tensor of Qs, Ks, and Vs.</span></span>
<span id="cb6-473"><a href="#cb6-473" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x (H * C) x T] tensor after attention.</span></span>
<span id="cb6-474"><a href="#cb6-474" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-475"><a href="#cb6-475" aria-hidden="true" tabindex="-1"></a>        bs, width, length <span class="op">=</span> qkv.shape</span>
<span id="cb6-476"><a href="#cb6-476" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> width <span class="op">%</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb6-477"><a href="#cb6-477" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> width <span class="op">//</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads)</span>
<span id="cb6-478"><a href="#cb6-478" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.reshape(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch <span class="op">*</span> <span class="dv">3</span>, length).split(ch, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-479"><a href="#cb6-479" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(math.sqrt(ch))</span>
<span id="cb6-480"><a href="#cb6-480" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.einsum(</span>
<span id="cb6-481"><a href="#cb6-481" aria-hidden="true" tabindex="-1"></a>            <span class="st">"bct,bcs-&gt;bts"</span>, q <span class="op">*</span> scale, k <span class="op">*</span> scale</span>
<span id="cb6-482"><a href="#cb6-482" aria-hidden="true" tabindex="-1"></a>        )  <span class="co"># More stable with f16 than dividing afterwards</span></span>
<span id="cb6-483"><a href="#cb6-483" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.softmax(weight.<span class="bu">float</span>(), dim<span class="op">=-</span><span class="dv">1</span>).<span class="bu">type</span>(weight.dtype)</span>
<span id="cb6-484"><a href="#cb6-484" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> th.einsum(<span class="st">"bts,bcs-&gt;bct"</span>, weight, v)</span>
<span id="cb6-485"><a href="#cb6-485" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a.reshape(bs, <span class="op">-</span><span class="dv">1</span>, length)</span>
<span id="cb6-486"><a href="#cb6-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-487"><a href="#cb6-487" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-488"><a href="#cb6-488" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> count_flops(model, _x, y):</span>
<span id="cb6-489"><a href="#cb6-489" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> count_flops_attn(model, _x, y)</span>
<span id="cb6-490"><a href="#cb6-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-491"><a href="#cb6-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-492"><a href="#cb6-492" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QKVAttention(nn.Module):</span>
<span id="cb6-493"><a href="#cb6-493" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-494"><a href="#cb6-494" aria-hidden="true" tabindex="-1"></a><span class="co">    A module which performs QKV attention and splits in a different order.</span></span>
<span id="cb6-495"><a href="#cb6-495" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-496"><a href="#cb6-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-497"><a href="#cb6-497" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_heads):</span>
<span id="cb6-498"><a href="#cb6-498" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-499"><a href="#cb6-499" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb6-500"><a href="#cb6-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-501"><a href="#cb6-501" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, qkv):</span>
<span id="cb6-502"><a href="#cb6-502" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-503"><a href="#cb6-503" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply QKV attention.</span></span>
<span id="cb6-504"><a href="#cb6-504" aria-hidden="true" tabindex="-1"></a><span class="co">        :param qkv: an [N x (3 * H * C) x T] tensor of Qs, Ks, and Vs.</span></span>
<span id="cb6-505"><a href="#cb6-505" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x (H * C) x T] tensor after attention.</span></span>
<span id="cb6-506"><a href="#cb6-506" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-507"><a href="#cb6-507" aria-hidden="true" tabindex="-1"></a>        bs, width, length <span class="op">=</span> qkv.shape</span>
<span id="cb6-508"><a href="#cb6-508" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> width <span class="op">%</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb6-509"><a href="#cb6-509" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> width <span class="op">//</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads)</span>
<span id="cb6-510"><a href="#cb6-510" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.chunk(<span class="dv">3</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-511"><a href="#cb6-511" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(math.sqrt(ch))</span>
<span id="cb6-512"><a href="#cb6-512" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.einsum(</span>
<span id="cb6-513"><a href="#cb6-513" aria-hidden="true" tabindex="-1"></a>            <span class="st">"bct,bcs-&gt;bts"</span>,</span>
<span id="cb6-514"><a href="#cb6-514" aria-hidden="true" tabindex="-1"></a>            (q <span class="op">*</span> scale).view(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length),</span>
<span id="cb6-515"><a href="#cb6-515" aria-hidden="true" tabindex="-1"></a>            (k <span class="op">*</span> scale).view(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length),</span>
<span id="cb6-516"><a href="#cb6-516" aria-hidden="true" tabindex="-1"></a>        )  <span class="co"># More stable with f16 than dividing afterwards</span></span>
<span id="cb6-517"><a href="#cb6-517" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.softmax(weight.<span class="bu">float</span>(), dim<span class="op">=-</span><span class="dv">1</span>).<span class="bu">type</span>(weight.dtype)</span>
<span id="cb6-518"><a href="#cb6-518" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> th.einsum(<span class="st">"bts,bcs-&gt;bct"</span>, weight, v.reshape(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length))</span>
<span id="cb6-519"><a href="#cb6-519" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a.reshape(bs, <span class="op">-</span><span class="dv">1</span>, length)</span>
<span id="cb6-520"><a href="#cb6-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-521"><a href="#cb6-521" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-522"><a href="#cb6-522" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> count_flops(model, _x, y):</span>
<span id="cb6-523"><a href="#cb6-523" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> count_flops_attn(model, _x, y)</span>
<span id="cb6-524"><a href="#cb6-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-525"><a href="#cb6-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-526"><a href="#cb6-526" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNetModel(nn.Module):</span>
<span id="cb6-527"><a href="#cb6-527" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-528"><a href="#cb6-528" aria-hidden="true" tabindex="-1"></a><span class="co">    The full UNet model with attention and timestep embedding.</span></span>
<span id="cb6-529"><a href="#cb6-529" aria-hidden="true" tabindex="-1"></a><span class="co">    :param in_channels: channels in the input Tensor.</span></span>
<span id="cb6-530"><a href="#cb6-530" aria-hidden="true" tabindex="-1"></a><span class="co">    :param emb_dim: base dimension of timestep embedding.</span></span>
<span id="cb6-531"><a href="#cb6-531" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_channels: base channel count for the model.</span></span>
<span id="cb6-532"><a href="#cb6-532" aria-hidden="true" tabindex="-1"></a><span class="co">    :param out_channels: channels in the output Tensor.</span></span>
<span id="cb6-533"><a href="#cb6-533" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_res_blocks: number of residual blocks per downsample.</span></span>
<span id="cb6-534"><a href="#cb6-534" aria-hidden="true" tabindex="-1"></a><span class="co">    :param attention_resolutions: a collection of downsample rates at which</span></span>
<span id="cb6-535"><a href="#cb6-535" aria-hidden="true" tabindex="-1"></a><span class="co">        attention will take place. May be a set, list, or tuple.</span></span>
<span id="cb6-536"><a href="#cb6-536" aria-hidden="true" tabindex="-1"></a><span class="co">        For example, if this contains 4, then at 4x downsampling, attention</span></span>
<span id="cb6-537"><a href="#cb6-537" aria-hidden="true" tabindex="-1"></a><span class="co">        will be used.</span></span>
<span id="cb6-538"><a href="#cb6-538" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dropout: the dropout probability.</span></span>
<span id="cb6-539"><a href="#cb6-539" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channel_mult: channel multiplier for each level of the UNet.</span></span>
<span id="cb6-540"><a href="#cb6-540" aria-hidden="true" tabindex="-1"></a><span class="co">    :param conv_resample: if True, use learned convolutions for upsampling and</span></span>
<span id="cb6-541"><a href="#cb6-541" aria-hidden="true" tabindex="-1"></a><span class="co">        downsampling.</span></span>
<span id="cb6-542"><a href="#cb6-542" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D.</span></span>
<span id="cb6-543"><a href="#cb6-543" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_classes: if specified (as an int), then this model will be</span></span>
<span id="cb6-544"><a href="#cb6-544" aria-hidden="true" tabindex="-1"></a><span class="co">        class-conditional with `num_classes` classes.</span></span>
<span id="cb6-545"><a href="#cb6-545" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_checkpoint: use gradient checkpointing to reduce memory usage.</span></span>
<span id="cb6-546"><a href="#cb6-546" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads: the number of attention heads in each attention layer.</span></span>
<span id="cb6-547"><a href="#cb6-547" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads_channels: if specified, ignore num_heads and instead use</span></span>
<span id="cb6-548"><a href="#cb6-548" aria-hidden="true" tabindex="-1"></a><span class="co">                               a fixed channel width per attention head.</span></span>
<span id="cb6-549"><a href="#cb6-549" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads_upsample: works with num_heads to set a different number</span></span>
<span id="cb6-550"><a href="#cb6-550" aria-hidden="true" tabindex="-1"></a><span class="co">                               of heads for upsampling. Deprecated.</span></span>
<span id="cb6-551"><a href="#cb6-551" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_scale_shift_norm: use a FiLM-like conditioning mechanism.</span></span>
<span id="cb6-552"><a href="#cb6-552" aria-hidden="true" tabindex="-1"></a><span class="co">    :param resblock_updown: use residual blocks for up/downsampling.</span></span>
<span id="cb6-553"><a href="#cb6-553" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_new_attention_order: use a different attention pattern for potentially</span></span>
<span id="cb6-554"><a href="#cb6-554" aria-hidden="true" tabindex="-1"></a><span class="co">                                    increased efficiency.</span></span>
<span id="cb6-555"><a href="#cb6-555" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-556"><a href="#cb6-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-557"><a href="#cb6-557" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-558"><a href="#cb6-558" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-559"><a href="#cb6-559" aria-hidden="true" tabindex="-1"></a>        image_size,</span>
<span id="cb6-560"><a href="#cb6-560" aria-hidden="true" tabindex="-1"></a>        in_channels,</span>
<span id="cb6-561"><a href="#cb6-561" aria-hidden="true" tabindex="-1"></a>        model_channels,</span>
<span id="cb6-562"><a href="#cb6-562" aria-hidden="true" tabindex="-1"></a>        out_channels,</span>
<span id="cb6-563"><a href="#cb6-563" aria-hidden="true" tabindex="-1"></a>        num_res_blocks,</span>
<span id="cb6-564"><a href="#cb6-564" aria-hidden="true" tabindex="-1"></a>        attention_resolutions,</span>
<span id="cb6-565"><a href="#cb6-565" aria-hidden="true" tabindex="-1"></a>        time_emb_factor<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-566"><a href="#cb6-566" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb6-567"><a href="#cb6-567" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>),</span>
<span id="cb6-568"><a href="#cb6-568" aria-hidden="true" tabindex="-1"></a>        conv_resample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-569"><a href="#cb6-569" aria-hidden="true" tabindex="-1"></a>        dims<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-570"><a href="#cb6-570" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-571"><a href="#cb6-571" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-572"><a href="#cb6-572" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-573"><a href="#cb6-573" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-574"><a href="#cb6-574" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-575"><a href="#cb6-575" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-576"><a href="#cb6-576" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-577"><a href="#cb6-577" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-578"><a href="#cb6-578" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-579"><a href="#cb6-579" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-580"><a href="#cb6-580" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-581"><a href="#cb6-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-582"><a href="#cb6-582" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_heads_upsample <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb6-583"><a href="#cb6-583" aria-hidden="true" tabindex="-1"></a>            num_heads_upsample <span class="op">=</span> num_heads</span>
<span id="cb6-584"><a href="#cb6-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-585"><a href="#cb6-585" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_size <span class="op">=</span> image_size</span>
<span id="cb6-586"><a href="#cb6-586" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_channels <span class="op">=</span> in_channels</span>
<span id="cb6-587"><a href="#cb6-587" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_channels <span class="op">=</span> model_channels</span>
<span id="cb6-588"><a href="#cb6-588" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels</span>
<span id="cb6-589"><a href="#cb6-589" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_res_blocks <span class="op">=</span> num_res_blocks</span>
<span id="cb6-590"><a href="#cb6-590" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention_resolutions <span class="op">=</span> attention_resolutions</span>
<span id="cb6-591"><a href="#cb6-591" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb6-592"><a href="#cb6-592" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channel_mult <span class="op">=</span> channel_mult</span>
<span id="cb6-593"><a href="#cb6-593" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_resample <span class="op">=</span> conv_resample</span>
<span id="cb6-594"><a href="#cb6-594" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_classes <span class="op">=</span> num_classes</span>
<span id="cb6-595"><a href="#cb6-595" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb6-596"><a href="#cb6-596" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dtype <span class="op">=</span> th.float16 <span class="cf">if</span> use_fp16 <span class="cf">else</span> th.float32</span>
<span id="cb6-597"><a href="#cb6-597" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb6-598"><a href="#cb6-598" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_head_channels <span class="op">=</span> num_head_channels</span>
<span id="cb6-599"><a href="#cb6-599" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads_upsample <span class="op">=</span> num_heads_upsample</span>
<span id="cb6-600"><a href="#cb6-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-601"><a href="#cb6-601" aria-hidden="true" tabindex="-1"></a>        time_embed_dim <span class="op">=</span> model_channels <span class="op">*</span> time_emb_factor</span>
<span id="cb6-602"><a href="#cb6-602" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time_embed <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-603"><a href="#cb6-603" aria-hidden="true" tabindex="-1"></a>            linear(model_channels, time_embed_dim),</span>
<span id="cb6-604"><a href="#cb6-604" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-605"><a href="#cb6-605" aria-hidden="true" tabindex="-1"></a>            linear(time_embed_dim, time_embed_dim),</span>
<span id="cb6-606"><a href="#cb6-606" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-607"><a href="#cb6-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-608"><a href="#cb6-608" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-609"><a href="#cb6-609" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.label_emb <span class="op">=</span> nn.Embedding(num_classes, time_embed_dim)</span>
<span id="cb6-610"><a href="#cb6-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-611"><a href="#cb6-611" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> input_ch <span class="op">=</span> <span class="bu">int</span>(channel_mult[<span class="dv">0</span>] <span class="op">*</span> model_channels)</span>
<span id="cb6-612"><a href="#cb6-612" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_blocks <span class="op">=</span> nn.ModuleList(</span>
<span id="cb6-613"><a href="#cb6-613" aria-hidden="true" tabindex="-1"></a>            [TimestepEmbedSequential(conv_nd(dims, in_channels, ch, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>))]</span>
<span id="cb6-614"><a href="#cb6-614" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-615"><a href="#cb6-615" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_size <span class="op">=</span> ch</span>
<span id="cb6-616"><a href="#cb6-616" aria-hidden="true" tabindex="-1"></a>        input_block_chans <span class="op">=</span> [ch]</span>
<span id="cb6-617"><a href="#cb6-617" aria-hidden="true" tabindex="-1"></a>        ds <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-618"><a href="#cb6-618" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> level, mult <span class="kw">in</span> <span class="bu">enumerate</span>(channel_mult):</span>
<span id="cb6-619"><a href="#cb6-619" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks):</span>
<span id="cb6-620"><a href="#cb6-620" aria-hidden="true" tabindex="-1"></a>                layers <span class="op">=</span> [</span>
<span id="cb6-621"><a href="#cb6-621" aria-hidden="true" tabindex="-1"></a>                    ResBlock(</span>
<span id="cb6-622"><a href="#cb6-622" aria-hidden="true" tabindex="-1"></a>                        ch,</span>
<span id="cb6-623"><a href="#cb6-623" aria-hidden="true" tabindex="-1"></a>                        time_embed_dim,</span>
<span id="cb6-624"><a href="#cb6-624" aria-hidden="true" tabindex="-1"></a>                        dropout,</span>
<span id="cb6-625"><a href="#cb6-625" aria-hidden="true" tabindex="-1"></a>                        out_channels<span class="op">=</span><span class="bu">int</span>(mult <span class="op">*</span> model_channels),</span>
<span id="cb6-626"><a href="#cb6-626" aria-hidden="true" tabindex="-1"></a>                        dims<span class="op">=</span>dims,</span>
<span id="cb6-627"><a href="#cb6-627" aria-hidden="true" tabindex="-1"></a>                        use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-628"><a href="#cb6-628" aria-hidden="true" tabindex="-1"></a>                        use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-629"><a href="#cb6-629" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-630"><a href="#cb6-630" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb6-631"><a href="#cb6-631" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> <span class="bu">int</span>(mult <span class="op">*</span> model_channels)</span>
<span id="cb6-632"><a href="#cb6-632" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> ds <span class="kw">in</span> attention_resolutions:</span>
<span id="cb6-633"><a href="#cb6-633" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb6-634"><a href="#cb6-634" aria-hidden="true" tabindex="-1"></a>                        AttentionBlock(</span>
<span id="cb6-635"><a href="#cb6-635" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-636"><a href="#cb6-636" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-637"><a href="#cb6-637" aria-hidden="true" tabindex="-1"></a>                            num_heads<span class="op">=</span>num_heads,</span>
<span id="cb6-638"><a href="#cb6-638" aria-hidden="true" tabindex="-1"></a>                            num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb6-639"><a href="#cb6-639" aria-hidden="true" tabindex="-1"></a>                            use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb6-640"><a href="#cb6-640" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-641"><a href="#cb6-641" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-642"><a href="#cb6-642" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.input_blocks.append(TimestepEmbedSequential(<span class="op">*</span>layers))</span>
<span id="cb6-643"><a href="#cb6-643" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-644"><a href="#cb6-644" aria-hidden="true" tabindex="-1"></a>                input_block_chans.append(ch)</span>
<span id="cb6-645"><a href="#cb6-645" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> level <span class="op">!=</span> <span class="bu">len</span>(channel_mult) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb6-646"><a href="#cb6-646" aria-hidden="true" tabindex="-1"></a>                out_ch <span class="op">=</span> ch</span>
<span id="cb6-647"><a href="#cb6-647" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.input_blocks.append(</span>
<span id="cb6-648"><a href="#cb6-648" aria-hidden="true" tabindex="-1"></a>                    TimestepEmbedSequential(</span>
<span id="cb6-649"><a href="#cb6-649" aria-hidden="true" tabindex="-1"></a>                        ResBlock(</span>
<span id="cb6-650"><a href="#cb6-650" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-651"><a href="#cb6-651" aria-hidden="true" tabindex="-1"></a>                            time_embed_dim,</span>
<span id="cb6-652"><a href="#cb6-652" aria-hidden="true" tabindex="-1"></a>                            dropout,</span>
<span id="cb6-653"><a href="#cb6-653" aria-hidden="true" tabindex="-1"></a>                            out_channels<span class="op">=</span>out_ch,</span>
<span id="cb6-654"><a href="#cb6-654" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>dims,</span>
<span id="cb6-655"><a href="#cb6-655" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-656"><a href="#cb6-656" aria-hidden="true" tabindex="-1"></a>                            use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-657"><a href="#cb6-657" aria-hidden="true" tabindex="-1"></a>                            down<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-658"><a href="#cb6-658" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-659"><a href="#cb6-659" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> resblock_updown</span>
<span id="cb6-660"><a href="#cb6-660" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> Downsample(</span>
<span id="cb6-661"><a href="#cb6-661" aria-hidden="true" tabindex="-1"></a>                            ch, conv_resample, dims<span class="op">=</span>dims, out_channels<span class="op">=</span>out_ch</span>
<span id="cb6-662"><a href="#cb6-662" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-663"><a href="#cb6-663" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-664"><a href="#cb6-664" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb6-665"><a href="#cb6-665" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> out_ch</span>
<span id="cb6-666"><a href="#cb6-666" aria-hidden="true" tabindex="-1"></a>                input_block_chans.append(ch)</span>
<span id="cb6-667"><a href="#cb6-667" aria-hidden="true" tabindex="-1"></a>                ds <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb6-668"><a href="#cb6-668" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-669"><a href="#cb6-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-670"><a href="#cb6-670" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.middle_block <span class="op">=</span> TimestepEmbedSequential(</span>
<span id="cb6-671"><a href="#cb6-671" aria-hidden="true" tabindex="-1"></a>            ResBlock(</span>
<span id="cb6-672"><a href="#cb6-672" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb6-673"><a href="#cb6-673" aria-hidden="true" tabindex="-1"></a>                time_embed_dim,</span>
<span id="cb6-674"><a href="#cb6-674" aria-hidden="true" tabindex="-1"></a>                dropout,</span>
<span id="cb6-675"><a href="#cb6-675" aria-hidden="true" tabindex="-1"></a>                dims<span class="op">=</span>dims,</span>
<span id="cb6-676"><a href="#cb6-676" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-677"><a href="#cb6-677" aria-hidden="true" tabindex="-1"></a>                use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-678"><a href="#cb6-678" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-679"><a href="#cb6-679" aria-hidden="true" tabindex="-1"></a>            AttentionBlock(</span>
<span id="cb6-680"><a href="#cb6-680" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb6-681"><a href="#cb6-681" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-682"><a href="#cb6-682" aria-hidden="true" tabindex="-1"></a>                num_heads<span class="op">=</span>num_heads,</span>
<span id="cb6-683"><a href="#cb6-683" aria-hidden="true" tabindex="-1"></a>                num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb6-684"><a href="#cb6-684" aria-hidden="true" tabindex="-1"></a>                use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb6-685"><a href="#cb6-685" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-686"><a href="#cb6-686" aria-hidden="true" tabindex="-1"></a>            ResBlock(</span>
<span id="cb6-687"><a href="#cb6-687" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb6-688"><a href="#cb6-688" aria-hidden="true" tabindex="-1"></a>                time_embed_dim,</span>
<span id="cb6-689"><a href="#cb6-689" aria-hidden="true" tabindex="-1"></a>                dropout,</span>
<span id="cb6-690"><a href="#cb6-690" aria-hidden="true" tabindex="-1"></a>                dims<span class="op">=</span>dims,</span>
<span id="cb6-691"><a href="#cb6-691" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-692"><a href="#cb6-692" aria-hidden="true" tabindex="-1"></a>                use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-693"><a href="#cb6-693" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-694"><a href="#cb6-694" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-695"><a href="#cb6-695" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-696"><a href="#cb6-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-697"><a href="#cb6-697" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_blocks <span class="op">=</span> nn.ModuleList([])</span>
<span id="cb6-698"><a href="#cb6-698" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> level, mult <span class="kw">in</span> <span class="bu">list</span>(<span class="bu">enumerate</span>(channel_mult))[::<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb6-699"><a href="#cb6-699" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb6-700"><a href="#cb6-700" aria-hidden="true" tabindex="-1"></a>                ich <span class="op">=</span> input_block_chans.pop()</span>
<span id="cb6-701"><a href="#cb6-701" aria-hidden="true" tabindex="-1"></a>                layers <span class="op">=</span> [</span>
<span id="cb6-702"><a href="#cb6-702" aria-hidden="true" tabindex="-1"></a>                    ResBlock(</span>
<span id="cb6-703"><a href="#cb6-703" aria-hidden="true" tabindex="-1"></a>                        ch <span class="op">+</span> ich,</span>
<span id="cb6-704"><a href="#cb6-704" aria-hidden="true" tabindex="-1"></a>                        time_embed_dim,</span>
<span id="cb6-705"><a href="#cb6-705" aria-hidden="true" tabindex="-1"></a>                        dropout,</span>
<span id="cb6-706"><a href="#cb6-706" aria-hidden="true" tabindex="-1"></a>                        out_channels<span class="op">=</span><span class="bu">int</span>(model_channels <span class="op">*</span> mult),</span>
<span id="cb6-707"><a href="#cb6-707" aria-hidden="true" tabindex="-1"></a>                        dims<span class="op">=</span>dims,</span>
<span id="cb6-708"><a href="#cb6-708" aria-hidden="true" tabindex="-1"></a>                        use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-709"><a href="#cb6-709" aria-hidden="true" tabindex="-1"></a>                        use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-710"><a href="#cb6-710" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-711"><a href="#cb6-711" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb6-712"><a href="#cb6-712" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> <span class="bu">int</span>(model_channels <span class="op">*</span> mult)</span>
<span id="cb6-713"><a href="#cb6-713" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> ds <span class="kw">in</span> attention_resolutions:</span>
<span id="cb6-714"><a href="#cb6-714" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb6-715"><a href="#cb6-715" aria-hidden="true" tabindex="-1"></a>                        AttentionBlock(</span>
<span id="cb6-716"><a href="#cb6-716" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-717"><a href="#cb6-717" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-718"><a href="#cb6-718" aria-hidden="true" tabindex="-1"></a>                            num_heads<span class="op">=</span>num_heads_upsample,</span>
<span id="cb6-719"><a href="#cb6-719" aria-hidden="true" tabindex="-1"></a>                            num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb6-720"><a href="#cb6-720" aria-hidden="true" tabindex="-1"></a>                            use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb6-721"><a href="#cb6-721" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-722"><a href="#cb6-722" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-723"><a href="#cb6-723" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> level <span class="kw">and</span> i <span class="op">==</span> num_res_blocks:</span>
<span id="cb6-724"><a href="#cb6-724" aria-hidden="true" tabindex="-1"></a>                    out_ch <span class="op">=</span> ch</span>
<span id="cb6-725"><a href="#cb6-725" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb6-726"><a href="#cb6-726" aria-hidden="true" tabindex="-1"></a>                        ResBlock(</span>
<span id="cb6-727"><a href="#cb6-727" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-728"><a href="#cb6-728" aria-hidden="true" tabindex="-1"></a>                            time_embed_dim,</span>
<span id="cb6-729"><a href="#cb6-729" aria-hidden="true" tabindex="-1"></a>                            dropout,</span>
<span id="cb6-730"><a href="#cb6-730" aria-hidden="true" tabindex="-1"></a>                            out_channels<span class="op">=</span>out_ch,</span>
<span id="cb6-731"><a href="#cb6-731" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>dims,</span>
<span id="cb6-732"><a href="#cb6-732" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-733"><a href="#cb6-733" aria-hidden="true" tabindex="-1"></a>                            use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-734"><a href="#cb6-734" aria-hidden="true" tabindex="-1"></a>                            up<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-735"><a href="#cb6-735" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-736"><a href="#cb6-736" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> resblock_updown</span>
<span id="cb6-737"><a href="#cb6-737" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> Upsample(ch, conv_resample, dims<span class="op">=</span>dims, out_channels<span class="op">=</span>out_ch)</span>
<span id="cb6-738"><a href="#cb6-738" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-739"><a href="#cb6-739" aria-hidden="true" tabindex="-1"></a>                    ds <span class="op">//=</span> <span class="dv">2</span></span>
<span id="cb6-740"><a href="#cb6-740" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.output_blocks.append(TimestepEmbedSequential(<span class="op">*</span>layers))</span>
<span id="cb6-741"><a href="#cb6-741" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-742"><a href="#cb6-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-743"><a href="#cb6-743" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-744"><a href="#cb6-744" aria-hidden="true" tabindex="-1"></a>            normalization(ch),</span>
<span id="cb6-745"><a href="#cb6-745" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-746"><a href="#cb6-746" aria-hidden="true" tabindex="-1"></a>            zero_module(conv_nd(dims, input_ch, out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb6-747"><a href="#cb6-747" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-748"><a href="#cb6-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-749"><a href="#cb6-749" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, t, x, y<span class="op">=</span><span class="va">None</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-750"><a href="#cb6-750" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-751"><a href="#cb6-751" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the model to an input batch.</span></span>
<span id="cb6-752"><a href="#cb6-752" aria-hidden="true" tabindex="-1"></a><span class="co">        :param t: a 1-D batch of timesteps.</span></span>
<span id="cb6-753"><a href="#cb6-753" aria-hidden="true" tabindex="-1"></a><span class="co">        :param x: an [N x C x ...] Tensor of inputs.</span></span>
<span id="cb6-754"><a href="#cb6-754" aria-hidden="true" tabindex="-1"></a><span class="co">        :param y: an [N] Tensor of labels, if class-conditional.</span></span>
<span id="cb6-755"><a href="#cb6-755" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x C x ...] Tensor of outputs.</span></span>
<span id="cb6-756"><a href="#cb6-756" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-757"><a href="#cb6-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-758"><a href="#cb6-758" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> (y <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>) <span class="op">==</span> (</span>
<span id="cb6-759"><a href="#cb6-759" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb6-760"><a href="#cb6-760" aria-hidden="true" tabindex="-1"></a>        ), <span class="st">"must specify y if and only if the model is class-conditional"</span></span>
<span id="cb6-761"><a href="#cb6-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-762"><a href="#cb6-762" aria-hidden="true" tabindex="-1"></a>        hs <span class="op">=</span> []</span>
<span id="cb6-763"><a href="#cb6-763" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> <span class="va">self</span>.time_embed(timestep_embedding(t, <span class="va">self</span>.model_channels))</span>
<span id="cb6-764"><a href="#cb6-764" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-765"><a href="#cb6-765" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> y.shape <span class="op">==</span> (x.shape[<span class="dv">0</span>],)</span>
<span id="cb6-766"><a href="#cb6-766" aria-hidden="true" tabindex="-1"></a>            emb <span class="op">=</span> emb <span class="op">+</span> <span class="va">self</span>.label_emb(y)</span>
<span id="cb6-767"><a href="#cb6-767" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> x.<span class="bu">type</span>(<span class="va">self</span>.dtype)</span>
<span id="cb6-768"><a href="#cb6-768" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.input_blocks:</span>
<span id="cb6-769"><a href="#cb6-769" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> module(h, emb)</span>
<span id="cb6-770"><a href="#cb6-770" aria-hidden="true" tabindex="-1"></a>            hs.append(h)</span>
<span id="cb6-771"><a href="#cb6-771" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.middle_block(h, emb)</span>
<span id="cb6-772"><a href="#cb6-772" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.output_blocks:</span>
<span id="cb6-773"><a href="#cb6-773" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> th.cat([h, hs.pop()], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-774"><a href="#cb6-774" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> module(h, emb)</span>
<span id="cb6-775"><a href="#cb6-775" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> h.<span class="bu">type</span>(x.dtype)</span>
<span id="cb6-776"><a href="#cb6-776" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out(h)</span>
<span id="cb6-777"><a href="#cb6-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-778"><a href="#cb6-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-779"><a href="#cb6-779" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNetBig(</span>
<span id="cb6-780"><a href="#cb6-780" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb6-781"><a href="#cb6-781" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-782"><a href="#cb6-782" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-783"><a href="#cb6-783" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">192</span>,</span>
<span id="cb6-784"><a href="#cb6-784" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-785"><a href="#cb6-785" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-786"><a href="#cb6-786" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb6-787"><a href="#cb6-787" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-788"><a href="#cb6-788" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb6-789"><a href="#cb6-789" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-790"><a href="#cb6-790" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb6-791"><a href="#cb6-791" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-792"><a href="#cb6-792" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-793"><a href="#cb6-793" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-794"><a href="#cb6-794" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-795"><a href="#cb6-795" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-796"><a href="#cb6-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-797"><a href="#cb6-797" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb6-798"><a href="#cb6-798" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-799"><a href="#cb6-799" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb6-800"><a href="#cb6-800" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-801"><a href="#cb6-801" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb6-802"><a href="#cb6-802" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb6-803"><a href="#cb6-803" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb6-804"><a href="#cb6-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-805"><a href="#cb6-805" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb6-806"><a href="#cb6-806" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb6-807"><a href="#cb6-807" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb6-808"><a href="#cb6-808" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb6-809"><a href="#cb6-809" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb6-810"><a href="#cb6-810" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-811"><a href="#cb6-811" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb6-812"><a href="#cb6-812" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb6-813"><a href="#cb6-813" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb6-814"><a href="#cb6-814" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb6-815"><a href="#cb6-815" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-816"><a href="#cb6-816" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-817"><a href="#cb6-817" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-818"><a href="#cb6-818" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-819"><a href="#cb6-819" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-820"><a href="#cb6-820" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-821"><a href="#cb6-821" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-822"><a href="#cb6-822" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-823"><a href="#cb6-823" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-824"><a href="#cb6-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-825"><a href="#cb6-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-826"><a href="#cb6-826" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNet(</span>
<span id="cb6-827"><a href="#cb6-827" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb6-828"><a href="#cb6-828" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-829"><a href="#cb6-829" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-830"><a href="#cb6-830" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-831"><a href="#cb6-831" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-832"><a href="#cb6-832" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-833"><a href="#cb6-833" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb6-834"><a href="#cb6-834" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-835"><a href="#cb6-835" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb6-836"><a href="#cb6-836" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-837"><a href="#cb6-837" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb6-838"><a href="#cb6-838" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-839"><a href="#cb6-839" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-840"><a href="#cb6-840" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-841"><a href="#cb6-841" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-842"><a href="#cb6-842" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-843"><a href="#cb6-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-844"><a href="#cb6-844" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb6-845"><a href="#cb6-845" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-846"><a href="#cb6-846" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb6-847"><a href="#cb6-847" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-848"><a href="#cb6-848" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb6-849"><a href="#cb6-849" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb6-850"><a href="#cb6-850" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb6-851"><a href="#cb6-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-852"><a href="#cb6-852" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb6-853"><a href="#cb6-853" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb6-854"><a href="#cb6-854" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb6-855"><a href="#cb6-855" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb6-856"><a href="#cb6-856" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb6-857"><a href="#cb6-857" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-858"><a href="#cb6-858" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb6-859"><a href="#cb6-859" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb6-860"><a href="#cb6-860" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb6-861"><a href="#cb6-861" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb6-862"><a href="#cb6-862" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-863"><a href="#cb6-863" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-864"><a href="#cb6-864" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-865"><a href="#cb6-865" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-866"><a href="#cb6-866" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-867"><a href="#cb6-867" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-868"><a href="#cb6-868" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-869"><a href="#cb6-869" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-870"><a href="#cb6-870" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-871"><a href="#cb6-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-872"><a href="#cb6-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-873"><a href="#cb6-873" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNetSmall(</span>
<span id="cb6-874"><a href="#cb6-874" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb6-875"><a href="#cb6-875" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-876"><a href="#cb6-876" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-877"><a href="#cb6-877" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb6-878"><a href="#cb6-878" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-879"><a href="#cb6-879" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-880"><a href="#cb6-880" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb6-881"><a href="#cb6-881" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-882"><a href="#cb6-882" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb6-883"><a href="#cb6-883" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-884"><a href="#cb6-884" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb6-885"><a href="#cb6-885" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-886"><a href="#cb6-886" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-887"><a href="#cb6-887" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-888"><a href="#cb6-888" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-889"><a href="#cb6-889" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-890"><a href="#cb6-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-891"><a href="#cb6-891" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb6-892"><a href="#cb6-892" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-893"><a href="#cb6-893" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb6-894"><a href="#cb6-894" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-895"><a href="#cb6-895" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb6-896"><a href="#cb6-896" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb6-897"><a href="#cb6-897" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb6-898"><a href="#cb6-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-899"><a href="#cb6-899" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb6-900"><a href="#cb6-900" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb6-901"><a href="#cb6-901" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb6-902"><a href="#cb6-902" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb6-903"><a href="#cb6-903" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb6-904"><a href="#cb6-904" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-905"><a href="#cb6-905" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb6-906"><a href="#cb6-906" aria-hidden="true" tabindex="-1"></a>        time_emb_factor<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-907"><a href="#cb6-907" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb6-908"><a href="#cb6-908" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb6-909"><a href="#cb6-909" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb6-910"><a href="#cb6-910" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-911"><a href="#cb6-911" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-912"><a href="#cb6-912" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-913"><a href="#cb6-913" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb6-914"><a href="#cb6-914" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-915"><a href="#cb6-915" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-916"><a href="#cb6-916" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-917"><a href="#cb6-917" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-918"><a href="#cb6-918" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-model-the-user-logic" class="level3">
<h3 class="anchored" data-anchor-id="create-model-the-user-logic">Create model (the user logic)</h3>
<div id="cell-13" class="cell" data-outputid="135b45ea-0a39-4376-ec4e-84370866d498" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>denoising_model <span class="op">=</span> UNet(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    image_size<span class="op">=</span>config.resolution,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"model params: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> denoising_model.parameters()) <span class="op">/</span> <span class="fl">1e6</span><span class="sc">:.2f}</span><span class="ss"> M"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>model params: 14.42 M</code></pre>
</div>
</div>
</section>
<section id="optimizer" class="level3">
<h3 class="anchored" data-anchor-id="optimizer">Optimizer</h3>
<div id="cell-15" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.AdamW(denoising_model.parameters(), lr<span class="op">=</span>config.learning_rate, weight_decay<span class="op">=</span>config.weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="diffusion-noise-schedule" class="level3">
<h3 class="anchored" data-anchor-id="diffusion-noise-schedule">Diffusion noise schedule</h3>
<div id="cell-17" class="cell" data-outputid="8f5d1c6a-a6ea-4e1e-9f87-69908e335cad" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>beta_min, beta_max <span class="op">=</span> <span class="fl">1e-4</span>, <span class="fl">0.02</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_min, beta_max = 1e-4, 1</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_min, beta_max = 0, 0.02</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_noise_schedule(n_T: <span class="bu">int</span>, device: torch.device) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, torch.Tensor]:</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    betas <span class="op">=</span> torch.linspace(beta_min, beta_max, n_T).to(device)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> betas</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    alphas_cumprod <span class="op">=</span> torch.cumprod(alphas, axis<span class="op">=</span><span class="dv">0</span>).to(device)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    alphas_cumprod_prev <span class="op">=</span> torch.cat([torch.ones(<span class="dv">1</span>).to(device), alphas_cumprod[:<span class="op">-</span><span class="dv">1</span>].to(device)])</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    sqrt_recip_alphas <span class="op">=</span> torch.sqrt(<span class="fl">1.0</span> <span class="op">/</span> alphas).to(device)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    sqrt_alphas_cumprod <span class="op">=</span> torch.sqrt(alphas_cumprod).to(device)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    sqrt_one_minus_alphas_cumprod <span class="op">=</span> torch.sqrt(<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    posterior_variance <span class="op">=</span> betas <span class="op">*</span> (<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod_prev) <span class="op">/</span> (<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"betas"</span>: betas,</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"alphas"</span>: alphas,</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"alphas_cumprod"</span>: alphas_cumprod,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_recip_alphas"</span>: sqrt_recip_alphas,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_alphas_cumprod"</span>: sqrt_alphas_cumprod,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_one_minus_alphas_cumprod"</span>: sqrt_one_minus_alphas_cumprod,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"posterior_variance"</span>: posterior_variance,</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>noise_schedule <span class="op">=</span> create_noise_schedule(config.num_denoising_steps, device)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the schedule</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"betas"</span>].cpu().numpy())</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"beta_t"</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"alphas_cumprod_t"</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"sqrt_alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"sqrt_alphas_cumprod_t"</span>)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"sqrt_one_minus_alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"sqrt_one_minus_alphas_cumprod_t"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train</h2>
<section id="forward-diffusion" class="level3">
<h3 class="anchored" data-anchor-id="forward-diffusion">Forward diffusion</h3>
<p>Forward diffusion can be considered as “data augmentation” in the training step. It adds noise to the data to challenge the model to be able to tell apart signal from noise. Diffusion is a particular way of adding noise, with much mathematical rigor.</p>
<div id="cell-20" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model components</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    _ts <span class="op">=</span> t.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> noise <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> torch.randn_like(x_0)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> _ts.<span class="bu">max</span>() <span class="op">&lt;</span> <span class="bu">len</span>(noise_schedule[<span class="st">"alphas_cumprod"</span>]), <span class="ss">f"t=</span><span class="sc">{</span>_ts<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss"> is larger than the length of noise_schedule: </span><span class="sc">{</span><span class="bu">len</span>(noise_schedule[<span class="st">'alphas_cumprod'</span>])<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][_ts]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (alpha_prod_t <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> x_0 <span class="op">+</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_prod_t) <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> noise</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t, noise</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualizing-forward-diffusion-on-an-image" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-forward-diffusion-on-an-image">Visualizing forward diffusion on an image</h3>
<div id="cell-22" class="cell" data-outputid="10c287ea-0fbb-450c-a9ac-cdb16bdfc9ac" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see what forward diffusion does.</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>x_0, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(val_dataloader))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>x_0 <span class="op">=</span> x_0.to(device)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>x_t_list <span class="op">=</span> []</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>common_noise <span class="op">=</span> torch.randn_like(x_0)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"x_0 std:", x_0[0].std().item())</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>noise_levels <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>]</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> noise_levels:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  t <span class="op">=</span> torch.full((x_0.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>device)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  x_t_list.append(forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span>common_noise)[<span class="dv">0</span>])</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (t, x_t) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(noise_levels, x_t_list)):</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print(x_t[0].min().item(), x_t[0].max().item())</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  plt.subplot(<span class="dv">1</span>, <span class="dv">10</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  plt.title(<span class="ss">f"t=</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">, std=</span><span class="sc">{</span>x_t[<span class="dv">0</span>]<span class="sc">.</span>std()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> x_t[<span class="dv">0</span>].cpu().numpy().transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>()) <span class="op">/</span> (img.<span class="bu">max</span>() <span class="op">-</span> img.<span class="bu">min</span>())</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> i <span class="op">&gt;=</span> <span class="dv">10</span>:</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="training-loop" class="level3">
<h3 class="anchored" data-anchor-id="training-loop">Training loop</h3>
<div id="cell-24" class="cell" data-outputid="5f8bbcb7-54a6-4bbf-ec87-362d0947b12c" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> MSELoss()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>denoising_model.train()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(denoising_model, steps<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Training on device:"</span>, device)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  max_train_steps <span class="op">=</span> steps</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  train_progress_bar <span class="op">=</span> tqdm(<span class="bu">enumerate</span>(itertools.cycle(train_dataloader)))</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  num_examples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> step, (x_0, _) <span class="kw">in</span> train_progress_bar:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    x_0 <span class="op">=</span> x_0.to(device)  <span class="co"># x_0 is the clean data to teach the model to generate</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn(x_0.shape).to(device)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.randint(<span class="dv">0</span>, config.num_denoising_steps, (x_0.shape[<span class="dv">0</span>],), device<span class="op">=</span>device).<span class="bu">long</span>()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    x_t, true_noise <span class="op">=</span> forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span>noise)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    predicted_noise <span class="op">=</span> denoising_model(t<span class="op">=</span>t, x<span class="op">=</span>x_t)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(predicted_noise, true_noise)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    loss.backward()<span class="op">;</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># torch.nn.utils.clip_grad_norm_(denoising_model.parameters(), 1)  # try commenting it out</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    train_progress_bar.set_postfix({<span class="st">"loss"</span>: loss.cpu().item()})</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    num_examples <span class="op">+=</span> <span class="bu">len</span>(x_0)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> step <span class="op">&gt;=</span> max_train_steps:</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f"Reached the max training steps:"</span>, max_train_steps)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"Trained on </span><span class="sc">{</span>num_examples<span class="sc">}</span><span class="ss"> examples."</span>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> loss</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c0eee08fa4c84a71a69c358e52053cf8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 100
Trained on 3232 examples.</code></pre>
</div>
</div>
</section>
</section>
<section id="generate" class="level2">
<h2 class="anchored" data-anchor-id="generate">Generate</h2>
<section id="the-sampling-algo" class="level3">
<h3 class="anchored" data-anchor-id="the-sampling-algo">The sampling algo</h3>
<div id="cell-27" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denoising_step(denoising_model, x_t, t, noise_schedule, thresholding<span class="op">=</span><span class="va">False</span>, clip_sample<span class="op">=</span><span class="va">True</span>, clip_sample_range<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the backward diffusion step, with the effect of denoising.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(t, <span class="bu">int</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> torch.full((x_t.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>x_t.device)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> t</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> denoising_model(t<span class="op">=</span>t_tensor, x<span class="op">=</span>x_t)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(model_output, <span class="st">"sample"</span>):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> model_output.sample</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract relevant values from noise_schedule</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># deal with t=0 case where t can be a tensor</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t_prev <span class="op">=</span> torch.where(t_tensor <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>                                    noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor <span class="op">-</span> <span class="dv">1</span>],</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>                                    torch.ones_like(t_tensor, device<span class="op">=</span>x_t.device))</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape alpha_prod_t_prev for proper broadcasting</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> alpha_prod_t.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t_prev <span class="op">=</span> alpha_prod_t_prev.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    beta_prod_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_prod_t</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    beta_prod_t_prev <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_prod_t_prev</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    current_alpha_t <span class="op">=</span> alpha_prod_t <span class="op">/</span> alpha_prod_t_prev</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    current_beta_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> current_alpha_t</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the previous sample mean</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    pred_original_sample <span class="op">=</span> (x_t <span class="op">-</span> beta_prod_t <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> model_output) <span class="op">/</span> alpha_prod_t <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clip_sample:</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        pred_original_sample <span class="op">=</span> torch.clamp(pred_original_sample, <span class="op">-</span>clip_sample_range, clip_sample_range)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the coefficients for pred_original_sample and current sample</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    pred_original_sample_coeff <span class="op">=</span> (alpha_prod_t_prev <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> current_beta_t) <span class="op">/</span> beta_prod_t</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    current_sample_coeff <span class="op">=</span> current_alpha_t <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> beta_prod_t_prev <span class="op">/</span> beta_prod_t</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the previous sample</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> pred_original_sample_coeff <span class="op">*</span> pred_original_sample <span class="op">+</span> current_sample_coeff <span class="op">*</span> x_t</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add noise</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.zeros_like(x_t)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    variance_noise <span class="op">=</span> torch.randn_like(x_t)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle t=0 case where t can be a tensor</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    non_zero_mask <span class="op">=</span> (t_tensor <span class="op">!=</span> <span class="dv">0</span>).<span class="bu">float</span>().view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> non_zero_mask <span class="op">*</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_prod_t_prev) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_prod_t) <span class="op">*</span> current_beta_t)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.clamp(variance, <span class="bu">min</span><span class="op">=</span><span class="fl">1e-20</span>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> pred_prev_sample <span class="op">+</span> (variance <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> variance_noise</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_prev_sample</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denoising_step_direct(</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    denoising_model,</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    x_t,</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    t,</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    noise_schedule,</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>    clip_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>    clip_sample_range<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the backward diffusion step, with the effect of denoising.</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(t, <span class="bu">int</span>):</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> torch.full((x_t.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>x_t.device)</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> t</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>        eps_theta <span class="op">=</span> denoising_model(t<span class="op">=</span>t_tensor, x<span class="op">=</span>x_t)</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(eps_theta, <span class="st">"sample"</span>):</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>        eps_theta <span class="op">=</span> eps_theta.sample</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract alphas from noise schedule</span></span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>    alpha_t <span class="op">=</span> noise_schedule[<span class="st">"alphas"</span>][t_tensor]</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>    alpha_t_cumprod <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor]</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape for broadcasting</span></span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a>    view_shape <span class="op">=</span> (<span class="op">-</span><span class="dv">1</span>,) <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">*</span> (x_t.ndim <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>    alpha_t <span class="op">=</span> alpha_t.view(<span class="op">*</span>view_shape)</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>    alpha_t_cumprod <span class="op">=</span> alpha_t_cumprod.view(<span class="op">*</span>view_shape)</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate epsilon factor</span></span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>    eps_factor <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod).sqrt()</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate mean for reverse process</span></span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> torch.sqrt(alpha_t)) <span class="op">*</span> (x_t <span class="op">-</span> eps_factor <span class="op">*</span> eps_theta)</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply clipping</span></span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if clip_sample:</span></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     mean = torch.clamp(mean, -clip_sample_range, clip_sample_range)</span></span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add noise scaled by variance for non-zero timesteps</span></span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn_like(x_t)</span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a>    beta_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_t</span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> beta_t <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod <span class="op">/</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod)</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.clamp(variance, <span class="bu">min</span><span class="op">=</span><span class="fl">1e-20</span>)  <span class="co"># Add clamp to prevent numerical instability</span></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mask out noise for t=0 timesteps</span></span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a>    non_zero_mask <span class="op">=</span> (t_tensor <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">float</span>().view(<span class="op">*</span>view_shape)</span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a>    noise_scale <span class="op">=</span> torch.sqrt(variance) <span class="op">*</span> non_zero_mask</span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> mean <span class="op">+</span> noise_scale <span class="op">*</span> noise</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply clipping</span></span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clip_sample:</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>        pred_prev_sample <span class="op">=</span> torch.clamp(pred_prev_sample, <span class="op">-</span>clip_sample_range, clip_sample_range)</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_prev_sample</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_samples_by_denoising(denoising_model, x_T, noise_schedule, n_T, device, thresholding<span class="op">=</span><span class="va">False</span>, clip_sample<span class="op">=</span><span class="va">True</span>, clip_sample_range<span class="op">=</span><span class="fl">1.0</span>, seed<span class="op">=</span><span class="dv">0</span>, method<span class="op">=</span><span class="st">"direct"</span>):</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the generation process.</span></span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> x_T.to(device)</span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a>    pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(n_T <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> pbar:</span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> method <span class="op">==</span> <span class="st">"direct"</span>:</span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> denoising_step_direct(denoising_model, x_t, t, noise_schedule, clip_sample, clip_sample_range)</span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> denoising_step(denoising_model, x_t, t, noise_schedule, thresholding, clip_sample, clip_sample_range)</span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a>        pbar.set_postfix({<span class="st">"std"</span>: x_t.std().item()})</span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print("raw x_t range", x_t.min(), x_t.max())</span></span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (x_t <span class="op">/</span> <span class="dv">2</span> <span class="op">+</span> <span class="fl">0.5</span>).clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print("after clamp", x_t.min(), x_t.max())</span></span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualize-sampled-images" class="level3">
<h3 class="anchored" data-anchor-id="visualize-sampled-images">Visualize sampled images</h3>
<div id="cell-29" class="cell" data-outputid="f8ea9e82-8f96-4cbf-8111-d3523a03523c" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the sampled images</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_sampled_images(method<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Loss of the denoising model:"</span>, loss.item())</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  x_T <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  x_sampled <span class="op">=</span> generate_samples_by_denoising(</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    denoising_model, x_T,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    noise_schedule, n_T<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    clip_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    clip_sample_range<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span>method,</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  x_sampled <span class="op">=</span> (x_sampled <span class="op">*</span> <span class="dv">255</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  sampled <span class="op">=</span> make_grid(x_sampled).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).cpu().numpy().astype(np.uint8)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  _ <span class="op">=</span> plt.imshow(sampled)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images(method<span class="op">=</span><span class="st">"direct"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.061633966863155365</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10e85508de2f4ad68a393c45cec3bd54","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-15-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-30" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.061633966863155365</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c3d5ca9976b04dda9ba4a7abd376ff17","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-16-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-some-more" class="level3">
<h3 class="anchored" data-anchor-id="train-some-more">Train some more</h3>
<div id="cell-32" class="cell" data-outputid="f75a00c2-d5b8-40b8-cb76-f9ee9b153ff5" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train some more</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ec41b2a4ea7e474ca3399a652bbce296","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 1000
Trained on 31998 examples.
loss: 0.02666069194674492</code></pre>
</div>
</div>
<div id="cell-33" class="cell" data-outputid="3fddfdf4-d80e-47f2-f4f9-2b8a515abe0f" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.02666069194674492</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7f2ef30a315a4e19a7c9533907eb96be","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-18-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-34" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images(method<span class="op">=</span><span class="st">"direct"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.02666069194674492</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"feb18119b53149f981173fc1189cd0b7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-19-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-even-more" class="level3">
<h3 class="anchored" data-anchor-id="train-even-more">Train even more</h3>
<div id="cell-36" class="cell" data-outputid="4afee568-bdf9-430b-876e-1f2816e6e175" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> g <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    g[<span class="st">'lr'</span>] <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># reduce learning rate</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7b3622b1500c4aa6b9436f5042c5d87e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 5000
Trained on 159828 examples.
loss: 0.06194191426038742
Loss of the denoising model: 0.06194191426038742</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"95f63b44ff004aaca1d506e047d41670","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-20-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="and-some-more" class="level3">
<h3 class="anchored" data-anchor-id="and-some-more">And, some more</h3>
<div id="cell-38" class="cell" data-outputid="d56c68d0-5586-4248-925f-0ae73056a1c6" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> g <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    g[<span class="st">'lr'</span>] <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># reduce learning rate</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5f39663da88c462b8306846b6b24f97e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 10000
Trained on 319624 examples.
loss: 0.028765305876731873
Loss of the denoising model: 0.028765305876731873</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7a002b34284a407aa02734178c3c86fc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-21-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-39" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e25a32e39bbc4ed4b88862c48ed44ea5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"04a04e7642904704b091d55b75d7aafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0511c75b13b24ac7a9b176df52129e07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"069b694b86394acf8f5faa461f5d3eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e4f9b259304302a261ec8764b3d72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c20bd7c5c644c3bce5ab928b8284be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"091762633712423c926d31d7420062fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a82f38232c74ae6beac08d705fbc240":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aec62e3c4544731a2780b65b62eb6a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_908d7b9ff8644df49b1c83ddb38f1e0f","placeholder":"​","style":"IPY_MODEL_0511c75b13b24ac7a9b176df52129e07","value":"100%"}},"0b984917930e4d2daa81be08ae4cb2e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bbd14d99c284ede80ec348ac6519076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ee3ed4db32b4e74aa27acd5c2cd506b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9df5ad68439e4a92994930f97f06463e","IPY_MODEL_eee89f8f48a54ac9b63df22a6036a3d3","IPY_MODEL_a1f2dd797f794d11b84b0b0faa73691e"],"layout":"IPY_MODEL_57b52910b9d84771b222292f22fb4c03"}},"116406195ae54436915610c992c7712d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11870333ac534f1bb948245b79f8ca5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11c93b786744467c9183fa4015cd6b76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4733482262f54e9ea9ed76fdb69bbaaa","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7e73e4ec0634cdfa66f0f6384896dc9","value":59}},"1325b49fca594dd0aa72c4917d044169":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_690142ae1d46418d854eaccd264f5a33","placeholder":"​","style":"IPY_MODEL_23a873f27f2b4fd3a754e621d88e0df1","value":""}},"15ddabb80b9d4d68a33cbf6eeb79f023":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bbdacaa845640118be28a222b614516":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a82f38232c74ae6beac08d705fbc240","placeholder":"​","style":"IPY_MODEL_37abc2a8c024497c833008eb0f4acdc5","value":" 59/1000 [00:02&lt;00:36, 25.48it/s, std=1]"}},"1d30484bd7af40d1bc9ef7f051a02aa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20af142079dd46348636f8be335bda81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23a873f27f2b4fd3a754e621d88e0df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24093408e2a14c3689c3a56c49b59eb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e4f9b259304302a261ec8764b3d72f","max":14630,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80927e843a5f4d8eb0ff014ecf79a16a","value":14630}},"2ce0dd3a7e704df8aa445338692f7820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31523e4acffc43379b965dd0729214cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"316b576e5513417c81d3bfde019cd94e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"323b40ae734847a5971df00030ffd202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aec62e3c4544731a2780b65b62eb6a9","IPY_MODEL_3efdd710357f4f1cb1c358e99dd99174","IPY_MODEL_3b136b9006674cffab93827f3ecf557e"],"layout":"IPY_MODEL_ec12eaff03404f5cb73019d439965362"}},"3358ed77dfe546ddaa66d33610c33b08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34019b31860f45f0920b74dd89dd3c9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3416498c265f4ab78d6c3afb3d34b208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_316b576e5513417c81d3bfde019cd94e","max":132588555,"min":0,"orientation":"horizontal","style":"IPY_MODEL_069b694b86394acf8f5faa461f5d3eb3","value":132588555}},"343c20931eed45078341f21e44bd8bed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3737b6c5fe7446ff9e79229cf7d1d6ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37abc2a8c024497c833008eb0f4acdc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"393703bd8fae4e02ac59936da8c9f59a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f41ba828156b41ba9b690c9e0bdbdea5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11870333ac534f1bb948245b79f8ca5c","value":1}},"3b136b9006674cffab93827f3ecf557e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70e3117594b4c6996897f5462383f3e","placeholder":"​","style":"IPY_MODEL_9849b3fe0b3c4e2baea1ce9791e5b63e","value":" 1000/1000 [00:48&lt;00:00, 18.41it/s, std=0.609]"}},"3b4dd3210aad4d1287329ca73acb3449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bef7665c9b14315b1479d605a7a9405":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c86d50c98ec4c6a92643a149b01ba0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e516edb99c048f696e08da2dfcc33ae","IPY_MODEL_efe15d8882b24e26981d9d88c94ce8a8","IPY_MODEL_ab6772c5f7794878bbb64306bc5af972"],"layout":"IPY_MODEL_8a69d7b1495a48a19dc9265de769af55"}},"3efdd710357f4f1cb1c358e99dd99174":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6828a915ee024b4e9619d97a73e0d53f","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20af142079dd46348636f8be335bda81","value":1000}},"45342bb8953d47a0941854fee6c23e4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46bd73d21fe04d85ac79b050efa2d348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4733482262f54e9ea9ed76fdb69bbaaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c7cc54c13144b61a137b2fa5b7434d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e516edb99c048f696e08da2dfcc33ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c6c547266245fda3b1443a18d9e960","placeholder":"​","style":"IPY_MODEL_31523e4acffc43379b965dd0729214cd","value":""}},"4eaed03beec6446e846a9ad191830ca7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a2df1e6ed940d5a7c48c4ed5077db4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c484507dbc16429f83191e2be1b77661","placeholder":"​","style":"IPY_MODEL_f0dbfe3d51f2453ca1cb4f8a83cd5ffd","value":" 100/? [00:20&lt;00:00,  5.77it/s, loss=0.0568]"}},"562e474564da4b1db302c573d86c5fc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"565489b7024045509b4f486228cbd812":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bac04a877244a5d9519b140560bbf46","placeholder":"​","style":"IPY_MODEL_2ce0dd3a7e704df8aa445338692f7820","value":"100%"}},"56b38e69c8984055909d72c8a112c495":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57b52910b9d84771b222292f22fb4c03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0d375601a14304baa35d08417e3d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf73b2b41d2e42cc8ad643c098de7b69","placeholder":"​","style":"IPY_MODEL_116406195ae54436915610c992c7712d","value":" 133M/133M [00:03&lt;00:00, 34.6MB/s]"}},"61d62a2ec60540969d2886143cbb5fb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6828a915ee024b4e9619d97a73e0d53f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"690142ae1d46418d854eaccd264f5a33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a5b3a68e9a441eafe984c868c994c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6bb12cdbe443b297cebc5c57b1d201":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cf20fee33b4fe4a3a13e18603923b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72105bbb98e94c529a92dd011395280a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"737f98f221974116917e83b8cbd6572f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c6c547266245fda3b1443a18d9e960":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab713c7e9344187bce06333a64a07b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9f4b079e2da49b2aa78eb827e97f17c","IPY_MODEL_f928cef14c724f1789733adbed20d7c7","IPY_MODEL_8ef5f869de0f43aaaf93eaebc6c2fc49"],"layout":"IPY_MODEL_f092fe6dd2234ff5ae9fd223087527c7"}},"7e3ef051d0884e5e9c31bf9af1285821":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec7943f2d6643f381405238b6a4d58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdfd015b50e8478db40df871a0e0760c","IPY_MODEL_ce6495b96c3541a0ae05c841ccfea5a2","IPY_MODEL_ee14c532db5946abb5b6bd8503c0987d"],"layout":"IPY_MODEL_34019b31860f45f0920b74dd89dd3c9f"}},"80927e843a5f4d8eb0ff014ecf79a16a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80935dc3f8844f0f92531b35d8274e0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836db012c54f4d1887d1ac5635b0bacf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1325b49fca594dd0aa72c4917d044169","IPY_MODEL_393703bd8fae4e02ac59936da8c9f59a","IPY_MODEL_55a2df1e6ed940d5a7c48c4ed5077db4"],"layout":"IPY_MODEL_a83ea576587e4be1b7188369f752e3a3"}},"83c9d9265843416d82e4c34afcde5f06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a69d7b1495a48a19dc9265de769af55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d19dac1130246eeb986253e30b29858":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8ef5f869de0f43aaaf93eaebc6c2fc49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7be0ede49164f8cb11494903dadc7ae","placeholder":"​","style":"IPY_MODEL_d545ee3a9e224b7fb8f3166dc2da9788","value":" 412/? [01:27&lt;00:00,  5.34it/s, loss=0.0537]"}},"908d7b9ff8644df49b1c83ddb38f1e0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911ad5c90fc84b9db9a6035ac22038aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94871be2b0af463c8d2d29e3eb11ab47","IPY_MODEL_11c93b786744467c9183fa4015cd6b76","IPY_MODEL_1bbdacaa845640118be28a222b614516"],"layout":"IPY_MODEL_6e6bb12cdbe443b297cebc5c57b1d201"}},"91566e775ba041e08bfdc9bf9bf9021b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3358ed77dfe546ddaa66d33610c33b08","max":13592289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c7cc54c13144b61a137b2fa5b7434d9","value":13592289}},"93d8b02d0438451f93d5d3285c042edf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94871be2b0af463c8d2d29e3eb11ab47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bef7665c9b14315b1479d605a7a9405","placeholder":"​","style":"IPY_MODEL_61d62a2ec60540969d2886143cbb5fb4","value":"  6%"}},"9636f001e46d44698f6b05b06a11aac2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97253397598a4ff88b3aea250f4ce488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3d274cb6ca747aebe9b13d23f733456","placeholder":"​","style":"IPY_MODEL_3737b6c5fe7446ff9e79229cf7d1d6ab","value":" 14630/14630 [00:00&lt;00:00, 18920.39 examples/s]"}},"9849b3fe0b3c4e2baea1ce9791e5b63e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bac04a877244a5d9519b140560bbf46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df5ad68439e4a92994930f97f06463e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e540d95436da46db961958b2f95e470c","placeholder":"​","style":"IPY_MODEL_0b984917930e4d2daa81be08ae4cb2e3","value":"Generating val split: 100%"}},"a14abff04e6748f9abfaac60ba80491a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_565489b7024045509b4f486228cbd812","IPY_MODEL_d562f66e77a04fd0a21ec627ef4e836e","IPY_MODEL_b215ab2b7dc547c18243460f6bd03307"],"layout":"IPY_MODEL_d4dfc8e846764ff19157516af2efbbd6"}},"a1f2dd797f794d11b84b0b0faa73691e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc4b4c2d5f6474b82c0aa525da80963","placeholder":"​","style":"IPY_MODEL_80935dc3f8844f0f92531b35d8274e0e","value":" 1500/1500 [00:00&lt;00:00, 12587.71 examples/s]"}},"a83ea576587e4be1b7188369f752e3a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6772c5f7794878bbb64306bc5af972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_091762633712423c926d31d7420062fb","placeholder":"​","style":"IPY_MODEL_3b4dd3210aad4d1287329ca73acb3449","value":" 412/? [01:18&lt;00:00,  6.69it/s, loss=0.044]"}},"b03e0fb1e87b4f4da5fb310165796af2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b075ace4d49b412daa113baefb97e239":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b113bc4e41a24547ba07dbf8572e59d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e39266507dcd40ef97bcef22fae30c35","IPY_MODEL_91566e775ba041e08bfdc9bf9bf9021b","IPY_MODEL_b128b30c717047e9bf38c24a0262641c"],"layout":"IPY_MODEL_4eaed03beec6446e846a9ad191830ca7"}},"b128b30c717047e9bf38c24a0262641c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_343c20931eed45078341f21e44bd8bed","placeholder":"​","style":"IPY_MODEL_04a04e7642904704b091d55b75d7aafd","value":" 13.6M/13.6M [00:00&lt;00:00, 42.1MB/s]"}},"b215ab2b7dc547c18243460f6bd03307":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e3ef051d0884e5e9c31bf9af1285821","placeholder":"​","style":"IPY_MODEL_b8e58ba8119f4dbd8e692dc282721706","value":" 1000/1000 [00:42&lt;00:00, 22.90it/s, std=0.361]"}},"b2505de75cd7482c92889f8f5f8b77de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5341358005b4feab7743c3a31c83c13","placeholder":"​","style":"IPY_MODEL_fa5abb0d23ca4a0c907f11127603ef03","value":"train-00000-of-00001.parquet: 100%"}},"b8e58ba8119f4dbd8e692dc282721706":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f4b079e2da49b2aa78eb827e97f17c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_737f98f221974116917e83b8cbd6572f","placeholder":"​","style":"IPY_MODEL_dd7c2aea9730499ba392af981b35a13c","value":""}},"bcc4b4c2d5f6474b82c0aa525da80963":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf73b2b41d2e42cc8ad643c098de7b69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d274cb6ca747aebe9b13d23f733456":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c484507dbc16429f83191e2be1b77661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c94a6ad8365d4bdab01059e8a807129d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc739e8196da4fa78d6510461487947e","IPY_MODEL_24093408e2a14c3689c3a56c49b59eb1","IPY_MODEL_97253397598a4ff88b3aea250f4ce488"],"layout":"IPY_MODEL_9636f001e46d44698f6b05b06a11aac2"}},"ce6495b96c3541a0ae05c841ccfea5a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54e6d1e22c24345b67b0f88e2e0f3e9","max":646,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83c9d9265843416d82e4c34afcde5f06","value":646}},"d4dfc8e846764ff19157516af2efbbd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d545ee3a9e224b7fb8f3166dc2da9788":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d562f66e77a04fd0a21ec627ef4e836e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f4c2d247d14135ade949074143a5bf","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93d8b02d0438451f93d5d3285c042edf","value":1000}},"d70e3117594b4c6996897f5462383f3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93e07d9cd22454e9551d8b069bbd1ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc0be83354814b1fb516faef5de175e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2505de75cd7482c92889f8f5f8b77de","IPY_MODEL_3416498c265f4ab78d6c3afb3d34b208","IPY_MODEL_5a0d375601a14304baa35d08417e3d64"],"layout":"IPY_MODEL_69a5b3a68e9a441eafe984c868c994c8"}},"dc739e8196da4fa78d6510461487947e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b075ace4d49b412daa113baefb97e239","placeholder":"​","style":"IPY_MODEL_46bd73d21fe04d85ac79b050efa2d348","value":"Generating train split: 100%"}},"dd7c2aea9730499ba392af981b35a13c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e39266507dcd40ef97bcef22fae30c35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b03e0fb1e87b4f4da5fb310165796af2","placeholder":"​","style":"IPY_MODEL_56b38e69c8984055909d72c8a112c495","value":"val-00000-of-00001.parquet: 100%"}},"e5341358005b4feab7743c3a31c83c13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e540d95436da46db961958b2f95e470c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7be0ede49164f8cb11494903dadc7ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec12eaff03404f5cb73019d439965362":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee14c532db5946abb5b6bd8503c0987d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c20bd7c5c644c3bce5ab928b8284be","placeholder":"​","style":"IPY_MODEL_d93e07d9cd22454e9551d8b069bbd1ee","value":" 646/646 [00:00&lt;00:00, 17.5kB/s]"}},"eee89f8f48a54ac9b63df22a6036a3d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d30484bd7af40d1bc9ef7f051a02aa9","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_562e474564da4b1db302c573d86c5fc3","value":1500}},"efe15d8882b24e26981d9d88c94ce8a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72105bbb98e94c529a92dd011395280a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15ddabb80b9d4d68a33cbf6eeb79f023","value":1}},"f092fe6dd2234ff5ae9fd223087527c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0dbfe3d51f2453ca1cb4f8a83cd5ffd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f41ba828156b41ba9b690c9e0bdbdea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f54e6d1e22c24345b67b0f88e2e0f3e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e73e4ec0634cdfa66f0f6384896dc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8f4c2d247d14135ade949074143a5bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f928cef14c724f1789733adbed20d7c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d19dac1130246eeb986253e30b29858","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bbd14d99c284ede80ec348ac6519076","value":1}},"fa5abb0d23ca4a0c907f11127603ef03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdfd015b50e8478db40df871a0e0760c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45342bb8953d47a0941854fee6c23e4c","placeholder":"​","style":"IPY_MODEL_71cf20fee33b4fe4a3a13e18603923b7","value":"README.md: 100%"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kungfuai\.github\.io\/nano-diffusion\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>