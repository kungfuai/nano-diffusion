<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Training a Diffusion Model for Animal Face Images â€“ Nano Diffusion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./2_1_nano_diffusion_afhq.html">2.1 Diffusion for Animal Face Images</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Nano Diffusion</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/kungfuai/nano-diffusion.git" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_Diffusion 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1 Diffusion for a 2D Point Cloud</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_a_refactor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1a Refactor</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_b_Diffusion_2D_hyperparams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.1b Experimenting with diffusion recipes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_2_Flow Matching 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1.2 Flow Matching for a 2D Point Cloud</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_1_nano_diffusion_afhq.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2.1 Diffusion for Animal Face Images</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_1_fid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.1 Evaluation: FID</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#training-configuration" id="toc-training-configuration" class="nav-link active" data-scroll-target="#training-configuration">Training Configuration</a></li>
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data">Load data</a></li>
  <li><a href="#create-model-components-for-diffusion" id="toc-create-model-components-for-diffusion" class="nav-link" data-scroll-target="#create-model-components-for-diffusion">Create model components for diffusion</a>
  <ul class="collapse">
  <li><a href="#library-code-for-model-architecture" id="toc-library-code-for-model-architecture" class="nav-link" data-scroll-target="#library-code-for-model-architecture">Library code for model architecture</a></li>
  <li><a href="#create-model-the-user-logic" id="toc-create-model-the-user-logic" class="nav-link" data-scroll-target="#create-model-the-user-logic">Create model (the user logic)</a></li>
  <li><a href="#optimizer" id="toc-optimizer" class="nav-link" data-scroll-target="#optimizer">Optimizer</a></li>
  <li><a href="#diffusion-noise-schedule" id="toc-diffusion-noise-schedule" class="nav-link" data-scroll-target="#diffusion-noise-schedule">Diffusion noise schedule</a></li>
  </ul></li>
  <li><a href="#train" id="toc-train" class="nav-link" data-scroll-target="#train">Train</a>
  <ul class="collapse">
  <li><a href="#forward-diffusion" id="toc-forward-diffusion" class="nav-link" data-scroll-target="#forward-diffusion">Forward diffusion</a></li>
  <li><a href="#visualizing-forward-diffusion-on-an-image" id="toc-visualizing-forward-diffusion-on-an-image" class="nav-link" data-scroll-target="#visualizing-forward-diffusion-on-an-image">Visualizing forward diffusion on an image</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training loop</a></li>
  </ul></li>
  <li><a href="#generate" id="toc-generate" class="nav-link" data-scroll-target="#generate">Generate</a>
  <ul class="collapse">
  <li><a href="#the-sampling-algo" id="toc-the-sampling-algo" class="nav-link" data-scroll-target="#the-sampling-algo">The sampling algo</a></li>
  <li><a href="#visualize-sampled-images" id="toc-visualize-sampled-images" class="nav-link" data-scroll-target="#visualize-sampled-images">Visualize sampled images</a></li>
  <li><a href="#train-some-more" id="toc-train-some-more" class="nav-link" data-scroll-target="#train-some-more">Train some more</a></li>
  <li><a href="#train-even-more" id="toc-train-even-more" class="nav-link" data-scroll-target="#train-even-more">Train even more</a></li>
  <li><a href="#and-some-more" id="toc-and-some-more" class="nav-link" data-scroll-target="#and-some-more">And, some more</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Training a Diffusion Model for Animal Face Images</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>(under construction)</p>
<div id="cell-2" class="cell" data-outputid="d2b5c8c3-27e8-442b-9f9f-cb83297d0063" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install datasets==3.0.2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> MSELoss</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> make_grid</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Tuple</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="training-configuration" class="level2">
<h2 class="anchored" data-anchor-id="training-configuration">Training Configuration</h2>
<div id="cell-5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrainingConfig:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    dataset: <span class="bu">str</span> <span class="op">=</span> <span class="st">"zzsi/afhq64_16k"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model architecture</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    resolution: <span class="bu">int</span> <span class="op">=</span> <span class="dv">64</span> <span class="co"># resolution of the image</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    num_denoising_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span> <span class="co"># number of timesteps</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop and optimizer</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    total_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100000</span>  <span class="co"># total number of training steps</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span> <span class="co"># batch size</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    learning_rate: <span class="bu">float</span> <span class="op">=</span> <span class="fl">5e-4</span> <span class="co"># initial learning rate</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-6</span> <span class="co"># weight decay</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data augmentation</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    random_flip: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span> <span class="co"># randomly flip images horizontally</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> TrainingConfig(resolution<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-data" class="level2">
<h2 class="anchored" data-anchor-id="load-data">Load data</h2>
<div id="cell-7" class="cell" data-outputid="ebcded33-8efd-4e60-d5ef-caf0ecd87062" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HuggingFaceDataset(Dataset):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset_path: <span class="bu">str</span>, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> load_dataset(dataset_path, split<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_key <span class="op">=</span> <span class="va">self</span>.find_image_key()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> find_image_key(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the dataset has the "image" key</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Can exapnd this to other common keys if needed</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"image"</span> <span class="kw">in</span> <span class="va">self</span>.dataset[<span class="dv">0</span>].keys():</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"image"</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">KeyError</span>(<span class="st">"Dataset does not have an 'image' key"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> <span class="va">self</span>.dataset[idx][<span class="va">self</span>.image_key]</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> image.convert(<span class="st">"RGB"</span>)  <span class="co"># Convert to RGB to ensure 3 channels</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># By default, set label to 0 to conform to current expected batch format</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, label</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(config: TrainingConfig) <span class="op">-&gt;</span> Tuple[DataLoader, DataLoader]:</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    resolution <span class="op">=</span> config.resolution</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    transforms_list <span class="op">=</span> [</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((resolution, resolution)),</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)),</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> config.random_flip:</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        transforms_list.insert(<span class="dv">0</span>, transforms.RandomHorizontalFlip())</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose(transforms_list)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    full_dataset <span class="op">=</span> HuggingFaceDataset(config.dataset, transform<span class="op">=</span>transform)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.9</span> <span class="op">*</span> <span class="bu">len</span>(full_dataset))</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    val_size <span class="op">=</span> <span class="bu">len</span>(full_dataset) <span class="op">-</span> train_size</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    train_dataset, val_dataset <span class="op">=</span> random_split(full_dataset, [train_size, val_size])</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    train_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        train_dataset, batch_size<span class="op">=</span>config.batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    val_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>        val_dataset, batch_size<span class="op">=</span>config.batch_size, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_dataloader, val_dataloader</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>train_dataloader, val_dataloader <span class="op">=</span> load_data(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell" data-outputid="fd4bd221-815c-45dd-bc10-da980d048d3d" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dataloader))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>grid_img <span class="op">=</span> make_grid(x[<span class="dv">0</span>]).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>grid_img <span class="op">=</span> (grid_img <span class="op">-</span> grid_img.<span class="bu">min</span>()) <span class="op">/</span> (grid_img.<span class="bu">max</span>() <span class="op">-</span> grid_img.<span class="bu">min</span>())</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(grid_img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="create-model-components-for-diffusion" class="level2">
<h2 class="anchored" data-anchor-id="create-model-components-for-diffusion">Create model components for diffusion</h2>
<section id="library-code-for-model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="library-code-for-model-architecture">Library code for model architecture</h3>
<div id="cell-11" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">From: https://github.com/VSehwag/minimal-diffusion/blob/main/unets.py</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> abc <span class="im">import</span> abstractmethod</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch <span class="im">as</span> th</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GroupNorm32(nn.GroupNorm):</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">super</span>().forward(x.<span class="bu">float</span>()).<span class="bu">type</span>(x.dtype)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conv_nd(dims, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a 1D, 2D, or 3D convolution module.</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dims <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv1d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv3d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported dimensions: </span><span class="sc">{</span>dims<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a linear module.</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nn.Linear(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> avg_pool_nd(dims, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a 1D, 2D, or 3D average pooling module.</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dims <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool1d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool3d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported dimensions: </span><span class="sc">{</span>dims<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_ema(target_params, source_params, rate<span class="op">=</span><span class="fl">0.99</span>):</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a><span class="co">    Update target parameters to be closer to those of source parameters using</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a><span class="co">    an exponential moving average.</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co">    :param target_params: the target parameter sequence.</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="co">    :param source_params: the source parameter sequence.</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="co">    :param rate: the EMA rate (closer to 1 means slower).</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> targ, src <span class="kw">in</span> <span class="bu">zip</span>(target_params, source_params):</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>        targ.detach().mul_(rate).add_(src, alpha<span class="op">=</span><span class="dv">1</span> <span class="op">-</span> rate)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_module(module):</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a><span class="co">    Zero out the parameters of a module and return it.</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> module.parameters():</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>        p.detach().zero_()</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> module</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalization(channels):</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a><span class="co">    Make a standard normalization layer.</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: number of input channels.</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: an nn.Module for normalization.</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> GroupNorm32(<span class="dv">32</span>, channels)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> timestep_embedding(timesteps, dim, max_period<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a><span class="co">    Create sinusoidal timestep embeddings.</span></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a><span class="co">    :param timesteps: a 1-D Tensor of N indices, one per batch element.</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a><span class="co">                      These may be fractional.</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dim: the dimension of the output.</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a><span class="co">    :param max_period: controls the minimum frequency of the embeddings.</span></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: an [N x dim] Tensor of positional embeddings.</span></span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>    half <span class="op">=</span> dim <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> th.exp(</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>        <span class="op">-</span>math.log(max_period) <span class="op">*</span> th.arange(start<span class="op">=</span><span class="dv">0</span>, end<span class="op">=</span>half, dtype<span class="op">=</span>th.float32) <span class="op">/</span> half</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>    ).to(device<span class="op">=</span>timesteps.device)</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> timesteps.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> timesteps[:, <span class="va">None</span>].<span class="bu">float</span>() <span class="op">*</span> freqs[<span class="va">None</span>]</span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> timesteps.<span class="bu">float</span>() <span class="op">*</span> freqs[<span class="va">None</span>]</span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>    embedding <span class="op">=</span> th.cat([th.cos(args), th.sin(args)], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dim <span class="op">%</span> <span class="dv">2</span>:</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>        embedding <span class="op">=</span> th.cat([embedding, th.zeros_like(embedding[:, :<span class="dv">1</span>])], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embedding</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> checkpoint(func, inputs, params, flag):</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a><span class="co">    Evaluate a function without caching intermediate activations, allowing for</span></span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a><span class="co">    reduced memory at the expense of extra compute in the backward pass.</span></span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a><span class="co">    :param func: the function to evaluate.</span></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="co">    :param inputs: the argument sequence to pass to `func`.</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a><span class="co">    :param params: a sequence of parameters `func` depends on but does not</span></span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a><span class="co">                   explicitly take as arguments.</span></span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a><span class="co">    :param flag: if False, disable gradient checkpointing.</span></span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> flag:</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> <span class="bu">tuple</span>(inputs) <span class="op">+</span> <span class="bu">tuple</span>(params)</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> CheckpointFunction.<span class="bu">apply</span>(func, <span class="bu">len</span>(inputs), <span class="op">*</span>args)</span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> func(<span class="op">*</span>inputs)</span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CheckpointFunction(th.autograd.Function):</span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(ctx, run_function, length, <span class="op">*</span>args):</span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a>        ctx.run_function <span class="op">=</span> run_function</span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>        ctx.input_tensors <span class="op">=</span> <span class="bu">list</span>(args[:length])</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a>        ctx.input_params <span class="op">=</span> <span class="bu">list</span>(args[length:])</span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> th.no_grad():</span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>            output_tensors <span class="op">=</span> ctx.run_function(<span class="op">*</span>ctx.input_tensors)</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output_tensors</span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(ctx, <span class="op">*</span>output_grads):</span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a>        ctx.input_tensors <span class="op">=</span> [x.detach().requires_grad_(<span class="va">True</span>) <span class="cf">for</span> x <span class="kw">in</span> ctx.input_tensors]</span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> th.enable_grad():</span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fixes a bug where the first op in run_function modifies the</span></span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tensor storage in place, which is not allowed for detach()'d</span></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tensors.</span></span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a>            shallow_copies <span class="op">=</span> [x.view_as(x) <span class="cf">for</span> x <span class="kw">in</span> ctx.input_tensors]</span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a>            output_tensors <span class="op">=</span> ctx.run_function(<span class="op">*</span>shallow_copies)</span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a>        input_grads <span class="op">=</span> th.autograd.grad(</span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a>            output_tensors,</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a>            ctx.input_tensors <span class="op">+</span> ctx.input_params,</span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a>            output_grads,</span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a>            allow_unused<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> ctx.input_tensors</span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> ctx.input_params</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> output_tensors</span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">None</span>, <span class="va">None</span>) <span class="op">+</span> input_grads</span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionPool2d(nn.Module):</span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a><span class="co">    Adapted from CLIP: https://github.com/openai/CLIP/blob/main/clip/model.py</span></span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a>        spacial_dim: <span class="bu">int</span>,</span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a>        embed_dim: <span class="bu">int</span>,</span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a>        num_heads_channels: <span class="bu">int</span>,</span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a>        output_dim: <span class="bu">int</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positional_embedding <span class="op">=</span> nn.Parameter(</span>
<span id="cb6-170"><a href="#cb6-170" aria-hidden="true" tabindex="-1"></a>            th.randn(embed_dim, spacial_dim <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> embed_dim <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qkv_proj <span class="op">=</span> conv_nd(<span class="dv">1</span>, embed_dim, <span class="dv">3</span> <span class="op">*</span> embed_dim, <span class="dv">1</span>)</span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj <span class="op">=</span> conv_nd(<span class="dv">1</span>, embed_dim, output_dim <span class="kw">or</span> embed_dim, <span class="dv">1</span>)</span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> embed_dim <span class="op">//</span> num_heads_channels</span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> QKVAttention(<span class="va">self</span>.num_heads)</span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>        b, c, <span class="op">*</span>_spatial <span class="op">=</span> x.shape</span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(b, c, <span class="op">-</span><span class="dv">1</span>)  <span class="co"># NC(HW)</span></span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> th.cat([x.mean(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>), x], dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># NC(HW+1)</span></span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.positional_embedding[<span class="va">None</span>, :, :].to(x.dtype)  <span class="co"># NC(HW+1)</span></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.qkv_proj(x)</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attention(x)</span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.c_proj(x)</span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x[:, :, <span class="dv">0</span>]</span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimestepBlock(nn.Module):</span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a><span class="co">    Any module where forward() takes timestep embeddings as a second argument.</span></span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a>    <span class="at">@abstractmethod</span></span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the module to `x` given `emb` timestep embeddings.</span></span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimestepEmbedSequential(nn.Sequential, TimestepBlock):</span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a><span class="co">    A sequential module that passes timestep embeddings to the children that</span></span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a><span class="co">    support it as an extra input.</span></span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>:</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, TimestepBlock):</span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x, emb)</span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x)</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Upsample(nn.Module):</span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a><span class="co">    An upsampling layer with an optional convolution.</span></span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: channels in the inputs and outputs.</span></span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: a bool determining if a convolution is applied.</span></span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then</span></span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a><span class="co">                 upsampling occurs in the inner-two dimensions.</span></span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, use_conv, dims<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dims <span class="op">=</span> dims</span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_conv:</span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.conv <span class="op">=</span> conv_nd(dims, <span class="va">self</span>.channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> x.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="va">self</span>.channels</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.interpolate(</span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a>                x, (x.shape[<span class="dv">2</span>], x.shape[<span class="dv">3</span>] <span class="op">*</span> <span class="dv">2</span>, x.shape[<span class="dv">4</span>] <span class="op">*</span> <span class="dv">2</span>), mode<span class="op">=</span><span class="st">"nearest"</span></span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.interpolate(x, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">"nearest"</span>)</span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> x.shape[<span class="op">-</span><span class="dv">2</span>] <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>            <span class="co"># upsampling layer transform [3x3] to [6x6]. Manually paddding it to make [7x7]</span></span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.pad(out, (<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.use_conv:</span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.conv(out)</span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Downsample(nn.Module):</span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a><span class="co">    A downsampling layer with an optional convolution.</span></span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: channels in the inputs and outputs.</span></span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: a bool determining if a convolution is applied.</span></span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then</span></span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a><span class="co">                 downsampling occurs in the inner-two dimensions.</span></span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, use_conv, dims<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dims <span class="op">=</span> dims</span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> <span class="dv">2</span> <span class="cf">if</span> dims <span class="op">!=</span> <span class="dv">3</span> <span class="cf">else</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_conv:</span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.op <span class="op">=</span> conv_nd(</span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a>                dims, <span class="va">self</span>.channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, stride<span class="op">=</span>stride, padding<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> <span class="va">self</span>.channels <span class="op">==</span> <span class="va">self</span>.out_channels</span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.op <span class="op">=</span> avg_pool_nd(dims, kernel_size<span class="op">=</span>stride, stride<span class="op">=</span>stride)</span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> x.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="va">self</span>.channels</span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.op(x)</span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResBlock(TimestepBlock):</span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a><span class="co">    A residual block that can optionally change the number of channels.</span></span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: the number of input channels.</span></span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a><span class="co">    :param emb_channels: the number of timestep embedding channels.</span></span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dropout: the rate of dropout.</span></span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a><span class="co">    :param out_channels: if specified, the number of out channels.</span></span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: if True and out_channels is specified, use a spatial</span></span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a><span class="co">        convolution instead of a smaller 1x1 convolution to change the</span></span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a><span class="co">        channels in the skip connection.</span></span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D.</span></span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_checkpoint: if True, use gradient checkpointing on this module.</span></span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a><span class="co">    :param up: if True, use this block for upsampling.</span></span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a><span class="co">    :param down: if True, use this block for downsampling.</span></span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a>        channels,</span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a>        emb_channels,</span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a>        dropout,</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a>        use_conv<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a>        dims<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a>        up<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a>        down<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emb_channels <span class="op">=</span> emb_channels</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_scale_shift_norm <span class="op">=</span> use_scale_shift_norm</span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a>            normalization(channels),</span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a>            conv_nd(dims, channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.updown <span class="op">=</span> up <span class="kw">or</span> down</span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> up:</span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> Upsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.x_upd <span class="op">=</span> Upsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> down:</span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> Downsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.x_upd <span class="op">=</span> Downsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> <span class="va">self</span>.x_upd <span class="op">=</span> nn.Identity()</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emb_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a>            linear(</span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a>                emb_channels,</span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a>                <span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.out_channels <span class="cf">if</span> use_scale_shift_norm <span class="cf">else</span> <span class="va">self</span>.out_channels,</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a>            normalization(<span class="va">self</span>.out_channels),</span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span>dropout),</span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a>            zero_module(</span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a>                conv_nd(dims, <span class="va">self</span>.out_channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.out_channels <span class="op">==</span> channels:</span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> nn.Identity()</span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> use_conv:</span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> conv_nd(</span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a>                dims, channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> conv_nd(dims, channels, <span class="va">self</span>.out_channels, <span class="dv">1</span>)</span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the block to a Tensor, conditioned on a timestep embedding.</span></span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a><span class="co">        :param x: an [N x C x ...] Tensor of features.</span></span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a><span class="co">        :param emb: an [N x emb_channels] Tensor of timestep embeddings.</span></span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x C x ...] Tensor of outputs.</span></span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint(</span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._forward, (x, emb), <span class="va">self</span>.parameters(), <span class="va">self</span>.use_checkpoint</span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward(<span class="va">self</span>, x, emb):</span>
<span id="cb6-370"><a href="#cb6-370" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.updown:</span>
<span id="cb6-371"><a href="#cb6-371" aria-hidden="true" tabindex="-1"></a>            in_rest, in_conv <span class="op">=</span> <span class="va">self</span>.in_layers[:<span class="op">-</span><span class="dv">1</span>], <span class="va">self</span>.in_layers[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> in_rest(x)</span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.h_upd(h)</span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.x_upd(x)</span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> in_conv(h)</span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.in_layers(x)</span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a>        emb_out <span class="op">=</span> <span class="va">self</span>.emb_layers(emb).<span class="bu">type</span>(h.dtype)</span>
<span id="cb6-379"><a href="#cb6-379" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="bu">len</span>(emb_out.shape) <span class="op">&lt;</span> <span class="bu">len</span>(h.shape):</span>
<span id="cb6-380"><a href="#cb6-380" aria-hidden="true" tabindex="-1"></a>            emb_out <span class="op">=</span> emb_out[..., <span class="va">None</span>]</span>
<span id="cb6-381"><a href="#cb6-381" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.use_scale_shift_norm:</span>
<span id="cb6-382"><a href="#cb6-382" aria-hidden="true" tabindex="-1"></a>            out_norm, out_rest <span class="op">=</span> <span class="va">self</span>.out_layers[<span class="dv">0</span>], <span class="va">self</span>.out_layers[<span class="dv">1</span>:]</span>
<span id="cb6-383"><a href="#cb6-383" aria-hidden="true" tabindex="-1"></a>            scale, shift <span class="op">=</span> th.chunk(emb_out, <span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-384"><a href="#cb6-384" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> out_norm(h) <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> scale) <span class="op">+</span> shift</span>
<span id="cb6-385"><a href="#cb6-385" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> out_rest(h)</span>
<span id="cb6-386"><a href="#cb6-386" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-387"><a href="#cb6-387" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> h <span class="op">+</span> emb_out</span>
<span id="cb6-388"><a href="#cb6-388" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.out_layers(h)</span>
<span id="cb6-389"><a href="#cb6-389" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.skip_connection(x) <span class="op">+</span> h</span>
<span id="cb6-390"><a href="#cb6-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-391"><a href="#cb6-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-392"><a href="#cb6-392" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(nn.Module):</span>
<span id="cb6-393"><a href="#cb6-393" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-394"><a href="#cb6-394" aria-hidden="true" tabindex="-1"></a><span class="co">    An attention block that allows spatial positions to attend to each other.</span></span>
<span id="cb6-395"><a href="#cb6-395" aria-hidden="true" tabindex="-1"></a><span class="co">    Originally ported from here, but adapted to the N-d case.</span></span>
<span id="cb6-396"><a href="#cb6-396" aria-hidden="true" tabindex="-1"></a><span class="co">    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.</span></span>
<span id="cb6-397"><a href="#cb6-397" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-398"><a href="#cb6-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-399"><a href="#cb6-399" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-400"><a href="#cb6-400" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-401"><a href="#cb6-401" aria-hidden="true" tabindex="-1"></a>        channels,</span>
<span id="cb6-402"><a href="#cb6-402" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-403"><a href="#cb6-403" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-404"><a href="#cb6-404" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-405"><a href="#cb6-405" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-406"><a href="#cb6-406" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-407"><a href="#cb6-407" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-408"><a href="#cb6-408" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb6-409"><a href="#cb6-409" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_head_channels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb6-410"><a href="#cb6-410" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb6-411"><a href="#cb6-411" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-412"><a href="#cb6-412" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> (</span>
<span id="cb6-413"><a href="#cb6-413" aria-hidden="true" tabindex="-1"></a>                channels <span class="op">%</span> num_head_channels <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb6-414"><a href="#cb6-414" aria-hidden="true" tabindex="-1"></a>            ), <span class="ss">f"q,k,v channels </span><span class="sc">{</span>channels<span class="sc">}</span><span class="ss"> is not divisible by num_head_channels </span><span class="sc">{</span>num_head_channels<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb6-415"><a href="#cb6-415" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_heads <span class="op">=</span> channels <span class="op">//</span> num_head_channels</span>
<span id="cb6-416"><a href="#cb6-416" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb6-417"><a href="#cb6-417" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> normalization(channels)</span>
<span id="cb6-418"><a href="#cb6-418" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qkv <span class="op">=</span> conv_nd(<span class="dv">1</span>, channels, channels <span class="op">*</span> <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb6-419"><a href="#cb6-419" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_new_attention_order:</span>
<span id="cb6-420"><a href="#cb6-420" aria-hidden="true" tabindex="-1"></a>            <span class="co"># split qkv before split heads</span></span>
<span id="cb6-421"><a href="#cb6-421" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attention <span class="op">=</span> QKVAttention(<span class="va">self</span>.num_heads)</span>
<span id="cb6-422"><a href="#cb6-422" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-423"><a href="#cb6-423" aria-hidden="true" tabindex="-1"></a>            <span class="co"># split heads before split qkv</span></span>
<span id="cb6-424"><a href="#cb6-424" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attention <span class="op">=</span> QKVAttentionLegacy(<span class="va">self</span>.num_heads)</span>
<span id="cb6-425"><a href="#cb6-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-426"><a href="#cb6-426" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_out <span class="op">=</span> zero_module(conv_nd(<span class="dv">1</span>, channels, channels, <span class="dv">1</span>))</span>
<span id="cb6-427"><a href="#cb6-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-428"><a href="#cb6-428" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb6-429"><a href="#cb6-429" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint(<span class="va">self</span>._forward, (x,), <span class="va">self</span>.parameters(), <span class="va">True</span>)</span>
<span id="cb6-430"><a href="#cb6-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-431"><a href="#cb6-431" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward(<span class="va">self</span>, x):</span>
<span id="cb6-432"><a href="#cb6-432" aria-hidden="true" tabindex="-1"></a>        b, c, <span class="op">*</span>spatial <span class="op">=</span> x.shape</span>
<span id="cb6-433"><a href="#cb6-433" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(b, c, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb6-434"><a href="#cb6-434" aria-hidden="true" tabindex="-1"></a>        qkv <span class="op">=</span> <span class="va">self</span>.qkv(<span class="va">self</span>.norm(x))</span>
<span id="cb6-435"><a href="#cb6-435" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.attention(qkv)</span>
<span id="cb6-436"><a href="#cb6-436" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.proj_out(h)</span>
<span id="cb6-437"><a href="#cb6-437" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (x <span class="op">+</span> h).reshape(b, c, <span class="op">*</span>spatial)</span>
<span id="cb6-438"><a href="#cb6-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-439"><a href="#cb6-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-440"><a href="#cb6-440" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_flops_attn(model, _x, y):</span>
<span id="cb6-441"><a href="#cb6-441" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-442"><a href="#cb6-442" aria-hidden="true" tabindex="-1"></a><span class="co">    A counter for the `thop` package to count the operations in an</span></span>
<span id="cb6-443"><a href="#cb6-443" aria-hidden="true" tabindex="-1"></a><span class="co">    attention operation.</span></span>
<span id="cb6-444"><a href="#cb6-444" aria-hidden="true" tabindex="-1"></a><span class="co">    Meant to be used like:</span></span>
<span id="cb6-445"><a href="#cb6-445" aria-hidden="true" tabindex="-1"></a><span class="co">        macs, params = thop.profile(</span></span>
<span id="cb6-446"><a href="#cb6-446" aria-hidden="true" tabindex="-1"></a><span class="co">            model,</span></span>
<span id="cb6-447"><a href="#cb6-447" aria-hidden="true" tabindex="-1"></a><span class="co">            inputs=(inputs, timestamps),</span></span>
<span id="cb6-448"><a href="#cb6-448" aria-hidden="true" tabindex="-1"></a><span class="co">            custom_ops={QKVAttention: QKVAttention.count_flops},</span></span>
<span id="cb6-449"><a href="#cb6-449" aria-hidden="true" tabindex="-1"></a><span class="co">        )</span></span>
<span id="cb6-450"><a href="#cb6-450" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-451"><a href="#cb6-451" aria-hidden="true" tabindex="-1"></a>    b, c, <span class="op">*</span>spatial <span class="op">=</span> y[<span class="dv">0</span>].shape</span>
<span id="cb6-452"><a href="#cb6-452" aria-hidden="true" tabindex="-1"></a>    num_spatial <span class="op">=</span> <span class="bu">int</span>(np.prod(spatial))</span>
<span id="cb6-453"><a href="#cb6-453" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We perform two matmuls with the same number of ops.</span></span>
<span id="cb6-454"><a href="#cb6-454" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The first computes the weight matrix, the second computes</span></span>
<span id="cb6-455"><a href="#cb6-455" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the combination of the value vectors.</span></span>
<span id="cb6-456"><a href="#cb6-456" aria-hidden="true" tabindex="-1"></a>    matmul_ops <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> b <span class="op">*</span> (num_spatial <span class="op">**</span> <span class="dv">2</span>) <span class="op">*</span> c</span>
<span id="cb6-457"><a href="#cb6-457" aria-hidden="true" tabindex="-1"></a>    model.total_ops <span class="op">+=</span> th.DoubleTensor([matmul_ops])</span>
<span id="cb6-458"><a href="#cb6-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-459"><a href="#cb6-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-460"><a href="#cb6-460" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QKVAttentionLegacy(nn.Module):</span>
<span id="cb6-461"><a href="#cb6-461" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-462"><a href="#cb6-462" aria-hidden="true" tabindex="-1"></a><span class="co">    A module which performs QKV attention. Matches legacy QKVAttention + input/ouput heads shaping</span></span>
<span id="cb6-463"><a href="#cb6-463" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-464"><a href="#cb6-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-465"><a href="#cb6-465" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_heads):</span>
<span id="cb6-466"><a href="#cb6-466" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-467"><a href="#cb6-467" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb6-468"><a href="#cb6-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-469"><a href="#cb6-469" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, qkv):</span>
<span id="cb6-470"><a href="#cb6-470" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-471"><a href="#cb6-471" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply QKV attention.</span></span>
<span id="cb6-472"><a href="#cb6-472" aria-hidden="true" tabindex="-1"></a><span class="co">        :param qkv: an [N x (H * 3 * C) x T] tensor of Qs, Ks, and Vs.</span></span>
<span id="cb6-473"><a href="#cb6-473" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x (H * C) x T] tensor after attention.</span></span>
<span id="cb6-474"><a href="#cb6-474" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-475"><a href="#cb6-475" aria-hidden="true" tabindex="-1"></a>        bs, width, length <span class="op">=</span> qkv.shape</span>
<span id="cb6-476"><a href="#cb6-476" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> width <span class="op">%</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb6-477"><a href="#cb6-477" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> width <span class="op">//</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads)</span>
<span id="cb6-478"><a href="#cb6-478" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.reshape(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch <span class="op">*</span> <span class="dv">3</span>, length).split(ch, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-479"><a href="#cb6-479" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(math.sqrt(ch))</span>
<span id="cb6-480"><a href="#cb6-480" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.einsum(</span>
<span id="cb6-481"><a href="#cb6-481" aria-hidden="true" tabindex="-1"></a>            <span class="st">"bct,bcs-&gt;bts"</span>, q <span class="op">*</span> scale, k <span class="op">*</span> scale</span>
<span id="cb6-482"><a href="#cb6-482" aria-hidden="true" tabindex="-1"></a>        )  <span class="co"># More stable with f16 than dividing afterwards</span></span>
<span id="cb6-483"><a href="#cb6-483" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.softmax(weight.<span class="bu">float</span>(), dim<span class="op">=-</span><span class="dv">1</span>).<span class="bu">type</span>(weight.dtype)</span>
<span id="cb6-484"><a href="#cb6-484" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> th.einsum(<span class="st">"bts,bcs-&gt;bct"</span>, weight, v)</span>
<span id="cb6-485"><a href="#cb6-485" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a.reshape(bs, <span class="op">-</span><span class="dv">1</span>, length)</span>
<span id="cb6-486"><a href="#cb6-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-487"><a href="#cb6-487" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-488"><a href="#cb6-488" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> count_flops(model, _x, y):</span>
<span id="cb6-489"><a href="#cb6-489" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> count_flops_attn(model, _x, y)</span>
<span id="cb6-490"><a href="#cb6-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-491"><a href="#cb6-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-492"><a href="#cb6-492" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QKVAttention(nn.Module):</span>
<span id="cb6-493"><a href="#cb6-493" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-494"><a href="#cb6-494" aria-hidden="true" tabindex="-1"></a><span class="co">    A module which performs QKV attention and splits in a different order.</span></span>
<span id="cb6-495"><a href="#cb6-495" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-496"><a href="#cb6-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-497"><a href="#cb6-497" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_heads):</span>
<span id="cb6-498"><a href="#cb6-498" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-499"><a href="#cb6-499" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb6-500"><a href="#cb6-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-501"><a href="#cb6-501" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, qkv):</span>
<span id="cb6-502"><a href="#cb6-502" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-503"><a href="#cb6-503" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply QKV attention.</span></span>
<span id="cb6-504"><a href="#cb6-504" aria-hidden="true" tabindex="-1"></a><span class="co">        :param qkv: an [N x (3 * H * C) x T] tensor of Qs, Ks, and Vs.</span></span>
<span id="cb6-505"><a href="#cb6-505" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x (H * C) x T] tensor after attention.</span></span>
<span id="cb6-506"><a href="#cb6-506" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-507"><a href="#cb6-507" aria-hidden="true" tabindex="-1"></a>        bs, width, length <span class="op">=</span> qkv.shape</span>
<span id="cb6-508"><a href="#cb6-508" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> width <span class="op">%</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb6-509"><a href="#cb6-509" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> width <span class="op">//</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads)</span>
<span id="cb6-510"><a href="#cb6-510" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.chunk(<span class="dv">3</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-511"><a href="#cb6-511" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(math.sqrt(ch))</span>
<span id="cb6-512"><a href="#cb6-512" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.einsum(</span>
<span id="cb6-513"><a href="#cb6-513" aria-hidden="true" tabindex="-1"></a>            <span class="st">"bct,bcs-&gt;bts"</span>,</span>
<span id="cb6-514"><a href="#cb6-514" aria-hidden="true" tabindex="-1"></a>            (q <span class="op">*</span> scale).view(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length),</span>
<span id="cb6-515"><a href="#cb6-515" aria-hidden="true" tabindex="-1"></a>            (k <span class="op">*</span> scale).view(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length),</span>
<span id="cb6-516"><a href="#cb6-516" aria-hidden="true" tabindex="-1"></a>        )  <span class="co"># More stable with f16 than dividing afterwards</span></span>
<span id="cb6-517"><a href="#cb6-517" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.softmax(weight.<span class="bu">float</span>(), dim<span class="op">=-</span><span class="dv">1</span>).<span class="bu">type</span>(weight.dtype)</span>
<span id="cb6-518"><a href="#cb6-518" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> th.einsum(<span class="st">"bts,bcs-&gt;bct"</span>, weight, v.reshape(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length))</span>
<span id="cb6-519"><a href="#cb6-519" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a.reshape(bs, <span class="op">-</span><span class="dv">1</span>, length)</span>
<span id="cb6-520"><a href="#cb6-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-521"><a href="#cb6-521" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb6-522"><a href="#cb6-522" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> count_flops(model, _x, y):</span>
<span id="cb6-523"><a href="#cb6-523" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> count_flops_attn(model, _x, y)</span>
<span id="cb6-524"><a href="#cb6-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-525"><a href="#cb6-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-526"><a href="#cb6-526" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNetModel(nn.Module):</span>
<span id="cb6-527"><a href="#cb6-527" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-528"><a href="#cb6-528" aria-hidden="true" tabindex="-1"></a><span class="co">    The full UNet model with attention and timestep embedding.</span></span>
<span id="cb6-529"><a href="#cb6-529" aria-hidden="true" tabindex="-1"></a><span class="co">    :param in_channels: channels in the input Tensor.</span></span>
<span id="cb6-530"><a href="#cb6-530" aria-hidden="true" tabindex="-1"></a><span class="co">    :param emb_dim: base dimension of timestep embedding.</span></span>
<span id="cb6-531"><a href="#cb6-531" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_channels: base channel count for the model.</span></span>
<span id="cb6-532"><a href="#cb6-532" aria-hidden="true" tabindex="-1"></a><span class="co">    :param out_channels: channels in the output Tensor.</span></span>
<span id="cb6-533"><a href="#cb6-533" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_res_blocks: number of residual blocks per downsample.</span></span>
<span id="cb6-534"><a href="#cb6-534" aria-hidden="true" tabindex="-1"></a><span class="co">    :param attention_resolutions: a collection of downsample rates at which</span></span>
<span id="cb6-535"><a href="#cb6-535" aria-hidden="true" tabindex="-1"></a><span class="co">        attention will take place. May be a set, list, or tuple.</span></span>
<span id="cb6-536"><a href="#cb6-536" aria-hidden="true" tabindex="-1"></a><span class="co">        For example, if this contains 4, then at 4x downsampling, attention</span></span>
<span id="cb6-537"><a href="#cb6-537" aria-hidden="true" tabindex="-1"></a><span class="co">        will be used.</span></span>
<span id="cb6-538"><a href="#cb6-538" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dropout: the dropout probability.</span></span>
<span id="cb6-539"><a href="#cb6-539" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channel_mult: channel multiplier for each level of the UNet.</span></span>
<span id="cb6-540"><a href="#cb6-540" aria-hidden="true" tabindex="-1"></a><span class="co">    :param conv_resample: if True, use learned convolutions for upsampling and</span></span>
<span id="cb6-541"><a href="#cb6-541" aria-hidden="true" tabindex="-1"></a><span class="co">        downsampling.</span></span>
<span id="cb6-542"><a href="#cb6-542" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D.</span></span>
<span id="cb6-543"><a href="#cb6-543" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_classes: if specified (as an int), then this model will be</span></span>
<span id="cb6-544"><a href="#cb6-544" aria-hidden="true" tabindex="-1"></a><span class="co">        class-conditional with `num_classes` classes.</span></span>
<span id="cb6-545"><a href="#cb6-545" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_checkpoint: use gradient checkpointing to reduce memory usage.</span></span>
<span id="cb6-546"><a href="#cb6-546" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads: the number of attention heads in each attention layer.</span></span>
<span id="cb6-547"><a href="#cb6-547" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads_channels: if specified, ignore num_heads and instead use</span></span>
<span id="cb6-548"><a href="#cb6-548" aria-hidden="true" tabindex="-1"></a><span class="co">                               a fixed channel width per attention head.</span></span>
<span id="cb6-549"><a href="#cb6-549" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads_upsample: works with num_heads to set a different number</span></span>
<span id="cb6-550"><a href="#cb6-550" aria-hidden="true" tabindex="-1"></a><span class="co">                               of heads for upsampling. Deprecated.</span></span>
<span id="cb6-551"><a href="#cb6-551" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_scale_shift_norm: use a FiLM-like conditioning mechanism.</span></span>
<span id="cb6-552"><a href="#cb6-552" aria-hidden="true" tabindex="-1"></a><span class="co">    :param resblock_updown: use residual blocks for up/downsampling.</span></span>
<span id="cb6-553"><a href="#cb6-553" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_new_attention_order: use a different attention pattern for potentially</span></span>
<span id="cb6-554"><a href="#cb6-554" aria-hidden="true" tabindex="-1"></a><span class="co">                                    increased efficiency.</span></span>
<span id="cb6-555"><a href="#cb6-555" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-556"><a href="#cb6-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-557"><a href="#cb6-557" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb6-558"><a href="#cb6-558" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb6-559"><a href="#cb6-559" aria-hidden="true" tabindex="-1"></a>        image_size,</span>
<span id="cb6-560"><a href="#cb6-560" aria-hidden="true" tabindex="-1"></a>        in_channels,</span>
<span id="cb6-561"><a href="#cb6-561" aria-hidden="true" tabindex="-1"></a>        model_channels,</span>
<span id="cb6-562"><a href="#cb6-562" aria-hidden="true" tabindex="-1"></a>        out_channels,</span>
<span id="cb6-563"><a href="#cb6-563" aria-hidden="true" tabindex="-1"></a>        num_res_blocks,</span>
<span id="cb6-564"><a href="#cb6-564" aria-hidden="true" tabindex="-1"></a>        attention_resolutions,</span>
<span id="cb6-565"><a href="#cb6-565" aria-hidden="true" tabindex="-1"></a>        time_emb_factor<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-566"><a href="#cb6-566" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb6-567"><a href="#cb6-567" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>),</span>
<span id="cb6-568"><a href="#cb6-568" aria-hidden="true" tabindex="-1"></a>        conv_resample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-569"><a href="#cb6-569" aria-hidden="true" tabindex="-1"></a>        dims<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-570"><a href="#cb6-570" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-571"><a href="#cb6-571" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-572"><a href="#cb6-572" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-573"><a href="#cb6-573" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-574"><a href="#cb6-574" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-575"><a href="#cb6-575" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-576"><a href="#cb6-576" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-577"><a href="#cb6-577" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-578"><a href="#cb6-578" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-579"><a href="#cb6-579" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb6-580"><a href="#cb6-580" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-581"><a href="#cb6-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-582"><a href="#cb6-582" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_heads_upsample <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb6-583"><a href="#cb6-583" aria-hidden="true" tabindex="-1"></a>            num_heads_upsample <span class="op">=</span> num_heads</span>
<span id="cb6-584"><a href="#cb6-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-585"><a href="#cb6-585" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_size <span class="op">=</span> image_size</span>
<span id="cb6-586"><a href="#cb6-586" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_channels <span class="op">=</span> in_channels</span>
<span id="cb6-587"><a href="#cb6-587" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_channels <span class="op">=</span> model_channels</span>
<span id="cb6-588"><a href="#cb6-588" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels</span>
<span id="cb6-589"><a href="#cb6-589" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_res_blocks <span class="op">=</span> num_res_blocks</span>
<span id="cb6-590"><a href="#cb6-590" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention_resolutions <span class="op">=</span> attention_resolutions</span>
<span id="cb6-591"><a href="#cb6-591" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb6-592"><a href="#cb6-592" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channel_mult <span class="op">=</span> channel_mult</span>
<span id="cb6-593"><a href="#cb6-593" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_resample <span class="op">=</span> conv_resample</span>
<span id="cb6-594"><a href="#cb6-594" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_classes <span class="op">=</span> num_classes</span>
<span id="cb6-595"><a href="#cb6-595" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb6-596"><a href="#cb6-596" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dtype <span class="op">=</span> th.float16 <span class="cf">if</span> use_fp16 <span class="cf">else</span> th.float32</span>
<span id="cb6-597"><a href="#cb6-597" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb6-598"><a href="#cb6-598" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_head_channels <span class="op">=</span> num_head_channels</span>
<span id="cb6-599"><a href="#cb6-599" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads_upsample <span class="op">=</span> num_heads_upsample</span>
<span id="cb6-600"><a href="#cb6-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-601"><a href="#cb6-601" aria-hidden="true" tabindex="-1"></a>        time_embed_dim <span class="op">=</span> model_channels <span class="op">*</span> time_emb_factor</span>
<span id="cb6-602"><a href="#cb6-602" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time_embed <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-603"><a href="#cb6-603" aria-hidden="true" tabindex="-1"></a>            linear(model_channels, time_embed_dim),</span>
<span id="cb6-604"><a href="#cb6-604" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-605"><a href="#cb6-605" aria-hidden="true" tabindex="-1"></a>            linear(time_embed_dim, time_embed_dim),</span>
<span id="cb6-606"><a href="#cb6-606" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-607"><a href="#cb6-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-608"><a href="#cb6-608" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-609"><a href="#cb6-609" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.label_emb <span class="op">=</span> nn.Embedding(num_classes, time_embed_dim)</span>
<span id="cb6-610"><a href="#cb6-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-611"><a href="#cb6-611" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> input_ch <span class="op">=</span> <span class="bu">int</span>(channel_mult[<span class="dv">0</span>] <span class="op">*</span> model_channels)</span>
<span id="cb6-612"><a href="#cb6-612" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_blocks <span class="op">=</span> nn.ModuleList(</span>
<span id="cb6-613"><a href="#cb6-613" aria-hidden="true" tabindex="-1"></a>            [TimestepEmbedSequential(conv_nd(dims, in_channels, ch, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>))]</span>
<span id="cb6-614"><a href="#cb6-614" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-615"><a href="#cb6-615" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_size <span class="op">=</span> ch</span>
<span id="cb6-616"><a href="#cb6-616" aria-hidden="true" tabindex="-1"></a>        input_block_chans <span class="op">=</span> [ch]</span>
<span id="cb6-617"><a href="#cb6-617" aria-hidden="true" tabindex="-1"></a>        ds <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-618"><a href="#cb6-618" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> level, mult <span class="kw">in</span> <span class="bu">enumerate</span>(channel_mult):</span>
<span id="cb6-619"><a href="#cb6-619" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks):</span>
<span id="cb6-620"><a href="#cb6-620" aria-hidden="true" tabindex="-1"></a>                layers <span class="op">=</span> [</span>
<span id="cb6-621"><a href="#cb6-621" aria-hidden="true" tabindex="-1"></a>                    ResBlock(</span>
<span id="cb6-622"><a href="#cb6-622" aria-hidden="true" tabindex="-1"></a>                        ch,</span>
<span id="cb6-623"><a href="#cb6-623" aria-hidden="true" tabindex="-1"></a>                        time_embed_dim,</span>
<span id="cb6-624"><a href="#cb6-624" aria-hidden="true" tabindex="-1"></a>                        dropout,</span>
<span id="cb6-625"><a href="#cb6-625" aria-hidden="true" tabindex="-1"></a>                        out_channels<span class="op">=</span><span class="bu">int</span>(mult <span class="op">*</span> model_channels),</span>
<span id="cb6-626"><a href="#cb6-626" aria-hidden="true" tabindex="-1"></a>                        dims<span class="op">=</span>dims,</span>
<span id="cb6-627"><a href="#cb6-627" aria-hidden="true" tabindex="-1"></a>                        use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-628"><a href="#cb6-628" aria-hidden="true" tabindex="-1"></a>                        use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-629"><a href="#cb6-629" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-630"><a href="#cb6-630" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb6-631"><a href="#cb6-631" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> <span class="bu">int</span>(mult <span class="op">*</span> model_channels)</span>
<span id="cb6-632"><a href="#cb6-632" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> ds <span class="kw">in</span> attention_resolutions:</span>
<span id="cb6-633"><a href="#cb6-633" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb6-634"><a href="#cb6-634" aria-hidden="true" tabindex="-1"></a>                        AttentionBlock(</span>
<span id="cb6-635"><a href="#cb6-635" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-636"><a href="#cb6-636" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-637"><a href="#cb6-637" aria-hidden="true" tabindex="-1"></a>                            num_heads<span class="op">=</span>num_heads,</span>
<span id="cb6-638"><a href="#cb6-638" aria-hidden="true" tabindex="-1"></a>                            num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb6-639"><a href="#cb6-639" aria-hidden="true" tabindex="-1"></a>                            use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb6-640"><a href="#cb6-640" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-641"><a href="#cb6-641" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-642"><a href="#cb6-642" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.input_blocks.append(TimestepEmbedSequential(<span class="op">*</span>layers))</span>
<span id="cb6-643"><a href="#cb6-643" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-644"><a href="#cb6-644" aria-hidden="true" tabindex="-1"></a>                input_block_chans.append(ch)</span>
<span id="cb6-645"><a href="#cb6-645" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> level <span class="op">!=</span> <span class="bu">len</span>(channel_mult) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb6-646"><a href="#cb6-646" aria-hidden="true" tabindex="-1"></a>                out_ch <span class="op">=</span> ch</span>
<span id="cb6-647"><a href="#cb6-647" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.input_blocks.append(</span>
<span id="cb6-648"><a href="#cb6-648" aria-hidden="true" tabindex="-1"></a>                    TimestepEmbedSequential(</span>
<span id="cb6-649"><a href="#cb6-649" aria-hidden="true" tabindex="-1"></a>                        ResBlock(</span>
<span id="cb6-650"><a href="#cb6-650" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-651"><a href="#cb6-651" aria-hidden="true" tabindex="-1"></a>                            time_embed_dim,</span>
<span id="cb6-652"><a href="#cb6-652" aria-hidden="true" tabindex="-1"></a>                            dropout,</span>
<span id="cb6-653"><a href="#cb6-653" aria-hidden="true" tabindex="-1"></a>                            out_channels<span class="op">=</span>out_ch,</span>
<span id="cb6-654"><a href="#cb6-654" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>dims,</span>
<span id="cb6-655"><a href="#cb6-655" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-656"><a href="#cb6-656" aria-hidden="true" tabindex="-1"></a>                            use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-657"><a href="#cb6-657" aria-hidden="true" tabindex="-1"></a>                            down<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-658"><a href="#cb6-658" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-659"><a href="#cb6-659" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> resblock_updown</span>
<span id="cb6-660"><a href="#cb6-660" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> Downsample(</span>
<span id="cb6-661"><a href="#cb6-661" aria-hidden="true" tabindex="-1"></a>                            ch, conv_resample, dims<span class="op">=</span>dims, out_channels<span class="op">=</span>out_ch</span>
<span id="cb6-662"><a href="#cb6-662" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-663"><a href="#cb6-663" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-664"><a href="#cb6-664" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb6-665"><a href="#cb6-665" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> out_ch</span>
<span id="cb6-666"><a href="#cb6-666" aria-hidden="true" tabindex="-1"></a>                input_block_chans.append(ch)</span>
<span id="cb6-667"><a href="#cb6-667" aria-hidden="true" tabindex="-1"></a>                ds <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb6-668"><a href="#cb6-668" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-669"><a href="#cb6-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-670"><a href="#cb6-670" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.middle_block <span class="op">=</span> TimestepEmbedSequential(</span>
<span id="cb6-671"><a href="#cb6-671" aria-hidden="true" tabindex="-1"></a>            ResBlock(</span>
<span id="cb6-672"><a href="#cb6-672" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb6-673"><a href="#cb6-673" aria-hidden="true" tabindex="-1"></a>                time_embed_dim,</span>
<span id="cb6-674"><a href="#cb6-674" aria-hidden="true" tabindex="-1"></a>                dropout,</span>
<span id="cb6-675"><a href="#cb6-675" aria-hidden="true" tabindex="-1"></a>                dims<span class="op">=</span>dims,</span>
<span id="cb6-676"><a href="#cb6-676" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-677"><a href="#cb6-677" aria-hidden="true" tabindex="-1"></a>                use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-678"><a href="#cb6-678" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-679"><a href="#cb6-679" aria-hidden="true" tabindex="-1"></a>            AttentionBlock(</span>
<span id="cb6-680"><a href="#cb6-680" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb6-681"><a href="#cb6-681" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-682"><a href="#cb6-682" aria-hidden="true" tabindex="-1"></a>                num_heads<span class="op">=</span>num_heads,</span>
<span id="cb6-683"><a href="#cb6-683" aria-hidden="true" tabindex="-1"></a>                num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb6-684"><a href="#cb6-684" aria-hidden="true" tabindex="-1"></a>                use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb6-685"><a href="#cb6-685" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-686"><a href="#cb6-686" aria-hidden="true" tabindex="-1"></a>            ResBlock(</span>
<span id="cb6-687"><a href="#cb6-687" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb6-688"><a href="#cb6-688" aria-hidden="true" tabindex="-1"></a>                time_embed_dim,</span>
<span id="cb6-689"><a href="#cb6-689" aria-hidden="true" tabindex="-1"></a>                dropout,</span>
<span id="cb6-690"><a href="#cb6-690" aria-hidden="true" tabindex="-1"></a>                dims<span class="op">=</span>dims,</span>
<span id="cb6-691"><a href="#cb6-691" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-692"><a href="#cb6-692" aria-hidden="true" tabindex="-1"></a>                use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-693"><a href="#cb6-693" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb6-694"><a href="#cb6-694" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-695"><a href="#cb6-695" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-696"><a href="#cb6-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-697"><a href="#cb6-697" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_blocks <span class="op">=</span> nn.ModuleList([])</span>
<span id="cb6-698"><a href="#cb6-698" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> level, mult <span class="kw">in</span> <span class="bu">list</span>(<span class="bu">enumerate</span>(channel_mult))[::<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb6-699"><a href="#cb6-699" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb6-700"><a href="#cb6-700" aria-hidden="true" tabindex="-1"></a>                ich <span class="op">=</span> input_block_chans.pop()</span>
<span id="cb6-701"><a href="#cb6-701" aria-hidden="true" tabindex="-1"></a>                layers <span class="op">=</span> [</span>
<span id="cb6-702"><a href="#cb6-702" aria-hidden="true" tabindex="-1"></a>                    ResBlock(</span>
<span id="cb6-703"><a href="#cb6-703" aria-hidden="true" tabindex="-1"></a>                        ch <span class="op">+</span> ich,</span>
<span id="cb6-704"><a href="#cb6-704" aria-hidden="true" tabindex="-1"></a>                        time_embed_dim,</span>
<span id="cb6-705"><a href="#cb6-705" aria-hidden="true" tabindex="-1"></a>                        dropout,</span>
<span id="cb6-706"><a href="#cb6-706" aria-hidden="true" tabindex="-1"></a>                        out_channels<span class="op">=</span><span class="bu">int</span>(model_channels <span class="op">*</span> mult),</span>
<span id="cb6-707"><a href="#cb6-707" aria-hidden="true" tabindex="-1"></a>                        dims<span class="op">=</span>dims,</span>
<span id="cb6-708"><a href="#cb6-708" aria-hidden="true" tabindex="-1"></a>                        use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-709"><a href="#cb6-709" aria-hidden="true" tabindex="-1"></a>                        use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-710"><a href="#cb6-710" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-711"><a href="#cb6-711" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb6-712"><a href="#cb6-712" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> <span class="bu">int</span>(model_channels <span class="op">*</span> mult)</span>
<span id="cb6-713"><a href="#cb6-713" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> ds <span class="kw">in</span> attention_resolutions:</span>
<span id="cb6-714"><a href="#cb6-714" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb6-715"><a href="#cb6-715" aria-hidden="true" tabindex="-1"></a>                        AttentionBlock(</span>
<span id="cb6-716"><a href="#cb6-716" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-717"><a href="#cb6-717" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-718"><a href="#cb6-718" aria-hidden="true" tabindex="-1"></a>                            num_heads<span class="op">=</span>num_heads_upsample,</span>
<span id="cb6-719"><a href="#cb6-719" aria-hidden="true" tabindex="-1"></a>                            num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb6-720"><a href="#cb6-720" aria-hidden="true" tabindex="-1"></a>                            use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb6-721"><a href="#cb6-721" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-722"><a href="#cb6-722" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-723"><a href="#cb6-723" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> level <span class="kw">and</span> i <span class="op">==</span> num_res_blocks:</span>
<span id="cb6-724"><a href="#cb6-724" aria-hidden="true" tabindex="-1"></a>                    out_ch <span class="op">=</span> ch</span>
<span id="cb6-725"><a href="#cb6-725" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb6-726"><a href="#cb6-726" aria-hidden="true" tabindex="-1"></a>                        ResBlock(</span>
<span id="cb6-727"><a href="#cb6-727" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb6-728"><a href="#cb6-728" aria-hidden="true" tabindex="-1"></a>                            time_embed_dim,</span>
<span id="cb6-729"><a href="#cb6-729" aria-hidden="true" tabindex="-1"></a>                            dropout,</span>
<span id="cb6-730"><a href="#cb6-730" aria-hidden="true" tabindex="-1"></a>                            out_channels<span class="op">=</span>out_ch,</span>
<span id="cb6-731"><a href="#cb6-731" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>dims,</span>
<span id="cb6-732"><a href="#cb6-732" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb6-733"><a href="#cb6-733" aria-hidden="true" tabindex="-1"></a>                            use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb6-734"><a href="#cb6-734" aria-hidden="true" tabindex="-1"></a>                            up<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-735"><a href="#cb6-735" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb6-736"><a href="#cb6-736" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> resblock_updown</span>
<span id="cb6-737"><a href="#cb6-737" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> Upsample(ch, conv_resample, dims<span class="op">=</span>dims, out_channels<span class="op">=</span>out_ch)</span>
<span id="cb6-738"><a href="#cb6-738" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb6-739"><a href="#cb6-739" aria-hidden="true" tabindex="-1"></a>                    ds <span class="op">//=</span> <span class="dv">2</span></span>
<span id="cb6-740"><a href="#cb6-740" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.output_blocks.append(TimestepEmbedSequential(<span class="op">*</span>layers))</span>
<span id="cb6-741"><a href="#cb6-741" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb6-742"><a href="#cb6-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-743"><a href="#cb6-743" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Sequential(</span>
<span id="cb6-744"><a href="#cb6-744" aria-hidden="true" tabindex="-1"></a>            normalization(ch),</span>
<span id="cb6-745"><a href="#cb6-745" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb6-746"><a href="#cb6-746" aria-hidden="true" tabindex="-1"></a>            zero_module(conv_nd(dims, input_ch, out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb6-747"><a href="#cb6-747" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-748"><a href="#cb6-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-749"><a href="#cb6-749" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, t, x, y<span class="op">=</span><span class="va">None</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb6-750"><a href="#cb6-750" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-751"><a href="#cb6-751" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the model to an input batch.</span></span>
<span id="cb6-752"><a href="#cb6-752" aria-hidden="true" tabindex="-1"></a><span class="co">        :param t: a 1-D batch of timesteps.</span></span>
<span id="cb6-753"><a href="#cb6-753" aria-hidden="true" tabindex="-1"></a><span class="co">        :param x: an [N x C x ...] Tensor of inputs.</span></span>
<span id="cb6-754"><a href="#cb6-754" aria-hidden="true" tabindex="-1"></a><span class="co">        :param y: an [N] Tensor of labels, if class-conditional.</span></span>
<span id="cb6-755"><a href="#cb6-755" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x C x ...] Tensor of outputs.</span></span>
<span id="cb6-756"><a href="#cb6-756" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-757"><a href="#cb6-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-758"><a href="#cb6-758" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> (y <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>) <span class="op">==</span> (</span>
<span id="cb6-759"><a href="#cb6-759" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb6-760"><a href="#cb6-760" aria-hidden="true" tabindex="-1"></a>        ), <span class="st">"must specify y if and only if the model is class-conditional"</span></span>
<span id="cb6-761"><a href="#cb6-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-762"><a href="#cb6-762" aria-hidden="true" tabindex="-1"></a>        hs <span class="op">=</span> []</span>
<span id="cb6-763"><a href="#cb6-763" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> <span class="va">self</span>.time_embed(timestep_embedding(t, <span class="va">self</span>.model_channels))</span>
<span id="cb6-764"><a href="#cb6-764" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-765"><a href="#cb6-765" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> y.shape <span class="op">==</span> (x.shape[<span class="dv">0</span>],)</span>
<span id="cb6-766"><a href="#cb6-766" aria-hidden="true" tabindex="-1"></a>            emb <span class="op">=</span> emb <span class="op">+</span> <span class="va">self</span>.label_emb(y)</span>
<span id="cb6-767"><a href="#cb6-767" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> x.<span class="bu">type</span>(<span class="va">self</span>.dtype)</span>
<span id="cb6-768"><a href="#cb6-768" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.input_blocks:</span>
<span id="cb6-769"><a href="#cb6-769" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> module(h, emb)</span>
<span id="cb6-770"><a href="#cb6-770" aria-hidden="true" tabindex="-1"></a>            hs.append(h)</span>
<span id="cb6-771"><a href="#cb6-771" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.middle_block(h, emb)</span>
<span id="cb6-772"><a href="#cb6-772" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.output_blocks:</span>
<span id="cb6-773"><a href="#cb6-773" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> th.cat([h, hs.pop()], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-774"><a href="#cb6-774" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> module(h, emb)</span>
<span id="cb6-775"><a href="#cb6-775" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> h.<span class="bu">type</span>(x.dtype)</span>
<span id="cb6-776"><a href="#cb6-776" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out(h)</span>
<span id="cb6-777"><a href="#cb6-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-778"><a href="#cb6-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-779"><a href="#cb6-779" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNetBig(</span>
<span id="cb6-780"><a href="#cb6-780" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb6-781"><a href="#cb6-781" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-782"><a href="#cb6-782" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-783"><a href="#cb6-783" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">192</span>,</span>
<span id="cb6-784"><a href="#cb6-784" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-785"><a href="#cb6-785" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-786"><a href="#cb6-786" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb6-787"><a href="#cb6-787" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-788"><a href="#cb6-788" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb6-789"><a href="#cb6-789" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-790"><a href="#cb6-790" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb6-791"><a href="#cb6-791" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-792"><a href="#cb6-792" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-793"><a href="#cb6-793" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-794"><a href="#cb6-794" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-795"><a href="#cb6-795" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-796"><a href="#cb6-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-797"><a href="#cb6-797" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb6-798"><a href="#cb6-798" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-799"><a href="#cb6-799" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb6-800"><a href="#cb6-800" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-801"><a href="#cb6-801" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb6-802"><a href="#cb6-802" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb6-803"><a href="#cb6-803" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb6-804"><a href="#cb6-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-805"><a href="#cb6-805" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb6-806"><a href="#cb6-806" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb6-807"><a href="#cb6-807" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb6-808"><a href="#cb6-808" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb6-809"><a href="#cb6-809" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb6-810"><a href="#cb6-810" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-811"><a href="#cb6-811" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb6-812"><a href="#cb6-812" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb6-813"><a href="#cb6-813" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb6-814"><a href="#cb6-814" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb6-815"><a href="#cb6-815" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-816"><a href="#cb6-816" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-817"><a href="#cb6-817" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-818"><a href="#cb6-818" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-819"><a href="#cb6-819" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-820"><a href="#cb6-820" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-821"><a href="#cb6-821" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-822"><a href="#cb6-822" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-823"><a href="#cb6-823" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-824"><a href="#cb6-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-825"><a href="#cb6-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-826"><a href="#cb6-826" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNet(</span>
<span id="cb6-827"><a href="#cb6-827" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb6-828"><a href="#cb6-828" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-829"><a href="#cb6-829" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-830"><a href="#cb6-830" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-831"><a href="#cb6-831" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-832"><a href="#cb6-832" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-833"><a href="#cb6-833" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb6-834"><a href="#cb6-834" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-835"><a href="#cb6-835" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb6-836"><a href="#cb6-836" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-837"><a href="#cb6-837" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb6-838"><a href="#cb6-838" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-839"><a href="#cb6-839" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-840"><a href="#cb6-840" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-841"><a href="#cb6-841" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-842"><a href="#cb6-842" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-843"><a href="#cb6-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-844"><a href="#cb6-844" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb6-845"><a href="#cb6-845" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-846"><a href="#cb6-846" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb6-847"><a href="#cb6-847" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-848"><a href="#cb6-848" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb6-849"><a href="#cb6-849" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb6-850"><a href="#cb6-850" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb6-851"><a href="#cb6-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-852"><a href="#cb6-852" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb6-853"><a href="#cb6-853" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb6-854"><a href="#cb6-854" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb6-855"><a href="#cb6-855" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb6-856"><a href="#cb6-856" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb6-857"><a href="#cb6-857" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-858"><a href="#cb6-858" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb6-859"><a href="#cb6-859" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb6-860"><a href="#cb6-860" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb6-861"><a href="#cb6-861" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb6-862"><a href="#cb6-862" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-863"><a href="#cb6-863" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-864"><a href="#cb6-864" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-865"><a href="#cb6-865" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb6-866"><a href="#cb6-866" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-867"><a href="#cb6-867" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-868"><a href="#cb6-868" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-869"><a href="#cb6-869" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-870"><a href="#cb6-870" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-871"><a href="#cb6-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-872"><a href="#cb6-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-873"><a href="#cb6-873" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNetSmall(</span>
<span id="cb6-874"><a href="#cb6-874" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb6-875"><a href="#cb6-875" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-876"><a href="#cb6-876" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-877"><a href="#cb6-877" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb6-878"><a href="#cb6-878" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb6-879"><a href="#cb6-879" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb6-880"><a href="#cb6-880" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb6-881"><a href="#cb6-881" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-882"><a href="#cb6-882" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb6-883"><a href="#cb6-883" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb6-884"><a href="#cb6-884" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb6-885"><a href="#cb6-885" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-886"><a href="#cb6-886" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-887"><a href="#cb6-887" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-888"><a href="#cb6-888" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-889"><a href="#cb6-889" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-890"><a href="#cb6-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-891"><a href="#cb6-891" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb6-892"><a href="#cb6-892" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb6-893"><a href="#cb6-893" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb6-894"><a href="#cb6-894" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-895"><a href="#cb6-895" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb6-896"><a href="#cb6-896" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb6-897"><a href="#cb6-897" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb6-898"><a href="#cb6-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-899"><a href="#cb6-899" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb6-900"><a href="#cb6-900" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb6-901"><a href="#cb6-901" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb6-902"><a href="#cb6-902" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb6-903"><a href="#cb6-903" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb6-904"><a href="#cb6-904" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-905"><a href="#cb6-905" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb6-906"><a href="#cb6-906" aria-hidden="true" tabindex="-1"></a>        time_emb_factor<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb6-907"><a href="#cb6-907" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb6-908"><a href="#cb6-908" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb6-909"><a href="#cb6-909" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb6-910"><a href="#cb6-910" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-911"><a href="#cb6-911" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-912"><a href="#cb6-912" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-913"><a href="#cb6-913" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb6-914"><a href="#cb6-914" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb6-915"><a href="#cb6-915" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-916"><a href="#cb6-916" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-917"><a href="#cb6-917" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-918"><a href="#cb6-918" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-model-the-user-logic" class="level3">
<h3 class="anchored" data-anchor-id="create-model-the-user-logic">Create model (the user logic)</h3>
<div id="cell-13" class="cell" data-outputid="135b45ea-0a39-4376-ec4e-84370866d498" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>denoising_model <span class="op">=</span> UNet(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    image_size<span class="op">=</span>config.resolution,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"model params: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> denoising_model.parameters()) <span class="op">/</span> <span class="fl">1e6</span><span class="sc">:.2f}</span><span class="ss"> M"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>model params: 14.42 M</code></pre>
</div>
</div>
</section>
<section id="optimizer" class="level3">
<h3 class="anchored" data-anchor-id="optimizer">Optimizer</h3>
<div id="cell-15" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.AdamW(denoising_model.parameters(), lr<span class="op">=</span>config.learning_rate, weight_decay<span class="op">=</span>config.weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="diffusion-noise-schedule" class="level3">
<h3 class="anchored" data-anchor-id="diffusion-noise-schedule">Diffusion noise schedule</h3>
<div id="cell-17" class="cell" data-outputid="8f5d1c6a-a6ea-4e1e-9f87-69908e335cad" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>beta_min, beta_max <span class="op">=</span> <span class="fl">1e-4</span>, <span class="fl">0.02</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_min, beta_max = 1e-4, 1</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_min, beta_max = 0, 0.02</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_noise_schedule(n_T: <span class="bu">int</span>, device: torch.device) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, torch.Tensor]:</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    betas <span class="op">=</span> torch.linspace(beta_min, beta_max, n_T).to(device)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> betas</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    alphas_cumprod <span class="op">=</span> torch.cumprod(alphas, axis<span class="op">=</span><span class="dv">0</span>).to(device)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    alphas_cumprod_prev <span class="op">=</span> torch.cat([torch.ones(<span class="dv">1</span>).to(device), alphas_cumprod[:<span class="op">-</span><span class="dv">1</span>].to(device)])</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    sqrt_recip_alphas <span class="op">=</span> torch.sqrt(<span class="fl">1.0</span> <span class="op">/</span> alphas).to(device)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    sqrt_alphas_cumprod <span class="op">=</span> torch.sqrt(alphas_cumprod).to(device)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    sqrt_one_minus_alphas_cumprod <span class="op">=</span> torch.sqrt(<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    posterior_variance <span class="op">=</span> betas <span class="op">*</span> (<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod_prev) <span class="op">/</span> (<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"betas"</span>: betas,</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"alphas"</span>: alphas,</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"alphas_cumprod"</span>: alphas_cumprod,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_recip_alphas"</span>: sqrt_recip_alphas,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_alphas_cumprod"</span>: sqrt_alphas_cumprod,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_one_minus_alphas_cumprod"</span>: sqrt_one_minus_alphas_cumprod,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"posterior_variance"</span>: posterior_variance,</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>noise_schedule <span class="op">=</span> create_noise_schedule(config.num_denoising_steps, device)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the schedule</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"betas"</span>].cpu().numpy())</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"beta_t"</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"alphas_cumprod_t"</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"sqrt_alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"sqrt_alphas_cumprod_t"</span>)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"sqrt_one_minus_alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"sqrt_one_minus_alphas_cumprod_t"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train</h2>
<section id="forward-diffusion" class="level3">
<h3 class="anchored" data-anchor-id="forward-diffusion">Forward diffusion</h3>
<p>Forward diffusion can be considered as â€œdata augmentationâ€ in the training step. It adds noise to the data to challenge the model to be able to tell apart signal from noise. Diffusion is a particular way of adding noise, with much mathematical rigor.</p>
<div id="cell-20" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model components</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    _ts <span class="op">=</span> t.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> noise <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> torch.randn_like(x_0)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> _ts.<span class="bu">max</span>() <span class="op">&lt;</span> <span class="bu">len</span>(noise_schedule[<span class="st">"alphas_cumprod"</span>]), <span class="ss">f"t=</span><span class="sc">{</span>_ts<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss"> is larger than the length of noise_schedule: </span><span class="sc">{</span><span class="bu">len</span>(noise_schedule[<span class="st">'alphas_cumprod'</span>])<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][_ts]</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (alpha_prod_t <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> x_0 <span class="op">+</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_prod_t) <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> noise</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t, noise</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualizing-forward-diffusion-on-an-image" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-forward-diffusion-on-an-image">Visualizing forward diffusion on an image</h3>
<div id="cell-22" class="cell" data-outputid="10c287ea-0fbb-450c-a9ac-cdb16bdfc9ac" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see what forward diffusion does.</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>x_0, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(val_dataloader))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>x_0 <span class="op">=</span> x_0.to(device)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>x_t_list <span class="op">=</span> []</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>common_noise <span class="op">=</span> torch.randn_like(x_0)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"x_0 std:", x_0[0].std().item())</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>noise_levels <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>]</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> noise_levels:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  t <span class="op">=</span> torch.full((x_0.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>device)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  x_t_list.append(forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span>common_noise)[<span class="dv">0</span>])</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (t, x_t) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(noise_levels, x_t_list)):</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print(x_t[0].min().item(), x_t[0].max().item())</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  plt.subplot(<span class="dv">1</span>, <span class="dv">10</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  plt.title(<span class="ss">f"t=</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">, std=</span><span class="sc">{</span>x_t[<span class="dv">0</span>]<span class="sc">.</span>std()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> x_t[<span class="dv">0</span>].cpu().numpy().transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>()) <span class="op">/</span> (img.<span class="bu">max</span>() <span class="op">-</span> img.<span class="bu">min</span>())</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> i <span class="op">&gt;=</span> <span class="dv">10</span>:</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="training-loop" class="level3">
<h3 class="anchored" data-anchor-id="training-loop">Training loop</h3>
<div id="cell-24" class="cell" data-outputid="5f8bbcb7-54a6-4bbf-ec87-362d0947b12c" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> MSELoss()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>denoising_model.train()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(denoising_model, steps<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Training on device:"</span>, device)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  max_train_steps <span class="op">=</span> steps</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  train_progress_bar <span class="op">=</span> tqdm(<span class="bu">enumerate</span>(itertools.cycle(train_dataloader)))</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  num_examples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> step, (x_0, _) <span class="kw">in</span> train_progress_bar:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    x_0 <span class="op">=</span> x_0.to(device)  <span class="co"># x_0 is the clean data to teach the model to generate</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn(x_0.shape).to(device)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.randint(<span class="dv">0</span>, config.num_denoising_steps, (x_0.shape[<span class="dv">0</span>],), device<span class="op">=</span>device).<span class="bu">long</span>()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    x_t, true_noise <span class="op">=</span> forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span>noise)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    predicted_noise <span class="op">=</span> denoising_model(t<span class="op">=</span>t, x<span class="op">=</span>x_t)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(predicted_noise, true_noise)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    loss.backward()<span class="op">;</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># torch.nn.utils.clip_grad_norm_(denoising_model.parameters(), 1)  # try commenting it out</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    train_progress_bar.set_postfix({<span class="st">"loss"</span>: loss.cpu().item()})</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    num_examples <span class="op">+=</span> <span class="bu">len</span>(x_0)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> step <span class="op">&gt;=</span> max_train_steps:</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f"Reached the max training steps:"</span>, max_train_steps)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"Trained on </span><span class="sc">{</span>num_examples<span class="sc">}</span><span class="ss"> examples."</span>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> loss</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c0eee08fa4c84a71a69c358e52053cf8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 100
Trained on 3232 examples.</code></pre>
</div>
</div>
</section>
</section>
<section id="generate" class="level2">
<h2 class="anchored" data-anchor-id="generate">Generate</h2>
<section id="the-sampling-algo" class="level3">
<h3 class="anchored" data-anchor-id="the-sampling-algo">The sampling algo</h3>
<div id="cell-27" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denoising_step(denoising_model, x_t, t, noise_schedule, thresholding<span class="op">=</span><span class="va">False</span>, clip_sample<span class="op">=</span><span class="va">True</span>, clip_sample_range<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the backward diffusion step, with the effect of denoising.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(t, <span class="bu">int</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> torch.full((x_t.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>x_t.device)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> t</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> denoising_model(t<span class="op">=</span>t_tensor, x<span class="op">=</span>x_t)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(model_output, <span class="st">"sample"</span>):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> model_output.sample</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract relevant values from noise_schedule</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># deal with t=0 case where t can be a tensor</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t_prev <span class="op">=</span> torch.where(t_tensor <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>                                    noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor <span class="op">-</span> <span class="dv">1</span>],</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>                                    torch.ones_like(t_tensor, device<span class="op">=</span>x_t.device))</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape alpha_prod_t_prev for proper broadcasting</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> alpha_prod_t.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t_prev <span class="op">=</span> alpha_prod_t_prev.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    beta_prod_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_prod_t</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    beta_prod_t_prev <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_prod_t_prev</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    current_alpha_t <span class="op">=</span> alpha_prod_t <span class="op">/</span> alpha_prod_t_prev</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    current_beta_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> current_alpha_t</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the previous sample mean</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    pred_original_sample <span class="op">=</span> (x_t <span class="op">-</span> beta_prod_t <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> model_output) <span class="op">/</span> alpha_prod_t <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clip_sample:</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        pred_original_sample <span class="op">=</span> torch.clamp(pred_original_sample, <span class="op">-</span>clip_sample_range, clip_sample_range)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the coefficients for pred_original_sample and current sample</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    pred_original_sample_coeff <span class="op">=</span> (alpha_prod_t_prev <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> current_beta_t) <span class="op">/</span> beta_prod_t</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    current_sample_coeff <span class="op">=</span> current_alpha_t <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> beta_prod_t_prev <span class="op">/</span> beta_prod_t</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the previous sample</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> pred_original_sample_coeff <span class="op">*</span> pred_original_sample <span class="op">+</span> current_sample_coeff <span class="op">*</span> x_t</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add noise</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.zeros_like(x_t)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    variance_noise <span class="op">=</span> torch.randn_like(x_t)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle t=0 case where t can be a tensor</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    non_zero_mask <span class="op">=</span> (t_tensor <span class="op">!=</span> <span class="dv">0</span>).<span class="bu">float</span>().view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> non_zero_mask <span class="op">*</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_prod_t_prev) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_prod_t) <span class="op">*</span> current_beta_t)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.clamp(variance, <span class="bu">min</span><span class="op">=</span><span class="fl">1e-20</span>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> pred_prev_sample <span class="op">+</span> (variance <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> variance_noise</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_prev_sample</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denoising_step_direct(</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    denoising_model,</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    x_t,</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    t,</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    noise_schedule,</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>    clip_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>    clip_sample_range<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the backward diffusion step, with the effect of denoising.</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(t, <span class="bu">int</span>):</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> torch.full((x_t.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>x_t.device)</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> t</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>        eps_theta <span class="op">=</span> denoising_model(t<span class="op">=</span>t_tensor, x<span class="op">=</span>x_t)</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(eps_theta, <span class="st">"sample"</span>):</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>        eps_theta <span class="op">=</span> eps_theta.sample</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract alphas from noise schedule</span></span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>    alpha_t <span class="op">=</span> noise_schedule[<span class="st">"alphas"</span>][t_tensor]</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>    alpha_t_cumprod <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor]</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape for broadcasting</span></span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a>    view_shape <span class="op">=</span> (<span class="op">-</span><span class="dv">1</span>,) <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">*</span> (x_t.ndim <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>    alpha_t <span class="op">=</span> alpha_t.view(<span class="op">*</span>view_shape)</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>    alpha_t_cumprod <span class="op">=</span> alpha_t_cumprod.view(<span class="op">*</span>view_shape)</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate epsilon factor</span></span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>    eps_factor <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod).sqrt()</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate mean for reverse process</span></span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> torch.sqrt(alpha_t)) <span class="op">*</span> (x_t <span class="op">-</span> eps_factor <span class="op">*</span> eps_theta)</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply clipping</span></span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if clip_sample:</span></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     mean = torch.clamp(mean, -clip_sample_range, clip_sample_range)</span></span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add noise scaled by variance for non-zero timesteps</span></span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn_like(x_t)</span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a>    beta_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_t</span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> beta_t <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod <span class="op">/</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod)</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.clamp(variance, <span class="bu">min</span><span class="op">=</span><span class="fl">1e-20</span>)  <span class="co"># Add clamp to prevent numerical instability</span></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mask out noise for t=0 timesteps</span></span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a>    non_zero_mask <span class="op">=</span> (t_tensor <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">float</span>().view(<span class="op">*</span>view_shape)</span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a>    noise_scale <span class="op">=</span> torch.sqrt(variance) <span class="op">*</span> non_zero_mask</span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> mean <span class="op">+</span> noise_scale <span class="op">*</span> noise</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply clipping</span></span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clip_sample:</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>        pred_prev_sample <span class="op">=</span> torch.clamp(pred_prev_sample, <span class="op">-</span>clip_sample_range, clip_sample_range)</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_prev_sample</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_samples_by_denoising(denoising_model, x_T, noise_schedule, n_T, device, thresholding<span class="op">=</span><span class="va">False</span>, clip_sample<span class="op">=</span><span class="va">True</span>, clip_sample_range<span class="op">=</span><span class="fl">1.0</span>, seed<span class="op">=</span><span class="dv">0</span>, method<span class="op">=</span><span class="st">"direct"</span>):</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the generation process.</span></span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> x_T.to(device)</span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a>    pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(n_T <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> pbar:</span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> method <span class="op">==</span> <span class="st">"direct"</span>:</span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> denoising_step_direct(denoising_model, x_t, t, noise_schedule, clip_sample, clip_sample_range)</span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> denoising_step(denoising_model, x_t, t, noise_schedule, thresholding, clip_sample, clip_sample_range)</span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a>        pbar.set_postfix({<span class="st">"std"</span>: x_t.std().item()})</span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print("raw x_t range", x_t.min(), x_t.max())</span></span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (x_t <span class="op">/</span> <span class="dv">2</span> <span class="op">+</span> <span class="fl">0.5</span>).clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print("after clamp", x_t.min(), x_t.max())</span></span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualize-sampled-images" class="level3">
<h3 class="anchored" data-anchor-id="visualize-sampled-images">Visualize sampled images</h3>
<div id="cell-29" class="cell" data-outputid="f8ea9e82-8f96-4cbf-8111-d3523a03523c" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the sampled images</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_sampled_images(method<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Loss of the denoising model:"</span>, loss.item())</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  x_T <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  x_sampled <span class="op">=</span> generate_samples_by_denoising(</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    denoising_model, x_T,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    noise_schedule, n_T<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    clip_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    clip_sample_range<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span>method,</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  x_sampled <span class="op">=</span> (x_sampled <span class="op">*</span> <span class="dv">255</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  sampled <span class="op">=</span> make_grid(x_sampled).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).cpu().numpy().astype(np.uint8)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  _ <span class="op">=</span> plt.imshow(sampled)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images(method<span class="op">=</span><span class="st">"direct"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.061633966863155365</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10e85508de2f4ad68a393c45cec3bd54","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-15-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-30" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.061633966863155365</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c3d5ca9976b04dda9ba4a7abd376ff17","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-16-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-some-more" class="level3">
<h3 class="anchored" data-anchor-id="train-some-more">Train some more</h3>
<div id="cell-32" class="cell" data-outputid="f75a00c2-d5b8-40b8-cb76-f9ee9b153ff5" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train some more</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ec41b2a4ea7e474ca3399a652bbce296","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 1000
Trained on 31998 examples.
loss: 0.02666069194674492</code></pre>
</div>
</div>
<div id="cell-33" class="cell" data-outputid="3fddfdf4-d80e-47f2-f4f9-2b8a515abe0f" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.02666069194674492</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7f2ef30a315a4e19a7c9533907eb96be","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-18-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-34" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images(method<span class="op">=</span><span class="st">"direct"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.02666069194674492</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"feb18119b53149f981173fc1189cd0b7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-19-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-even-more" class="level3">
<h3 class="anchored" data-anchor-id="train-even-more">Train even more</h3>
<div id="cell-36" class="cell" data-outputid="4afee568-bdf9-430b-876e-1f2816e6e175" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> g <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    g[<span class="st">'lr'</span>] <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># reduce learning rate</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7b3622b1500c4aa6b9436f5042c5d87e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 5000
Trained on 159828 examples.
loss: 0.06194191426038742
Loss of the denoising model: 0.06194191426038742</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"95f63b44ff004aaca1d506e047d41670","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-20-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="and-some-more" class="level3">
<h3 class="anchored" data-anchor-id="and-some-more">And, some more</h3>
<div id="cell-38" class="cell" data-outputid="d56c68d0-5586-4248-925f-0ae73056a1c6" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> g <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    g[<span class="st">'lr'</span>] <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># reduce learning rate</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5f39663da88c462b8306846b6b24f97e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 10000
Trained on 319624 examples.
loss: 0.028765305876731873
Loss of the denoising model: 0.028765305876731873</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7a002b34284a407aa02734178c3c86fc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-21-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-39" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e25a32e39bbc4ed4b88862c48ed44ea5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"04a04e7642904704b091d55b75d7aafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0511c75b13b24ac7a9b176df52129e07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"069b694b86394acf8f5faa461f5d3eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e4f9b259304302a261ec8764b3d72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c20bd7c5c644c3bce5ab928b8284be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"091762633712423c926d31d7420062fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a82f38232c74ae6beac08d705fbc240":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aec62e3c4544731a2780b65b62eb6a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_908d7b9ff8644df49b1c83ddb38f1e0f","placeholder":"â€‹","style":"IPY_MODEL_0511c75b13b24ac7a9b176df52129e07","value":"100%"}},"0b984917930e4d2daa81be08ae4cb2e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bbd14d99c284ede80ec348ac6519076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ee3ed4db32b4e74aa27acd5c2cd506b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9df5ad68439e4a92994930f97f06463e","IPY_MODEL_eee89f8f48a54ac9b63df22a6036a3d3","IPY_MODEL_a1f2dd797f794d11b84b0b0faa73691e"],"layout":"IPY_MODEL_57b52910b9d84771b222292f22fb4c03"}},"116406195ae54436915610c992c7712d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11870333ac534f1bb948245b79f8ca5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11c93b786744467c9183fa4015cd6b76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4733482262f54e9ea9ed76fdb69bbaaa","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7e73e4ec0634cdfa66f0f6384896dc9","value":59}},"1325b49fca594dd0aa72c4917d044169":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_690142ae1d46418d854eaccd264f5a33","placeholder":"â€‹","style":"IPY_MODEL_23a873f27f2b4fd3a754e621d88e0df1","value":""}},"15ddabb80b9d4d68a33cbf6eeb79f023":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bbdacaa845640118be28a222b614516":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a82f38232c74ae6beac08d705fbc240","placeholder":"â€‹","style":"IPY_MODEL_37abc2a8c024497c833008eb0f4acdc5","value":"â€‡59/1000â€‡[00:02&lt;00:36,â€‡25.48it/s,â€‡std=1]"}},"1d30484bd7af40d1bc9ef7f051a02aa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20af142079dd46348636f8be335bda81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23a873f27f2b4fd3a754e621d88e0df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24093408e2a14c3689c3a56c49b59eb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e4f9b259304302a261ec8764b3d72f","max":14630,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80927e843a5f4d8eb0ff014ecf79a16a","value":14630}},"2ce0dd3a7e704df8aa445338692f7820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31523e4acffc43379b965dd0729214cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"316b576e5513417c81d3bfde019cd94e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"323b40ae734847a5971df00030ffd202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aec62e3c4544731a2780b65b62eb6a9","IPY_MODEL_3efdd710357f4f1cb1c358e99dd99174","IPY_MODEL_3b136b9006674cffab93827f3ecf557e"],"layout":"IPY_MODEL_ec12eaff03404f5cb73019d439965362"}},"3358ed77dfe546ddaa66d33610c33b08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34019b31860f45f0920b74dd89dd3c9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3416498c265f4ab78d6c3afb3d34b208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_316b576e5513417c81d3bfde019cd94e","max":132588555,"min":0,"orientation":"horizontal","style":"IPY_MODEL_069b694b86394acf8f5faa461f5d3eb3","value":132588555}},"343c20931eed45078341f21e44bd8bed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3737b6c5fe7446ff9e79229cf7d1d6ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37abc2a8c024497c833008eb0f4acdc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"393703bd8fae4e02ac59936da8c9f59a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f41ba828156b41ba9b690c9e0bdbdea5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11870333ac534f1bb948245b79f8ca5c","value":1}},"3b136b9006674cffab93827f3ecf557e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70e3117594b4c6996897f5462383f3e","placeholder":"â€‹","style":"IPY_MODEL_9849b3fe0b3c4e2baea1ce9791e5b63e","value":"â€‡1000/1000â€‡[00:48&lt;00:00,â€‡18.41it/s,â€‡std=0.609]"}},"3b4dd3210aad4d1287329ca73acb3449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bef7665c9b14315b1479d605a7a9405":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c86d50c98ec4c6a92643a149b01ba0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e516edb99c048f696e08da2dfcc33ae","IPY_MODEL_efe15d8882b24e26981d9d88c94ce8a8","IPY_MODEL_ab6772c5f7794878bbb64306bc5af972"],"layout":"IPY_MODEL_8a69d7b1495a48a19dc9265de769af55"}},"3efdd710357f4f1cb1c358e99dd99174":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6828a915ee024b4e9619d97a73e0d53f","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20af142079dd46348636f8be335bda81","value":1000}},"45342bb8953d47a0941854fee6c23e4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46bd73d21fe04d85ac79b050efa2d348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4733482262f54e9ea9ed76fdb69bbaaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c7cc54c13144b61a137b2fa5b7434d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e516edb99c048f696e08da2dfcc33ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c6c547266245fda3b1443a18d9e960","placeholder":"â€‹","style":"IPY_MODEL_31523e4acffc43379b965dd0729214cd","value":""}},"4eaed03beec6446e846a9ad191830ca7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a2df1e6ed940d5a7c48c4ed5077db4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c484507dbc16429f83191e2be1b77661","placeholder":"â€‹","style":"IPY_MODEL_f0dbfe3d51f2453ca1cb4f8a83cd5ffd","value":"â€‡100/?â€‡[00:20&lt;00:00,â€‡â€‡5.77it/s,â€‡loss=0.0568]"}},"562e474564da4b1db302c573d86c5fc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"565489b7024045509b4f486228cbd812":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bac04a877244a5d9519b140560bbf46","placeholder":"â€‹","style":"IPY_MODEL_2ce0dd3a7e704df8aa445338692f7820","value":"100%"}},"56b38e69c8984055909d72c8a112c495":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57b52910b9d84771b222292f22fb4c03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0d375601a14304baa35d08417e3d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf73b2b41d2e42cc8ad643c098de7b69","placeholder":"â€‹","style":"IPY_MODEL_116406195ae54436915610c992c7712d","value":"â€‡133M/133Mâ€‡[00:03&lt;00:00,â€‡34.6MB/s]"}},"61d62a2ec60540969d2886143cbb5fb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6828a915ee024b4e9619d97a73e0d53f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"690142ae1d46418d854eaccd264f5a33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a5b3a68e9a441eafe984c868c994c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6bb12cdbe443b297cebc5c57b1d201":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cf20fee33b4fe4a3a13e18603923b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72105bbb98e94c529a92dd011395280a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"737f98f221974116917e83b8cbd6572f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c6c547266245fda3b1443a18d9e960":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab713c7e9344187bce06333a64a07b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9f4b079e2da49b2aa78eb827e97f17c","IPY_MODEL_f928cef14c724f1789733adbed20d7c7","IPY_MODEL_8ef5f869de0f43aaaf93eaebc6c2fc49"],"layout":"IPY_MODEL_f092fe6dd2234ff5ae9fd223087527c7"}},"7e3ef051d0884e5e9c31bf9af1285821":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec7943f2d6643f381405238b6a4d58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdfd015b50e8478db40df871a0e0760c","IPY_MODEL_ce6495b96c3541a0ae05c841ccfea5a2","IPY_MODEL_ee14c532db5946abb5b6bd8503c0987d"],"layout":"IPY_MODEL_34019b31860f45f0920b74dd89dd3c9f"}},"80927e843a5f4d8eb0ff014ecf79a16a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80935dc3f8844f0f92531b35d8274e0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836db012c54f4d1887d1ac5635b0bacf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1325b49fca594dd0aa72c4917d044169","IPY_MODEL_393703bd8fae4e02ac59936da8c9f59a","IPY_MODEL_55a2df1e6ed940d5a7c48c4ed5077db4"],"layout":"IPY_MODEL_a83ea576587e4be1b7188369f752e3a3"}},"83c9d9265843416d82e4c34afcde5f06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a69d7b1495a48a19dc9265de769af55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d19dac1130246eeb986253e30b29858":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8ef5f869de0f43aaaf93eaebc6c2fc49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7be0ede49164f8cb11494903dadc7ae","placeholder":"â€‹","style":"IPY_MODEL_d545ee3a9e224b7fb8f3166dc2da9788","value":"â€‡412/?â€‡[01:27&lt;00:00,â€‡â€‡5.34it/s,â€‡loss=0.0537]"}},"908d7b9ff8644df49b1c83ddb38f1e0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911ad5c90fc84b9db9a6035ac22038aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94871be2b0af463c8d2d29e3eb11ab47","IPY_MODEL_11c93b786744467c9183fa4015cd6b76","IPY_MODEL_1bbdacaa845640118be28a222b614516"],"layout":"IPY_MODEL_6e6bb12cdbe443b297cebc5c57b1d201"}},"91566e775ba041e08bfdc9bf9bf9021b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3358ed77dfe546ddaa66d33610c33b08","max":13592289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c7cc54c13144b61a137b2fa5b7434d9","value":13592289}},"93d8b02d0438451f93d5d3285c042edf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94871be2b0af463c8d2d29e3eb11ab47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bef7665c9b14315b1479d605a7a9405","placeholder":"â€‹","style":"IPY_MODEL_61d62a2ec60540969d2886143cbb5fb4","value":"â€‡â€‡6%"}},"9636f001e46d44698f6b05b06a11aac2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97253397598a4ff88b3aea250f4ce488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3d274cb6ca747aebe9b13d23f733456","placeholder":"â€‹","style":"IPY_MODEL_3737b6c5fe7446ff9e79229cf7d1d6ab","value":"â€‡14630/14630â€‡[00:00&lt;00:00,â€‡18920.39â€‡examples/s]"}},"9849b3fe0b3c4e2baea1ce9791e5b63e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bac04a877244a5d9519b140560bbf46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df5ad68439e4a92994930f97f06463e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e540d95436da46db961958b2f95e470c","placeholder":"â€‹","style":"IPY_MODEL_0b984917930e4d2daa81be08ae4cb2e3","value":"Generatingâ€‡valâ€‡split:â€‡100%"}},"a14abff04e6748f9abfaac60ba80491a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_565489b7024045509b4f486228cbd812","IPY_MODEL_d562f66e77a04fd0a21ec627ef4e836e","IPY_MODEL_b215ab2b7dc547c18243460f6bd03307"],"layout":"IPY_MODEL_d4dfc8e846764ff19157516af2efbbd6"}},"a1f2dd797f794d11b84b0b0faa73691e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc4b4c2d5f6474b82c0aa525da80963","placeholder":"â€‹","style":"IPY_MODEL_80935dc3f8844f0f92531b35d8274e0e","value":"â€‡1500/1500â€‡[00:00&lt;00:00,â€‡12587.71â€‡examples/s]"}},"a83ea576587e4be1b7188369f752e3a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6772c5f7794878bbb64306bc5af972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_091762633712423c926d31d7420062fb","placeholder":"â€‹","style":"IPY_MODEL_3b4dd3210aad4d1287329ca73acb3449","value":"â€‡412/?â€‡[01:18&lt;00:00,â€‡â€‡6.69it/s,â€‡loss=0.044]"}},"b03e0fb1e87b4f4da5fb310165796af2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b075ace4d49b412daa113baefb97e239":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b113bc4e41a24547ba07dbf8572e59d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e39266507dcd40ef97bcef22fae30c35","IPY_MODEL_91566e775ba041e08bfdc9bf9bf9021b","IPY_MODEL_b128b30c717047e9bf38c24a0262641c"],"layout":"IPY_MODEL_4eaed03beec6446e846a9ad191830ca7"}},"b128b30c717047e9bf38c24a0262641c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_343c20931eed45078341f21e44bd8bed","placeholder":"â€‹","style":"IPY_MODEL_04a04e7642904704b091d55b75d7aafd","value":"â€‡13.6M/13.6Mâ€‡[00:00&lt;00:00,â€‡42.1MB/s]"}},"b215ab2b7dc547c18243460f6bd03307":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e3ef051d0884e5e9c31bf9af1285821","placeholder":"â€‹","style":"IPY_MODEL_b8e58ba8119f4dbd8e692dc282721706","value":"â€‡1000/1000â€‡[00:42&lt;00:00,â€‡22.90it/s,â€‡std=0.361]"}},"b2505de75cd7482c92889f8f5f8b77de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5341358005b4feab7743c3a31c83c13","placeholder":"â€‹","style":"IPY_MODEL_fa5abb0d23ca4a0c907f11127603ef03","value":"train-00000-of-00001.parquet:â€‡100%"}},"b8e58ba8119f4dbd8e692dc282721706":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f4b079e2da49b2aa78eb827e97f17c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_737f98f221974116917e83b8cbd6572f","placeholder":"â€‹","style":"IPY_MODEL_dd7c2aea9730499ba392af981b35a13c","value":""}},"bcc4b4c2d5f6474b82c0aa525da80963":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf73b2b41d2e42cc8ad643c098de7b69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d274cb6ca747aebe9b13d23f733456":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c484507dbc16429f83191e2be1b77661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c94a6ad8365d4bdab01059e8a807129d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc739e8196da4fa78d6510461487947e","IPY_MODEL_24093408e2a14c3689c3a56c49b59eb1","IPY_MODEL_97253397598a4ff88b3aea250f4ce488"],"layout":"IPY_MODEL_9636f001e46d44698f6b05b06a11aac2"}},"ce6495b96c3541a0ae05c841ccfea5a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54e6d1e22c24345b67b0f88e2e0f3e9","max":646,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83c9d9265843416d82e4c34afcde5f06","value":646}},"d4dfc8e846764ff19157516af2efbbd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d545ee3a9e224b7fb8f3166dc2da9788":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d562f66e77a04fd0a21ec627ef4e836e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f4c2d247d14135ade949074143a5bf","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93d8b02d0438451f93d5d3285c042edf","value":1000}},"d70e3117594b4c6996897f5462383f3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93e07d9cd22454e9551d8b069bbd1ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc0be83354814b1fb516faef5de175e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2505de75cd7482c92889f8f5f8b77de","IPY_MODEL_3416498c265f4ab78d6c3afb3d34b208","IPY_MODEL_5a0d375601a14304baa35d08417e3d64"],"layout":"IPY_MODEL_69a5b3a68e9a441eafe984c868c994c8"}},"dc739e8196da4fa78d6510461487947e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b075ace4d49b412daa113baefb97e239","placeholder":"â€‹","style":"IPY_MODEL_46bd73d21fe04d85ac79b050efa2d348","value":"Generatingâ€‡trainâ€‡split:â€‡100%"}},"dd7c2aea9730499ba392af981b35a13c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e39266507dcd40ef97bcef22fae30c35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b03e0fb1e87b4f4da5fb310165796af2","placeholder":"â€‹","style":"IPY_MODEL_56b38e69c8984055909d72c8a112c495","value":"val-00000-of-00001.parquet:â€‡100%"}},"e5341358005b4feab7743c3a31c83c13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e540d95436da46db961958b2f95e470c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7be0ede49164f8cb11494903dadc7ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec12eaff03404f5cb73019d439965362":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee14c532db5946abb5b6bd8503c0987d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c20bd7c5c644c3bce5ab928b8284be","placeholder":"â€‹","style":"IPY_MODEL_d93e07d9cd22454e9551d8b069bbd1ee","value":"â€‡646/646â€‡[00:00&lt;00:00,â€‡17.5kB/s]"}},"eee89f8f48a54ac9b63df22a6036a3d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d30484bd7af40d1bc9ef7f051a02aa9","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_562e474564da4b1db302c573d86c5fc3","value":1500}},"efe15d8882b24e26981d9d88c94ce8a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72105bbb98e94c529a92dd011395280a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15ddabb80b9d4d68a33cbf6eeb79f023","value":1}},"f092fe6dd2234ff5ae9fd223087527c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0dbfe3d51f2453ca1cb4f8a83cd5ffd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f41ba828156b41ba9b690c9e0bdbdea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f54e6d1e22c24345b67b0f88e2e0f3e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e73e4ec0634cdfa66f0f6384896dc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8f4c2d247d14135ade949074143a5bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f928cef14c724f1789733adbed20d7c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d19dac1130246eeb986253e30b29858","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bbd14d99c284ede80ec348ac6519076","value":1}},"fa5abb0d23ca4a0c907f11127603ef03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdfd015b50e8478db40df871a0e0760c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45342bb8953d47a0941854fee6c23e4c","placeholder":"â€‹","style":"IPY_MODEL_71cf20fee33b4fe4a3a13e18603923b7","value":"README.md:â€‡100%"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kungfuai\.github\.io\/nano-diffusion\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>