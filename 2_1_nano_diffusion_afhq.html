<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Training a Diffusion Model for Animal Face Images – Nano Diffusion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Nano Diffusion</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/kungfuai/nano-diffusion.git" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./2_1_nano_diffusion_afhq.html">Generating Animal Face Images</a></li><li class="breadcrumb-item"><a href="./2_1_nano_diffusion_afhq.html">Training a Diffusion Model for Animal Face Images</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Generating a 2D Point Cloud</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Diffusion</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_Diffusion 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training a Diffusion Model on 2D Points</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_a_refactor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A refactoring exercise</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_1_b_Diffusion_2D_hyperparams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experiment with hyperparameters</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Flow Matching</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_2_Flow Matching 2D Toy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training a Flow Matching Model for 2D Point Generation</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Generating Animal Face Images</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_1_nano_diffusion_afhq.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Training a Diffusion Model for Animal Face Images</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_1_fid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quality evaluation of an image generation model</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#prerequisites" id="toc-prerequisites" class="nav-link" data-scroll-target="#prerequisites">Prerequisites</a></li>
  </ul></li>
  <li><a href="#training-configuration" id="toc-training-configuration" class="nav-link" data-scroll-target="#training-configuration">Training Configuration</a></li>
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data">Load data</a></li>
  <li><a href="#create-model-components-for-diffusion" id="toc-create-model-components-for-diffusion" class="nav-link" data-scroll-target="#create-model-components-for-diffusion">Create model components for diffusion</a>
  <ul class="collapse">
  <li><a href="#library-code-for-model-architecture" id="toc-library-code-for-model-architecture" class="nav-link" data-scroll-target="#library-code-for-model-architecture">Library code for model architecture</a></li>
  <li><a href="#create-model-the-user-logic" id="toc-create-model-the-user-logic" class="nav-link" data-scroll-target="#create-model-the-user-logic">Create model (the user logic)</a></li>
  <li><a href="#optimizer" id="toc-optimizer" class="nav-link" data-scroll-target="#optimizer">Optimizer</a></li>
  </ul></li>
  <li><a href="#train" id="toc-train" class="nav-link" data-scroll-target="#train">Train</a>
  <ul class="collapse">
  <li><a href="#forward-diffusion" id="toc-forward-diffusion" class="nav-link" data-scroll-target="#forward-diffusion">Forward diffusion</a></li>
  <li><a href="#visualizing-forward-diffusion-on-an-image" id="toc-visualizing-forward-diffusion-on-an-image" class="nav-link" data-scroll-target="#visualizing-forward-diffusion-on-an-image">Visualizing forward diffusion on an image</a></li>
  </ul></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training loop</a></li>
  <li><a href="#generate" id="toc-generate" class="nav-link" data-scroll-target="#generate">Generate</a>
  <ul class="collapse">
  <li><a href="#the-sampling-algorithm-reversing-the-diffusion-process" id="toc-the-sampling-algorithm-reversing-the-diffusion-process" class="nav-link" data-scroll-target="#the-sampling-algorithm-reversing-the-diffusion-process">The sampling algorithm: reversing the diffusion process</a></li>
  <li><a href="#the-clamping" id="toc-the-clamping" class="nav-link" data-scroll-target="#the-clamping">The clamping</a></li>
  <li><a href="#visualize-sampled-images" id="toc-visualize-sampled-images" class="nav-link" data-scroll-target="#visualize-sampled-images">Visualize sampled images</a></li>
  <li><a href="#train-some-more" id="toc-train-some-more" class="nav-link" data-scroll-target="#train-some-more">Train some more</a></li>
  <li><a href="#train-even-more" id="toc-train-even-more" class="nav-link" data-scroll-target="#train-even-more">Train even more</a></li>
  <li><a href="#and-some-more" id="toc-and-some-more" class="nav-link" data-scroll-target="#and-some-more">And, some more</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./2_1_nano_diffusion_afhq.html">Generating Animal Face Images</a></li><li class="breadcrumb-item"><a href="./2_1_nano_diffusion_afhq.html">Training a Diffusion Model for Animal Face Images</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Training a Diffusion Model for Animal Face Images</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a href="https://colab.research.google.com/github/kungfuai/nano-diffusion/blob/main/notebooks/2_1_nano_diffusion_afhq.ipynb">open in colab</a></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This notebook demonstrates how to train a diffusion model on the Animal Faces-HQ (AFHQ) dataset. We’ll implement a simplified version of denoising diffusion probabilistic models (DDPM) to generate high-quality animal face images.</p>
<section id="overview" class="level3">
<h3 class="anchored" data-anchor-id="overview">Overview</h3>
<ol type="1">
<li>Set up the training configuration</li>
<li>Load and preprocess the AFHQ dataset</li>
<li>Define the UNet architecture</li>
<li>Implement the diffusion process</li>
<li>Train the model</li>
<li>Generate new images</li>
</ol>
</section>
<section id="prerequisites" class="level3">
<h3 class="anchored" data-anchor-id="prerequisites">Prerequisites</h3>
<ul>
<li>PyTorch</li>
<li>datasets library (<code>pip install datasets==3.0.2</code>)</li>
<li>Basic understanding of deep learning and generative models</li>
</ul>
<div id="cell-2" class="cell" data-outputid="d2b5c8c3-27e8-442b-9f9f-cb83297d0063" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install datasets==3.0.2</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install torchvision==0.17.2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>load_ext autoreload</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>autoreload <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-4" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, random_split</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> MSELoss</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> make_grid</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Tuple</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="training-configuration" class="level2">
<h2 class="anchored" data-anchor-id="training-configuration">Training Configuration</h2>
<p>The <code>TrainingConfig</code> class below defines all hyperparameters for our model: - Dataset: AFHQ dataset at 64x64 resolution - Model architecture: UNet with attention - Training parameters: batch size, learning rate, etc. - Data augmentation options</p>
<div id="cell-6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrainingConfig:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    dataset: <span class="bu">str</span> <span class="op">=</span> <span class="st">"zzsi/afhq64_16k"</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model architecture</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    resolution: <span class="bu">int</span> <span class="op">=</span> <span class="dv">64</span> <span class="co"># resolution of the image</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    num_denoising_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">1000</span> <span class="co"># number of timesteps</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop and optimizer</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    total_steps: <span class="bu">int</span> <span class="op">=</span> <span class="dv">100000</span>  <span class="co"># total number of training steps</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">32</span> <span class="co"># batch size</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    learning_rate: <span class="bu">float</span> <span class="op">=</span> <span class="fl">5e-4</span> <span class="co"># initial learning rate</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    weight_decay: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-6</span> <span class="co"># weight decay</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data augmentation</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    random_flip: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span> <span class="co"># randomly flip images horizontally</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> TrainingConfig(resolution<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-data" class="level2">
<h2 class="anchored" data-anchor-id="load-data">Load data</h2>
<p>We use the HuggingFace datasets library to load the AFHQ dataset. The data pipeline includes: - Loading images from HuggingFace - Resizing to the target resolution - Applying normalization and optional augmentations</p>
<div id="cell-8" class="cell" data-outputid="ebcded33-8efd-4e60-d5ef-caf0ecd87062" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HuggingFaceDataset(Dataset):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset_path: <span class="bu">str</span>, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> load_dataset(dataset_path, split<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_key <span class="op">=</span> <span class="va">self</span>.find_image_key()</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> find_image_key(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the dataset has the "image" key</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">NOTE</span><span class="co">: Can exapnd this to other common keys if needed</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"image"</span> <span class="kw">in</span> <span class="va">self</span>.dataset[<span class="dv">0</span>].keys():</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="st">"image"</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">KeyError</span>(<span class="st">"Dataset does not have an 'image' key"</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> <span class="va">self</span>.dataset[idx][<span class="va">self</span>.image_key]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> image.convert(<span class="st">"RGB"</span>)  <span class="co"># Convert to RGB to ensure 3 channels</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># By default, set label to 0 to conform to current expected batch format</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, label</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(config: TrainingConfig) <span class="op">-&gt;</span> Tuple[DataLoader, DataLoader]:</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    resolution <span class="op">=</span> config.resolution</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    transforms_list <span class="op">=</span> [</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        transforms.Resize((resolution, resolution)),</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), (<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)),</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> config.random_flip:</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        transforms_list.insert(<span class="dv">0</span>, transforms.RandomHorizontalFlip())</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose(transforms_list)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    full_dataset <span class="op">=</span> HuggingFaceDataset(config.dataset, transform<span class="op">=</span>transform)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.9</span> <span class="op">*</span> <span class="bu">len</span>(full_dataset))</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    val_size <span class="op">=</span> <span class="bu">len</span>(full_dataset) <span class="op">-</span> train_size</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    train_dataset, val_dataset <span class="op">=</span> random_split(full_dataset, [train_size, val_size], generator<span class="op">=</span>torch.Generator().manual_seed(<span class="dv">0</span>))</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    train_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        train_dataset, batch_size<span class="op">=</span>config.batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    val_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        val_dataset, batch_size<span class="op">=</span>config.batch_size, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_dataloader, val_dataloader</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>train_dataloader, val_dataloader <span class="op">=</span> load_data(config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-9" class="cell" data-outputid="fd4bd221-815c-45dd-bc10-da980d048d3d" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dataloader))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>grid_img <span class="op">=</span> make_grid(x[<span class="dv">0</span>]).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>grid_img <span class="op">=</span> (grid_img <span class="op">-</span> grid_img.<span class="bu">min</span>()) <span class="op">/</span> (grid_img.<span class="bu">max</span>() <span class="op">-</span> grid_img.<span class="bu">min</span>())</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(grid_img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="create-model-components-for-diffusion" class="level2">
<h2 class="anchored" data-anchor-id="create-model-components-for-diffusion">Create model components for diffusion</h2>
<p>For image generation, a typical model architecture can be a UNet or a transformer. We use UNet in this notebook.</p>
<p>Below are some utility functions and classesfor the model architecture.</p>
<section id="library-code-for-model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="library-code-for-model-architecture">Library code for model architecture</h3>
<div id="cell-12" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">From: https://github.com/VSehwag/minimal-diffusion/blob/main/unets.py</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> abc <span class="im">import</span> abstractmethod</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch <span class="im">as</span> th</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GroupNorm32(nn.GroupNorm):</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">super</span>().forward(x.<span class="bu">float</span>()).<span class="bu">type</span>(x.dtype)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conv_nd(dims, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a 1D, 2D, or 3D convolution module.</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dims <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv1d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.Conv3d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported dimensions: </span><span class="sc">{</span>dims<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a linear module.</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nn.Linear(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> avg_pool_nd(dims, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a 1D, 2D, or 3D average pooling module.</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dims <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool1d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool2d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AvgPool3d(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported dimensions: </span><span class="sc">{</span>dims<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_ema(target_params, source_params, rate<span class="op">=</span><span class="fl">0.99</span>):</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a><span class="co">    Update target parameters to be closer to those of source parameters using</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a><span class="co">    an exponential moving average.</span></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a><span class="co">    :param target_params: the target parameter sequence.</span></span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a><span class="co">    :param source_params: the source parameter sequence.</span></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a><span class="co">    :param rate: the EMA rate (closer to 1 means slower).</span></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> targ, src <span class="kw">in</span> <span class="bu">zip</span>(target_params, source_params):</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>        targ.detach().mul_(rate).add_(src, alpha<span class="op">=</span><span class="dv">1</span> <span class="op">-</span> rate)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_module(module):</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a><span class="co">    Zero out the parameters of a module and return it.</span></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> module.parameters():</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>        p.detach().zero_()</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> module</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalization(channels):</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a><span class="co">    Make a standard normalization layer.</span></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: number of input channels.</span></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: an nn.Module for normalization.</span></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> GroupNorm32(<span class="dv">32</span>, channels)</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> timestep_embedding(timesteps, dim, max_period<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a><span class="co">    Create sinusoidal timestep embeddings.</span></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a><span class="co">    :param timesteps: a 1-D Tensor of N indices, one per batch element.</span></span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a><span class="co">                      These may be fractional.</span></span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dim: the dimension of the output.</span></span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a><span class="co">    :param max_period: controls the minimum frequency of the embeddings.</span></span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a><span class="co">    :return: an [N x dim] Tensor of positional embeddings.</span></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>    half <span class="op">=</span> dim <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> th.exp(</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>        <span class="op">-</span>math.log(max_period) <span class="op">*</span> th.arange(start<span class="op">=</span><span class="dv">0</span>, end<span class="op">=</span>half, dtype<span class="op">=</span>th.float32) <span class="op">/</span> half</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>    ).to(device<span class="op">=</span>timesteps.device)</span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> timesteps.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> timesteps[:, <span class="va">None</span>].<span class="bu">float</span>() <span class="op">*</span> freqs[<span class="va">None</span>]</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> timesteps.<span class="bu">float</span>() <span class="op">*</span> freqs[<span class="va">None</span>]</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>    embedding <span class="op">=</span> th.cat([th.cos(args), th.sin(args)], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dim <span class="op">%</span> <span class="dv">2</span>:</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>        embedding <span class="op">=</span> th.cat([embedding, th.zeros_like(embedding[:, :<span class="dv">1</span>])], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embedding</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> checkpoint(func, inputs, params, flag):</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a><span class="co">    Evaluate a function without caching intermediate activations, allowing for</span></span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a><span class="co">    reduced memory at the expense of extra compute in the backward pass.</span></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a><span class="co">    :param func: the function to evaluate.</span></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a><span class="co">    :param inputs: the argument sequence to pass to `func`.</span></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a><span class="co">    :param params: a sequence of parameters `func` depends on but does not</span></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a><span class="co">                   explicitly take as arguments.</span></span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a><span class="co">    :param flag: if False, disable gradient checkpointing.</span></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> flag:</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>        args <span class="op">=</span> <span class="bu">tuple</span>(inputs) <span class="op">+</span> <span class="bu">tuple</span>(params)</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> CheckpointFunction.<span class="bu">apply</span>(func, <span class="bu">len</span>(inputs), <span class="op">*</span>args)</span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> func(<span class="op">*</span>inputs)</span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CheckpointFunction(th.autograd.Function):</span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(ctx, run_function, length, <span class="op">*</span>args):</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a>        ctx.run_function <span class="op">=</span> run_function</span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a>        ctx.input_tensors <span class="op">=</span> <span class="bu">list</span>(args[:length])</span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>        ctx.input_params <span class="op">=</span> <span class="bu">list</span>(args[length:])</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> th.no_grad():</span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>            output_tensors <span class="op">=</span> ctx.run_function(<span class="op">*</span>ctx.input_tensors)</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output_tensors</span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(ctx, <span class="op">*</span>output_grads):</span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>        ctx.input_tensors <span class="op">=</span> [x.detach().requires_grad_(<span class="va">True</span>) <span class="cf">for</span> x <span class="kw">in</span> ctx.input_tensors]</span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> th.enable_grad():</span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fixes a bug where the first op in run_function modifies the</span></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tensor storage in place, which is not allowed for detach()'d</span></span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tensors.</span></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a>            shallow_copies <span class="op">=</span> [x.view_as(x) <span class="cf">for</span> x <span class="kw">in</span> ctx.input_tensors]</span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a>            output_tensors <span class="op">=</span> ctx.run_function(<span class="op">*</span>shallow_copies)</span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>        input_grads <span class="op">=</span> th.autograd.grad(</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a>            output_tensors,</span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a>            ctx.input_tensors <span class="op">+</span> ctx.input_params,</span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a>            output_grads,</span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>            allow_unused<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> ctx.input_tensors</span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> ctx.input_params</span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> output_tensors</span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">None</span>, <span class="va">None</span>) <span class="op">+</span> input_grads</span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionPool2d(nn.Module):</span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a><span class="co">    Adapted from CLIP: https://github.com/openai/CLIP/blob/main/clip/model.py</span></span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a>        spacial_dim: <span class="bu">int</span>,</span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a>        embed_dim: <span class="bu">int</span>,</span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a>        num_heads_channels: <span class="bu">int</span>,</span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a>        output_dim: <span class="bu">int</span> <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positional_embedding <span class="op">=</span> nn.Parameter(</span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a>            th.randn(embed_dim, spacial_dim <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> embed_dim <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qkv_proj <span class="op">=</span> conv_nd(<span class="dv">1</span>, embed_dim, <span class="dv">3</span> <span class="op">*</span> embed_dim, <span class="dv">1</span>)</span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_proj <span class="op">=</span> conv_nd(<span class="dv">1</span>, embed_dim, output_dim <span class="kw">or</span> embed_dim, <span class="dv">1</span>)</span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> embed_dim <span class="op">//</span> num_heads_channels</span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> QKVAttention(<span class="va">self</span>.num_heads)</span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a>        b, c, <span class="op">*</span>_spatial <span class="op">=</span> x.shape</span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(b, c, <span class="op">-</span><span class="dv">1</span>)  <span class="co"># NC(HW)</span></span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> th.cat([x.mean(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>), x], dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># NC(HW+1)</span></span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.positional_embedding[<span class="va">None</span>, :, :].to(x.dtype)  <span class="co"># NC(HW+1)</span></span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.qkv_proj(x)</span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.attention(x)</span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.c_proj(x)</span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x[:, :, <span class="dv">0</span>]</span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimestepBlock(nn.Module):</span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a><span class="co">    Any module where forward() takes timestep embeddings as a second argument.</span></span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a>    <span class="at">@abstractmethod</span></span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the module to `x` given `emb` timestep embeddings.</span></span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TimestepEmbedSequential(nn.Sequential, TimestepBlock):</span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a><span class="co">    A sequential module that passes timestep embeddings to the children that</span></span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a><span class="co">    support it as an extra input.</span></span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>:</span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, TimestepBlock):</span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x, emb)</span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> layer(x)</span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Upsample(nn.Module):</span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a><span class="co">    An upsampling layer with an optional convolution.</span></span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: channels in the inputs and outputs.</span></span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: a bool determining if a convolution is applied.</span></span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then</span></span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a><span class="co">                 upsampling occurs in the inner-two dimensions.</span></span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, use_conv, dims<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb7-227"><a href="#cb7-227" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb7-228"><a href="#cb7-228" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dims <span class="op">=</span> dims</span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_conv:</span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.conv <span class="op">=</span> conv_nd(dims, <span class="va">self</span>.channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-233"><a href="#cb7-233" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-234"><a href="#cb7-234" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> x.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="va">self</span>.channels</span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.dims <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.interpolate(</span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a>                x, (x.shape[<span class="dv">2</span>], x.shape[<span class="dv">3</span>] <span class="op">*</span> <span class="dv">2</span>, x.shape[<span class="dv">4</span>] <span class="op">*</span> <span class="dv">2</span>), mode<span class="op">=</span><span class="st">"nearest"</span></span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.interpolate(x, scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">"nearest"</span>)</span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> x.shape[<span class="op">-</span><span class="dv">2</span>] <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a>            <span class="co"># upsampling layer transform [3x3] to [6x6]. Manually paddding it to make [7x7]</span></span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> F.pad(out, (<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.use_conv:</span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> <span class="va">self</span>.conv(out)</span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb7-247"><a href="#cb7-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-248"><a href="#cb7-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-249"><a href="#cb7-249" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Downsample(nn.Module):</span>
<span id="cb7-250"><a href="#cb7-250" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-251"><a href="#cb7-251" aria-hidden="true" tabindex="-1"></a><span class="co">    A downsampling layer with an optional convolution.</span></span>
<span id="cb7-252"><a href="#cb7-252" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: channels in the inputs and outputs.</span></span>
<span id="cb7-253"><a href="#cb7-253" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: a bool determining if a convolution is applied.</span></span>
<span id="cb7-254"><a href="#cb7-254" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D. If 3D, then</span></span>
<span id="cb7-255"><a href="#cb7-255" aria-hidden="true" tabindex="-1"></a><span class="co">                 downsampling occurs in the inner-two dimensions.</span></span>
<span id="cb7-256"><a href="#cb7-256" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-257"><a href="#cb7-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-258"><a href="#cb7-258" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, channels, use_conv, dims<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-259"><a href="#cb7-259" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-260"><a href="#cb7-260" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb7-261"><a href="#cb7-261" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb7-262"><a href="#cb7-262" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb7-263"><a href="#cb7-263" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dims <span class="op">=</span> dims</span>
<span id="cb7-264"><a href="#cb7-264" aria-hidden="true" tabindex="-1"></a>        stride <span class="op">=</span> <span class="dv">2</span> <span class="cf">if</span> dims <span class="op">!=</span> <span class="dv">3</span> <span class="cf">else</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-265"><a href="#cb7-265" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_conv:</span>
<span id="cb7-266"><a href="#cb7-266" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.op <span class="op">=</span> conv_nd(</span>
<span id="cb7-267"><a href="#cb7-267" aria-hidden="true" tabindex="-1"></a>                dims, <span class="va">self</span>.channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, stride<span class="op">=</span>stride, padding<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-268"><a href="#cb7-268" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-269"><a href="#cb7-269" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-270"><a href="#cb7-270" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> <span class="va">self</span>.channels <span class="op">==</span> <span class="va">self</span>.out_channels</span>
<span id="cb7-271"><a href="#cb7-271" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.op <span class="op">=</span> avg_pool_nd(dims, kernel_size<span class="op">=</span>stride, stride<span class="op">=</span>stride)</span>
<span id="cb7-272"><a href="#cb7-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-273"><a href="#cb7-273" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-274"><a href="#cb7-274" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> x.shape[<span class="dv">1</span>] <span class="op">==</span> <span class="va">self</span>.channels</span>
<span id="cb7-275"><a href="#cb7-275" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.op(x)</span>
<span id="cb7-276"><a href="#cb7-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-277"><a href="#cb7-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-278"><a href="#cb7-278" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResBlock(TimestepBlock):</span>
<span id="cb7-279"><a href="#cb7-279" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-280"><a href="#cb7-280" aria-hidden="true" tabindex="-1"></a><span class="co">    A residual block that can optionally change the number of channels.</span></span>
<span id="cb7-281"><a href="#cb7-281" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channels: the number of input channels.</span></span>
<span id="cb7-282"><a href="#cb7-282" aria-hidden="true" tabindex="-1"></a><span class="co">    :param emb_channels: the number of timestep embedding channels.</span></span>
<span id="cb7-283"><a href="#cb7-283" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dropout: the rate of dropout.</span></span>
<span id="cb7-284"><a href="#cb7-284" aria-hidden="true" tabindex="-1"></a><span class="co">    :param out_channels: if specified, the number of out channels.</span></span>
<span id="cb7-285"><a href="#cb7-285" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_conv: if True and out_channels is specified, use a spatial</span></span>
<span id="cb7-286"><a href="#cb7-286" aria-hidden="true" tabindex="-1"></a><span class="co">        convolution instead of a smaller 1x1 convolution to change the</span></span>
<span id="cb7-287"><a href="#cb7-287" aria-hidden="true" tabindex="-1"></a><span class="co">        channels in the skip connection.</span></span>
<span id="cb7-288"><a href="#cb7-288" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D.</span></span>
<span id="cb7-289"><a href="#cb7-289" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_checkpoint: if True, use gradient checkpointing on this module.</span></span>
<span id="cb7-290"><a href="#cb7-290" aria-hidden="true" tabindex="-1"></a><span class="co">    :param up: if True, use this block for upsampling.</span></span>
<span id="cb7-291"><a href="#cb7-291" aria-hidden="true" tabindex="-1"></a><span class="co">    :param down: if True, use this block for downsampling.</span></span>
<span id="cb7-292"><a href="#cb7-292" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-293"><a href="#cb7-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-294"><a href="#cb7-294" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb7-295"><a href="#cb7-295" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb7-296"><a href="#cb7-296" aria-hidden="true" tabindex="-1"></a>        channels,</span>
<span id="cb7-297"><a href="#cb7-297" aria-hidden="true" tabindex="-1"></a>        emb_channels,</span>
<span id="cb7-298"><a href="#cb7-298" aria-hidden="true" tabindex="-1"></a>        dropout,</span>
<span id="cb7-299"><a href="#cb7-299" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb7-300"><a href="#cb7-300" aria-hidden="true" tabindex="-1"></a>        use_conv<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-301"><a href="#cb7-301" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-302"><a href="#cb7-302" aria-hidden="true" tabindex="-1"></a>        dims<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-303"><a href="#cb7-303" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-304"><a href="#cb7-304" aria-hidden="true" tabindex="-1"></a>        up<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-305"><a href="#cb7-305" aria-hidden="true" tabindex="-1"></a>        down<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-306"><a href="#cb7-306" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb7-307"><a href="#cb7-307" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-308"><a href="#cb7-308" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb7-309"><a href="#cb7-309" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emb_channels <span class="op">=</span> emb_channels</span>
<span id="cb7-310"><a href="#cb7-310" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb7-311"><a href="#cb7-311" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels <span class="kw">or</span> channels</span>
<span id="cb7-312"><a href="#cb7-312" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_conv <span class="op">=</span> use_conv</span>
<span id="cb7-313"><a href="#cb7-313" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb7-314"><a href="#cb7-314" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_scale_shift_norm <span class="op">=</span> use_scale_shift_norm</span>
<span id="cb7-315"><a href="#cb7-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-316"><a href="#cb7-316" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-317"><a href="#cb7-317" aria-hidden="true" tabindex="-1"></a>            normalization(channels),</span>
<span id="cb7-318"><a href="#cb7-318" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb7-319"><a href="#cb7-319" aria-hidden="true" tabindex="-1"></a>            conv_nd(dims, channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-320"><a href="#cb7-320" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-321"><a href="#cb7-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-322"><a href="#cb7-322" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.updown <span class="op">=</span> up <span class="kw">or</span> down</span>
<span id="cb7-323"><a href="#cb7-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-324"><a href="#cb7-324" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> up:</span>
<span id="cb7-325"><a href="#cb7-325" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> Upsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb7-326"><a href="#cb7-326" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.x_upd <span class="op">=</span> Upsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb7-327"><a href="#cb7-327" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> down:</span>
<span id="cb7-328"><a href="#cb7-328" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> Downsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb7-329"><a href="#cb7-329" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.x_upd <span class="op">=</span> Downsample(channels, <span class="va">False</span>, dims)</span>
<span id="cb7-330"><a href="#cb7-330" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-331"><a href="#cb7-331" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.h_upd <span class="op">=</span> <span class="va">self</span>.x_upd <span class="op">=</span> nn.Identity()</span>
<span id="cb7-332"><a href="#cb7-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-333"><a href="#cb7-333" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.emb_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-334"><a href="#cb7-334" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb7-335"><a href="#cb7-335" aria-hidden="true" tabindex="-1"></a>            linear(</span>
<span id="cb7-336"><a href="#cb7-336" aria-hidden="true" tabindex="-1"></a>                emb_channels,</span>
<span id="cb7-337"><a href="#cb7-337" aria-hidden="true" tabindex="-1"></a>                <span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.out_channels <span class="cf">if</span> use_scale_shift_norm <span class="cf">else</span> <span class="va">self</span>.out_channels,</span>
<span id="cb7-338"><a href="#cb7-338" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb7-339"><a href="#cb7-339" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-340"><a href="#cb7-340" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-341"><a href="#cb7-341" aria-hidden="true" tabindex="-1"></a>            normalization(<span class="va">self</span>.out_channels),</span>
<span id="cb7-342"><a href="#cb7-342" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb7-343"><a href="#cb7-343" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span>dropout),</span>
<span id="cb7-344"><a href="#cb7-344" aria-hidden="true" tabindex="-1"></a>            zero_module(</span>
<span id="cb7-345"><a href="#cb7-345" aria-hidden="true" tabindex="-1"></a>                conv_nd(dims, <span class="va">self</span>.out_channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-346"><a href="#cb7-346" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb7-347"><a href="#cb7-347" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-348"><a href="#cb7-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-349"><a href="#cb7-349" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.out_channels <span class="op">==</span> channels:</span>
<span id="cb7-350"><a href="#cb7-350" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> nn.Identity()</span>
<span id="cb7-351"><a href="#cb7-351" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> use_conv:</span>
<span id="cb7-352"><a href="#cb7-352" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> conv_nd(</span>
<span id="cb7-353"><a href="#cb7-353" aria-hidden="true" tabindex="-1"></a>                dims, channels, <span class="va">self</span>.out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-354"><a href="#cb7-354" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-355"><a href="#cb7-355" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-356"><a href="#cb7-356" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.skip_connection <span class="op">=</span> conv_nd(dims, channels, <span class="va">self</span>.out_channels, <span class="dv">1</span>)</span>
<span id="cb7-357"><a href="#cb7-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-358"><a href="#cb7-358" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, emb):</span>
<span id="cb7-359"><a href="#cb7-359" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-360"><a href="#cb7-360" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the block to a Tensor, conditioned on a timestep embedding.</span></span>
<span id="cb7-361"><a href="#cb7-361" aria-hidden="true" tabindex="-1"></a><span class="co">        :param x: an [N x C x ...] Tensor of features.</span></span>
<span id="cb7-362"><a href="#cb7-362" aria-hidden="true" tabindex="-1"></a><span class="co">        :param emb: an [N x emb_channels] Tensor of timestep embeddings.</span></span>
<span id="cb7-363"><a href="#cb7-363" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x C x ...] Tensor of outputs.</span></span>
<span id="cb7-364"><a href="#cb7-364" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-365"><a href="#cb7-365" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint(</span>
<span id="cb7-366"><a href="#cb7-366" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._forward, (x, emb), <span class="va">self</span>.parameters(), <span class="va">self</span>.use_checkpoint</span>
<span id="cb7-367"><a href="#cb7-367" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-368"><a href="#cb7-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-369"><a href="#cb7-369" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward(<span class="va">self</span>, x, emb):</span>
<span id="cb7-370"><a href="#cb7-370" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.updown:</span>
<span id="cb7-371"><a href="#cb7-371" aria-hidden="true" tabindex="-1"></a>            in_rest, in_conv <span class="op">=</span> <span class="va">self</span>.in_layers[:<span class="op">-</span><span class="dv">1</span>], <span class="va">self</span>.in_layers[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb7-372"><a href="#cb7-372" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> in_rest(x)</span>
<span id="cb7-373"><a href="#cb7-373" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.h_upd(h)</span>
<span id="cb7-374"><a href="#cb7-374" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.x_upd(x)</span>
<span id="cb7-375"><a href="#cb7-375" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> in_conv(h)</span>
<span id="cb7-376"><a href="#cb7-376" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-377"><a href="#cb7-377" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.in_layers(x)</span>
<span id="cb7-378"><a href="#cb7-378" aria-hidden="true" tabindex="-1"></a>        emb_out <span class="op">=</span> <span class="va">self</span>.emb_layers(emb).<span class="bu">type</span>(h.dtype)</span>
<span id="cb7-379"><a href="#cb7-379" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="bu">len</span>(emb_out.shape) <span class="op">&lt;</span> <span class="bu">len</span>(h.shape):</span>
<span id="cb7-380"><a href="#cb7-380" aria-hidden="true" tabindex="-1"></a>            emb_out <span class="op">=</span> emb_out[..., <span class="va">None</span>]</span>
<span id="cb7-381"><a href="#cb7-381" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.use_scale_shift_norm:</span>
<span id="cb7-382"><a href="#cb7-382" aria-hidden="true" tabindex="-1"></a>            out_norm, out_rest <span class="op">=</span> <span class="va">self</span>.out_layers[<span class="dv">0</span>], <span class="va">self</span>.out_layers[<span class="dv">1</span>:]</span>
<span id="cb7-383"><a href="#cb7-383" aria-hidden="true" tabindex="-1"></a>            scale, shift <span class="op">=</span> th.chunk(emb_out, <span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-384"><a href="#cb7-384" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> out_norm(h) <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> scale) <span class="op">+</span> shift</span>
<span id="cb7-385"><a href="#cb7-385" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> out_rest(h)</span>
<span id="cb7-386"><a href="#cb7-386" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-387"><a href="#cb7-387" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> h <span class="op">+</span> emb_out</span>
<span id="cb7-388"><a href="#cb7-388" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.out_layers(h)</span>
<span id="cb7-389"><a href="#cb7-389" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.skip_connection(x) <span class="op">+</span> h</span>
<span id="cb7-390"><a href="#cb7-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-391"><a href="#cb7-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-392"><a href="#cb7-392" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(nn.Module):</span>
<span id="cb7-393"><a href="#cb7-393" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-394"><a href="#cb7-394" aria-hidden="true" tabindex="-1"></a><span class="co">    An attention block that allows spatial positions to attend to each other.</span></span>
<span id="cb7-395"><a href="#cb7-395" aria-hidden="true" tabindex="-1"></a><span class="co">    Originally ported from here, but adapted to the N-d case.</span></span>
<span id="cb7-396"><a href="#cb7-396" aria-hidden="true" tabindex="-1"></a><span class="co">    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/models/unet.py#L66.</span></span>
<span id="cb7-397"><a href="#cb7-397" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-398"><a href="#cb7-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-399"><a href="#cb7-399" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb7-400"><a href="#cb7-400" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb7-401"><a href="#cb7-401" aria-hidden="true" tabindex="-1"></a>        channels,</span>
<span id="cb7-402"><a href="#cb7-402" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-403"><a href="#cb7-403" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-404"><a href="#cb7-404" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-405"><a href="#cb7-405" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-406"><a href="#cb7-406" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb7-407"><a href="#cb7-407" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-408"><a href="#cb7-408" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channels <span class="op">=</span> channels</span>
<span id="cb7-409"><a href="#cb7-409" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_head_channels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb7-410"><a href="#cb7-410" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb7-411"><a href="#cb7-411" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-412"><a href="#cb7-412" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> (</span>
<span id="cb7-413"><a href="#cb7-413" aria-hidden="true" tabindex="-1"></a>                channels <span class="op">%</span> num_head_channels <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb7-414"><a href="#cb7-414" aria-hidden="true" tabindex="-1"></a>            ), <span class="ss">f"q,k,v channels </span><span class="sc">{</span>channels<span class="sc">}</span><span class="ss"> is not divisible by num_head_channels </span><span class="sc">{</span>num_head_channels<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb7-415"><a href="#cb7-415" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_heads <span class="op">=</span> channels <span class="op">//</span> num_head_channels</span>
<span id="cb7-416"><a href="#cb7-416" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb7-417"><a href="#cb7-417" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> normalization(channels)</span>
<span id="cb7-418"><a href="#cb7-418" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qkv <span class="op">=</span> conv_nd(<span class="dv">1</span>, channels, channels <span class="op">*</span> <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb7-419"><a href="#cb7-419" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_new_attention_order:</span>
<span id="cb7-420"><a href="#cb7-420" aria-hidden="true" tabindex="-1"></a>            <span class="co"># split qkv before split heads</span></span>
<span id="cb7-421"><a href="#cb7-421" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attention <span class="op">=</span> QKVAttention(<span class="va">self</span>.num_heads)</span>
<span id="cb7-422"><a href="#cb7-422" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-423"><a href="#cb7-423" aria-hidden="true" tabindex="-1"></a>            <span class="co"># split heads before split qkv</span></span>
<span id="cb7-424"><a href="#cb7-424" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.attention <span class="op">=</span> QKVAttentionLegacy(<span class="va">self</span>.num_heads)</span>
<span id="cb7-425"><a href="#cb7-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-426"><a href="#cb7-426" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.proj_out <span class="op">=</span> zero_module(conv_nd(<span class="dv">1</span>, channels, channels, <span class="dv">1</span>))</span>
<span id="cb7-427"><a href="#cb7-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-428"><a href="#cb7-428" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-429"><a href="#cb7-429" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint(<span class="va">self</span>._forward, (x,), <span class="va">self</span>.parameters(), <span class="va">True</span>)</span>
<span id="cb7-430"><a href="#cb7-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-431"><a href="#cb7-431" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _forward(<span class="va">self</span>, x):</span>
<span id="cb7-432"><a href="#cb7-432" aria-hidden="true" tabindex="-1"></a>        b, c, <span class="op">*</span>spatial <span class="op">=</span> x.shape</span>
<span id="cb7-433"><a href="#cb7-433" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(b, c, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-434"><a href="#cb7-434" aria-hidden="true" tabindex="-1"></a>        qkv <span class="op">=</span> <span class="va">self</span>.qkv(<span class="va">self</span>.norm(x))</span>
<span id="cb7-435"><a href="#cb7-435" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.attention(qkv)</span>
<span id="cb7-436"><a href="#cb7-436" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.proj_out(h)</span>
<span id="cb7-437"><a href="#cb7-437" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (x <span class="op">+</span> h).reshape(b, c, <span class="op">*</span>spatial)</span>
<span id="cb7-438"><a href="#cb7-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-439"><a href="#cb7-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-440"><a href="#cb7-440" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_flops_attn(model, _x, y):</span>
<span id="cb7-441"><a href="#cb7-441" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-442"><a href="#cb7-442" aria-hidden="true" tabindex="-1"></a><span class="co">    A counter for the `thop` package to count the operations in an</span></span>
<span id="cb7-443"><a href="#cb7-443" aria-hidden="true" tabindex="-1"></a><span class="co">    attention operation.</span></span>
<span id="cb7-444"><a href="#cb7-444" aria-hidden="true" tabindex="-1"></a><span class="co">    Meant to be used like:</span></span>
<span id="cb7-445"><a href="#cb7-445" aria-hidden="true" tabindex="-1"></a><span class="co">        macs, params = thop.profile(</span></span>
<span id="cb7-446"><a href="#cb7-446" aria-hidden="true" tabindex="-1"></a><span class="co">            model,</span></span>
<span id="cb7-447"><a href="#cb7-447" aria-hidden="true" tabindex="-1"></a><span class="co">            inputs=(inputs, timestamps),</span></span>
<span id="cb7-448"><a href="#cb7-448" aria-hidden="true" tabindex="-1"></a><span class="co">            custom_ops={QKVAttention: QKVAttention.count_flops},</span></span>
<span id="cb7-449"><a href="#cb7-449" aria-hidden="true" tabindex="-1"></a><span class="co">        )</span></span>
<span id="cb7-450"><a href="#cb7-450" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-451"><a href="#cb7-451" aria-hidden="true" tabindex="-1"></a>    b, c, <span class="op">*</span>spatial <span class="op">=</span> y[<span class="dv">0</span>].shape</span>
<span id="cb7-452"><a href="#cb7-452" aria-hidden="true" tabindex="-1"></a>    num_spatial <span class="op">=</span> <span class="bu">int</span>(np.prod(spatial))</span>
<span id="cb7-453"><a href="#cb7-453" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We perform two matmuls with the same number of ops.</span></span>
<span id="cb7-454"><a href="#cb7-454" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The first computes the weight matrix, the second computes</span></span>
<span id="cb7-455"><a href="#cb7-455" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the combination of the value vectors.</span></span>
<span id="cb7-456"><a href="#cb7-456" aria-hidden="true" tabindex="-1"></a>    matmul_ops <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> b <span class="op">*</span> (num_spatial <span class="op">**</span> <span class="dv">2</span>) <span class="op">*</span> c</span>
<span id="cb7-457"><a href="#cb7-457" aria-hidden="true" tabindex="-1"></a>    model.total_ops <span class="op">+=</span> th.DoubleTensor([matmul_ops])</span>
<span id="cb7-458"><a href="#cb7-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-459"><a href="#cb7-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-460"><a href="#cb7-460" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QKVAttentionLegacy(nn.Module):</span>
<span id="cb7-461"><a href="#cb7-461" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-462"><a href="#cb7-462" aria-hidden="true" tabindex="-1"></a><span class="co">    A module which performs QKV attention. Matches legacy QKVAttention + input/ouput heads shaping</span></span>
<span id="cb7-463"><a href="#cb7-463" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-464"><a href="#cb7-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-465"><a href="#cb7-465" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_heads):</span>
<span id="cb7-466"><a href="#cb7-466" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-467"><a href="#cb7-467" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb7-468"><a href="#cb7-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-469"><a href="#cb7-469" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, qkv):</span>
<span id="cb7-470"><a href="#cb7-470" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-471"><a href="#cb7-471" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply QKV attention.</span></span>
<span id="cb7-472"><a href="#cb7-472" aria-hidden="true" tabindex="-1"></a><span class="co">        :param qkv: an [N x (H * 3 * C) x T] tensor of Qs, Ks, and Vs.</span></span>
<span id="cb7-473"><a href="#cb7-473" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x (H * C) x T] tensor after attention.</span></span>
<span id="cb7-474"><a href="#cb7-474" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-475"><a href="#cb7-475" aria-hidden="true" tabindex="-1"></a>        bs, width, length <span class="op">=</span> qkv.shape</span>
<span id="cb7-476"><a href="#cb7-476" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> width <span class="op">%</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb7-477"><a href="#cb7-477" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> width <span class="op">//</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads)</span>
<span id="cb7-478"><a href="#cb7-478" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.reshape(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch <span class="op">*</span> <span class="dv">3</span>, length).split(ch, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-479"><a href="#cb7-479" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(math.sqrt(ch))</span>
<span id="cb7-480"><a href="#cb7-480" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.einsum(</span>
<span id="cb7-481"><a href="#cb7-481" aria-hidden="true" tabindex="-1"></a>            <span class="st">"bct,bcs-&gt;bts"</span>, q <span class="op">*</span> scale, k <span class="op">*</span> scale</span>
<span id="cb7-482"><a href="#cb7-482" aria-hidden="true" tabindex="-1"></a>        )  <span class="co"># More stable with f16 than dividing afterwards</span></span>
<span id="cb7-483"><a href="#cb7-483" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.softmax(weight.<span class="bu">float</span>(), dim<span class="op">=-</span><span class="dv">1</span>).<span class="bu">type</span>(weight.dtype)</span>
<span id="cb7-484"><a href="#cb7-484" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> th.einsum(<span class="st">"bts,bcs-&gt;bct"</span>, weight, v)</span>
<span id="cb7-485"><a href="#cb7-485" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a.reshape(bs, <span class="op">-</span><span class="dv">1</span>, length)</span>
<span id="cb7-486"><a href="#cb7-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-487"><a href="#cb7-487" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb7-488"><a href="#cb7-488" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> count_flops(model, _x, y):</span>
<span id="cb7-489"><a href="#cb7-489" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> count_flops_attn(model, _x, y)</span>
<span id="cb7-490"><a href="#cb7-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-491"><a href="#cb7-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-492"><a href="#cb7-492" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QKVAttention(nn.Module):</span>
<span id="cb7-493"><a href="#cb7-493" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-494"><a href="#cb7-494" aria-hidden="true" tabindex="-1"></a><span class="co">    A module which performs QKV attention and splits in a different order.</span></span>
<span id="cb7-495"><a href="#cb7-495" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-496"><a href="#cb7-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-497"><a href="#cb7-497" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_heads):</span>
<span id="cb7-498"><a href="#cb7-498" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-499"><a href="#cb7-499" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_heads <span class="op">=</span> n_heads</span>
<span id="cb7-500"><a href="#cb7-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-501"><a href="#cb7-501" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, qkv):</span>
<span id="cb7-502"><a href="#cb7-502" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-503"><a href="#cb7-503" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply QKV attention.</span></span>
<span id="cb7-504"><a href="#cb7-504" aria-hidden="true" tabindex="-1"></a><span class="co">        :param qkv: an [N x (3 * H * C) x T] tensor of Qs, Ks, and Vs.</span></span>
<span id="cb7-505"><a href="#cb7-505" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x (H * C) x T] tensor after attention.</span></span>
<span id="cb7-506"><a href="#cb7-506" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-507"><a href="#cb7-507" aria-hidden="true" tabindex="-1"></a>        bs, width, length <span class="op">=</span> qkv.shape</span>
<span id="cb7-508"><a href="#cb7-508" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> width <span class="op">%</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb7-509"><a href="#cb7-509" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> width <span class="op">//</span> (<span class="dv">3</span> <span class="op">*</span> <span class="va">self</span>.n_heads)</span>
<span id="cb7-510"><a href="#cb7-510" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> qkv.chunk(<span class="dv">3</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-511"><a href="#cb7-511" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> math.sqrt(math.sqrt(ch))</span>
<span id="cb7-512"><a href="#cb7-512" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.einsum(</span>
<span id="cb7-513"><a href="#cb7-513" aria-hidden="true" tabindex="-1"></a>            <span class="st">"bct,bcs-&gt;bts"</span>,</span>
<span id="cb7-514"><a href="#cb7-514" aria-hidden="true" tabindex="-1"></a>            (q <span class="op">*</span> scale).view(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length),</span>
<span id="cb7-515"><a href="#cb7-515" aria-hidden="true" tabindex="-1"></a>            (k <span class="op">*</span> scale).view(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length),</span>
<span id="cb7-516"><a href="#cb7-516" aria-hidden="true" tabindex="-1"></a>        )  <span class="co"># More stable with f16 than dividing afterwards</span></span>
<span id="cb7-517"><a href="#cb7-517" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> th.softmax(weight.<span class="bu">float</span>(), dim<span class="op">=-</span><span class="dv">1</span>).<span class="bu">type</span>(weight.dtype)</span>
<span id="cb7-518"><a href="#cb7-518" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> th.einsum(<span class="st">"bts,bcs-&gt;bct"</span>, weight, v.reshape(bs <span class="op">*</span> <span class="va">self</span>.n_heads, ch, length))</span>
<span id="cb7-519"><a href="#cb7-519" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a.reshape(bs, <span class="op">-</span><span class="dv">1</span>, length)</span>
<span id="cb7-520"><a href="#cb7-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-521"><a href="#cb7-521" aria-hidden="true" tabindex="-1"></a>    <span class="at">@staticmethod</span></span>
<span id="cb7-522"><a href="#cb7-522" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> count_flops(model, _x, y):</span>
<span id="cb7-523"><a href="#cb7-523" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> count_flops_attn(model, _x, y)</span>
<span id="cb7-524"><a href="#cb7-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-525"><a href="#cb7-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-526"><a href="#cb7-526" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNetModel(nn.Module):</span>
<span id="cb7-527"><a href="#cb7-527" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-528"><a href="#cb7-528" aria-hidden="true" tabindex="-1"></a><span class="co">    The full UNet model with attention and timestep embedding.</span></span>
<span id="cb7-529"><a href="#cb7-529" aria-hidden="true" tabindex="-1"></a><span class="co">    :param in_channels: channels in the input Tensor.</span></span>
<span id="cb7-530"><a href="#cb7-530" aria-hidden="true" tabindex="-1"></a><span class="co">    :param emb_dim: base dimension of timestep embedding.</span></span>
<span id="cb7-531"><a href="#cb7-531" aria-hidden="true" tabindex="-1"></a><span class="co">    :param model_channels: base channel count for the model.</span></span>
<span id="cb7-532"><a href="#cb7-532" aria-hidden="true" tabindex="-1"></a><span class="co">    :param out_channels: channels in the output Tensor.</span></span>
<span id="cb7-533"><a href="#cb7-533" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_res_blocks: number of residual blocks per downsample.</span></span>
<span id="cb7-534"><a href="#cb7-534" aria-hidden="true" tabindex="-1"></a><span class="co">    :param attention_resolutions: a collection of downsample rates at which</span></span>
<span id="cb7-535"><a href="#cb7-535" aria-hidden="true" tabindex="-1"></a><span class="co">        attention will take place. May be a set, list, or tuple.</span></span>
<span id="cb7-536"><a href="#cb7-536" aria-hidden="true" tabindex="-1"></a><span class="co">        For example, if this contains 4, then at 4x downsampling, attention</span></span>
<span id="cb7-537"><a href="#cb7-537" aria-hidden="true" tabindex="-1"></a><span class="co">        will be used.</span></span>
<span id="cb7-538"><a href="#cb7-538" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dropout: the dropout probability.</span></span>
<span id="cb7-539"><a href="#cb7-539" aria-hidden="true" tabindex="-1"></a><span class="co">    :param channel_mult: channel multiplier for each level of the UNet.</span></span>
<span id="cb7-540"><a href="#cb7-540" aria-hidden="true" tabindex="-1"></a><span class="co">    :param conv_resample: if True, use learned convolutions for upsampling and</span></span>
<span id="cb7-541"><a href="#cb7-541" aria-hidden="true" tabindex="-1"></a><span class="co">        downsampling.</span></span>
<span id="cb7-542"><a href="#cb7-542" aria-hidden="true" tabindex="-1"></a><span class="co">    :param dims: determines if the signal is 1D, 2D, or 3D.</span></span>
<span id="cb7-543"><a href="#cb7-543" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_classes: if specified (as an int), then this model will be</span></span>
<span id="cb7-544"><a href="#cb7-544" aria-hidden="true" tabindex="-1"></a><span class="co">        class-conditional with `num_classes` classes.</span></span>
<span id="cb7-545"><a href="#cb7-545" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_checkpoint: use gradient checkpointing to reduce memory usage.</span></span>
<span id="cb7-546"><a href="#cb7-546" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads: the number of attention heads in each attention layer.</span></span>
<span id="cb7-547"><a href="#cb7-547" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads_channels: if specified, ignore num_heads and instead use</span></span>
<span id="cb7-548"><a href="#cb7-548" aria-hidden="true" tabindex="-1"></a><span class="co">                               a fixed channel width per attention head.</span></span>
<span id="cb7-549"><a href="#cb7-549" aria-hidden="true" tabindex="-1"></a><span class="co">    :param num_heads_upsample: works with num_heads to set a different number</span></span>
<span id="cb7-550"><a href="#cb7-550" aria-hidden="true" tabindex="-1"></a><span class="co">                               of heads for upsampling. Deprecated.</span></span>
<span id="cb7-551"><a href="#cb7-551" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_scale_shift_norm: use a FiLM-like conditioning mechanism.</span></span>
<span id="cb7-552"><a href="#cb7-552" aria-hidden="true" tabindex="-1"></a><span class="co">    :param resblock_updown: use residual blocks for up/downsampling.</span></span>
<span id="cb7-553"><a href="#cb7-553" aria-hidden="true" tabindex="-1"></a><span class="co">    :param use_new_attention_order: use a different attention pattern for potentially</span></span>
<span id="cb7-554"><a href="#cb7-554" aria-hidden="true" tabindex="-1"></a><span class="co">                                    increased efficiency.</span></span>
<span id="cb7-555"><a href="#cb7-555" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-556"><a href="#cb7-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-557"><a href="#cb7-557" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb7-558"><a href="#cb7-558" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb7-559"><a href="#cb7-559" aria-hidden="true" tabindex="-1"></a>        image_size,</span>
<span id="cb7-560"><a href="#cb7-560" aria-hidden="true" tabindex="-1"></a>        in_channels,</span>
<span id="cb7-561"><a href="#cb7-561" aria-hidden="true" tabindex="-1"></a>        model_channels,</span>
<span id="cb7-562"><a href="#cb7-562" aria-hidden="true" tabindex="-1"></a>        out_channels,</span>
<span id="cb7-563"><a href="#cb7-563" aria-hidden="true" tabindex="-1"></a>        num_res_blocks,</span>
<span id="cb7-564"><a href="#cb7-564" aria-hidden="true" tabindex="-1"></a>        attention_resolutions,</span>
<span id="cb7-565"><a href="#cb7-565" aria-hidden="true" tabindex="-1"></a>        time_emb_factor<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-566"><a href="#cb7-566" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb7-567"><a href="#cb7-567" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>),</span>
<span id="cb7-568"><a href="#cb7-568" aria-hidden="true" tabindex="-1"></a>        conv_resample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-569"><a href="#cb7-569" aria-hidden="true" tabindex="-1"></a>        dims<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-570"><a href="#cb7-570" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb7-571"><a href="#cb7-571" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-572"><a href="#cb7-572" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-573"><a href="#cb7-573" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-574"><a href="#cb7-574" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-575"><a href="#cb7-575" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-576"><a href="#cb7-576" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-577"><a href="#cb7-577" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-578"><a href="#cb7-578" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-579"><a href="#cb7-579" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb7-580"><a href="#cb7-580" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-581"><a href="#cb7-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-582"><a href="#cb7-582" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_heads_upsample <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb7-583"><a href="#cb7-583" aria-hidden="true" tabindex="-1"></a>            num_heads_upsample <span class="op">=</span> num_heads</span>
<span id="cb7-584"><a href="#cb7-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-585"><a href="#cb7-585" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_size <span class="op">=</span> image_size</span>
<span id="cb7-586"><a href="#cb7-586" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_channels <span class="op">=</span> in_channels</span>
<span id="cb7-587"><a href="#cb7-587" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_channels <span class="op">=</span> model_channels</span>
<span id="cb7-588"><a href="#cb7-588" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels</span>
<span id="cb7-589"><a href="#cb7-589" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_res_blocks <span class="op">=</span> num_res_blocks</span>
<span id="cb7-590"><a href="#cb7-590" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention_resolutions <span class="op">=</span> attention_resolutions</span>
<span id="cb7-591"><a href="#cb7-591" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> dropout</span>
<span id="cb7-592"><a href="#cb7-592" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.channel_mult <span class="op">=</span> channel_mult</span>
<span id="cb7-593"><a href="#cb7-593" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_resample <span class="op">=</span> conv_resample</span>
<span id="cb7-594"><a href="#cb7-594" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_classes <span class="op">=</span> num_classes</span>
<span id="cb7-595"><a href="#cb7-595" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.use_checkpoint <span class="op">=</span> use_checkpoint</span>
<span id="cb7-596"><a href="#cb7-596" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dtype <span class="op">=</span> th.float16 <span class="cf">if</span> use_fp16 <span class="cf">else</span> th.float32</span>
<span id="cb7-597"><a href="#cb7-597" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb7-598"><a href="#cb7-598" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_head_channels <span class="op">=</span> num_head_channels</span>
<span id="cb7-599"><a href="#cb7-599" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads_upsample <span class="op">=</span> num_heads_upsample</span>
<span id="cb7-600"><a href="#cb7-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-601"><a href="#cb7-601" aria-hidden="true" tabindex="-1"></a>        time_embed_dim <span class="op">=</span> model_channels <span class="op">*</span> time_emb_factor</span>
<span id="cb7-602"><a href="#cb7-602" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time_embed <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-603"><a href="#cb7-603" aria-hidden="true" tabindex="-1"></a>            linear(model_channels, time_embed_dim),</span>
<span id="cb7-604"><a href="#cb7-604" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb7-605"><a href="#cb7-605" aria-hidden="true" tabindex="-1"></a>            linear(time_embed_dim, time_embed_dim),</span>
<span id="cb7-606"><a href="#cb7-606" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-607"><a href="#cb7-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-608"><a href="#cb7-608" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-609"><a href="#cb7-609" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.label_emb <span class="op">=</span> nn.Embedding(num_classes, time_embed_dim)</span>
<span id="cb7-610"><a href="#cb7-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-611"><a href="#cb7-611" aria-hidden="true" tabindex="-1"></a>        ch <span class="op">=</span> input_ch <span class="op">=</span> <span class="bu">int</span>(channel_mult[<span class="dv">0</span>] <span class="op">*</span> model_channels)</span>
<span id="cb7-612"><a href="#cb7-612" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_blocks <span class="op">=</span> nn.ModuleList(</span>
<span id="cb7-613"><a href="#cb7-613" aria-hidden="true" tabindex="-1"></a>            [TimestepEmbedSequential(conv_nd(dims, in_channels, ch, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>))]</span>
<span id="cb7-614"><a href="#cb7-614" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-615"><a href="#cb7-615" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_size <span class="op">=</span> ch</span>
<span id="cb7-616"><a href="#cb7-616" aria-hidden="true" tabindex="-1"></a>        input_block_chans <span class="op">=</span> [ch]</span>
<span id="cb7-617"><a href="#cb7-617" aria-hidden="true" tabindex="-1"></a>        ds <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-618"><a href="#cb7-618" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> level, mult <span class="kw">in</span> <span class="bu">enumerate</span>(channel_mult):</span>
<span id="cb7-619"><a href="#cb7-619" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks):</span>
<span id="cb7-620"><a href="#cb7-620" aria-hidden="true" tabindex="-1"></a>                layers <span class="op">=</span> [</span>
<span id="cb7-621"><a href="#cb7-621" aria-hidden="true" tabindex="-1"></a>                    ResBlock(</span>
<span id="cb7-622"><a href="#cb7-622" aria-hidden="true" tabindex="-1"></a>                        ch,</span>
<span id="cb7-623"><a href="#cb7-623" aria-hidden="true" tabindex="-1"></a>                        time_embed_dim,</span>
<span id="cb7-624"><a href="#cb7-624" aria-hidden="true" tabindex="-1"></a>                        dropout,</span>
<span id="cb7-625"><a href="#cb7-625" aria-hidden="true" tabindex="-1"></a>                        out_channels<span class="op">=</span><span class="bu">int</span>(mult <span class="op">*</span> model_channels),</span>
<span id="cb7-626"><a href="#cb7-626" aria-hidden="true" tabindex="-1"></a>                        dims<span class="op">=</span>dims,</span>
<span id="cb7-627"><a href="#cb7-627" aria-hidden="true" tabindex="-1"></a>                        use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-628"><a href="#cb7-628" aria-hidden="true" tabindex="-1"></a>                        use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb7-629"><a href="#cb7-629" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb7-630"><a href="#cb7-630" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb7-631"><a href="#cb7-631" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> <span class="bu">int</span>(mult <span class="op">*</span> model_channels)</span>
<span id="cb7-632"><a href="#cb7-632" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> ds <span class="kw">in</span> attention_resolutions:</span>
<span id="cb7-633"><a href="#cb7-633" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb7-634"><a href="#cb7-634" aria-hidden="true" tabindex="-1"></a>                        AttentionBlock(</span>
<span id="cb7-635"><a href="#cb7-635" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb7-636"><a href="#cb7-636" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-637"><a href="#cb7-637" aria-hidden="true" tabindex="-1"></a>                            num_heads<span class="op">=</span>num_heads,</span>
<span id="cb7-638"><a href="#cb7-638" aria-hidden="true" tabindex="-1"></a>                            num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb7-639"><a href="#cb7-639" aria-hidden="true" tabindex="-1"></a>                            use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb7-640"><a href="#cb7-640" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb7-641"><a href="#cb7-641" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb7-642"><a href="#cb7-642" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.input_blocks.append(TimestepEmbedSequential(<span class="op">*</span>layers))</span>
<span id="cb7-643"><a href="#cb7-643" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb7-644"><a href="#cb7-644" aria-hidden="true" tabindex="-1"></a>                input_block_chans.append(ch)</span>
<span id="cb7-645"><a href="#cb7-645" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> level <span class="op">!=</span> <span class="bu">len</span>(channel_mult) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb7-646"><a href="#cb7-646" aria-hidden="true" tabindex="-1"></a>                out_ch <span class="op">=</span> ch</span>
<span id="cb7-647"><a href="#cb7-647" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.input_blocks.append(</span>
<span id="cb7-648"><a href="#cb7-648" aria-hidden="true" tabindex="-1"></a>                    TimestepEmbedSequential(</span>
<span id="cb7-649"><a href="#cb7-649" aria-hidden="true" tabindex="-1"></a>                        ResBlock(</span>
<span id="cb7-650"><a href="#cb7-650" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb7-651"><a href="#cb7-651" aria-hidden="true" tabindex="-1"></a>                            time_embed_dim,</span>
<span id="cb7-652"><a href="#cb7-652" aria-hidden="true" tabindex="-1"></a>                            dropout,</span>
<span id="cb7-653"><a href="#cb7-653" aria-hidden="true" tabindex="-1"></a>                            out_channels<span class="op">=</span>out_ch,</span>
<span id="cb7-654"><a href="#cb7-654" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>dims,</span>
<span id="cb7-655"><a href="#cb7-655" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-656"><a href="#cb7-656" aria-hidden="true" tabindex="-1"></a>                            use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb7-657"><a href="#cb7-657" aria-hidden="true" tabindex="-1"></a>                            down<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-658"><a href="#cb7-658" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb7-659"><a href="#cb7-659" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> resblock_updown</span>
<span id="cb7-660"><a href="#cb7-660" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> Downsample(</span>
<span id="cb7-661"><a href="#cb7-661" aria-hidden="true" tabindex="-1"></a>                            ch, conv_resample, dims<span class="op">=</span>dims, out_channels<span class="op">=</span>out_ch</span>
<span id="cb7-662"><a href="#cb7-662" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb7-663"><a href="#cb7-663" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb7-664"><a href="#cb7-664" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb7-665"><a href="#cb7-665" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> out_ch</span>
<span id="cb7-666"><a href="#cb7-666" aria-hidden="true" tabindex="-1"></a>                input_block_chans.append(ch)</span>
<span id="cb7-667"><a href="#cb7-667" aria-hidden="true" tabindex="-1"></a>                ds <span class="op">*=</span> <span class="dv">2</span></span>
<span id="cb7-668"><a href="#cb7-668" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb7-669"><a href="#cb7-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-670"><a href="#cb7-670" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.middle_block <span class="op">=</span> TimestepEmbedSequential(</span>
<span id="cb7-671"><a href="#cb7-671" aria-hidden="true" tabindex="-1"></a>            ResBlock(</span>
<span id="cb7-672"><a href="#cb7-672" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb7-673"><a href="#cb7-673" aria-hidden="true" tabindex="-1"></a>                time_embed_dim,</span>
<span id="cb7-674"><a href="#cb7-674" aria-hidden="true" tabindex="-1"></a>                dropout,</span>
<span id="cb7-675"><a href="#cb7-675" aria-hidden="true" tabindex="-1"></a>                dims<span class="op">=</span>dims,</span>
<span id="cb7-676"><a href="#cb7-676" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-677"><a href="#cb7-677" aria-hidden="true" tabindex="-1"></a>                use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb7-678"><a href="#cb7-678" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb7-679"><a href="#cb7-679" aria-hidden="true" tabindex="-1"></a>            AttentionBlock(</span>
<span id="cb7-680"><a href="#cb7-680" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb7-681"><a href="#cb7-681" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-682"><a href="#cb7-682" aria-hidden="true" tabindex="-1"></a>                num_heads<span class="op">=</span>num_heads,</span>
<span id="cb7-683"><a href="#cb7-683" aria-hidden="true" tabindex="-1"></a>                num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb7-684"><a href="#cb7-684" aria-hidden="true" tabindex="-1"></a>                use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb7-685"><a href="#cb7-685" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb7-686"><a href="#cb7-686" aria-hidden="true" tabindex="-1"></a>            ResBlock(</span>
<span id="cb7-687"><a href="#cb7-687" aria-hidden="true" tabindex="-1"></a>                ch,</span>
<span id="cb7-688"><a href="#cb7-688" aria-hidden="true" tabindex="-1"></a>                time_embed_dim,</span>
<span id="cb7-689"><a href="#cb7-689" aria-hidden="true" tabindex="-1"></a>                dropout,</span>
<span id="cb7-690"><a href="#cb7-690" aria-hidden="true" tabindex="-1"></a>                dims<span class="op">=</span>dims,</span>
<span id="cb7-691"><a href="#cb7-691" aria-hidden="true" tabindex="-1"></a>                use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-692"><a href="#cb7-692" aria-hidden="true" tabindex="-1"></a>                use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb7-693"><a href="#cb7-693" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb7-694"><a href="#cb7-694" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-695"><a href="#cb7-695" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb7-696"><a href="#cb7-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-697"><a href="#cb7-697" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_blocks <span class="op">=</span> nn.ModuleList([])</span>
<span id="cb7-698"><a href="#cb7-698" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> level, mult <span class="kw">in</span> <span class="bu">list</span>(<span class="bu">enumerate</span>(channel_mult))[::<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb7-699"><a href="#cb7-699" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb7-700"><a href="#cb7-700" aria-hidden="true" tabindex="-1"></a>                ich <span class="op">=</span> input_block_chans.pop()</span>
<span id="cb7-701"><a href="#cb7-701" aria-hidden="true" tabindex="-1"></a>                layers <span class="op">=</span> [</span>
<span id="cb7-702"><a href="#cb7-702" aria-hidden="true" tabindex="-1"></a>                    ResBlock(</span>
<span id="cb7-703"><a href="#cb7-703" aria-hidden="true" tabindex="-1"></a>                        ch <span class="op">+</span> ich,</span>
<span id="cb7-704"><a href="#cb7-704" aria-hidden="true" tabindex="-1"></a>                        time_embed_dim,</span>
<span id="cb7-705"><a href="#cb7-705" aria-hidden="true" tabindex="-1"></a>                        dropout,</span>
<span id="cb7-706"><a href="#cb7-706" aria-hidden="true" tabindex="-1"></a>                        out_channels<span class="op">=</span><span class="bu">int</span>(model_channels <span class="op">*</span> mult),</span>
<span id="cb7-707"><a href="#cb7-707" aria-hidden="true" tabindex="-1"></a>                        dims<span class="op">=</span>dims,</span>
<span id="cb7-708"><a href="#cb7-708" aria-hidden="true" tabindex="-1"></a>                        use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-709"><a href="#cb7-709" aria-hidden="true" tabindex="-1"></a>                        use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb7-710"><a href="#cb7-710" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb7-711"><a href="#cb7-711" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb7-712"><a href="#cb7-712" aria-hidden="true" tabindex="-1"></a>                ch <span class="op">=</span> <span class="bu">int</span>(model_channels <span class="op">*</span> mult)</span>
<span id="cb7-713"><a href="#cb7-713" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> ds <span class="kw">in</span> attention_resolutions:</span>
<span id="cb7-714"><a href="#cb7-714" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb7-715"><a href="#cb7-715" aria-hidden="true" tabindex="-1"></a>                        AttentionBlock(</span>
<span id="cb7-716"><a href="#cb7-716" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb7-717"><a href="#cb7-717" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-718"><a href="#cb7-718" aria-hidden="true" tabindex="-1"></a>                            num_heads<span class="op">=</span>num_heads_upsample,</span>
<span id="cb7-719"><a href="#cb7-719" aria-hidden="true" tabindex="-1"></a>                            num_head_channels<span class="op">=</span>num_head_channels,</span>
<span id="cb7-720"><a href="#cb7-720" aria-hidden="true" tabindex="-1"></a>                            use_new_attention_order<span class="op">=</span>use_new_attention_order,</span>
<span id="cb7-721"><a href="#cb7-721" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb7-722"><a href="#cb7-722" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb7-723"><a href="#cb7-723" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> level <span class="kw">and</span> i <span class="op">==</span> num_res_blocks:</span>
<span id="cb7-724"><a href="#cb7-724" aria-hidden="true" tabindex="-1"></a>                    out_ch <span class="op">=</span> ch</span>
<span id="cb7-725"><a href="#cb7-725" aria-hidden="true" tabindex="-1"></a>                    layers.append(</span>
<span id="cb7-726"><a href="#cb7-726" aria-hidden="true" tabindex="-1"></a>                        ResBlock(</span>
<span id="cb7-727"><a href="#cb7-727" aria-hidden="true" tabindex="-1"></a>                            ch,</span>
<span id="cb7-728"><a href="#cb7-728" aria-hidden="true" tabindex="-1"></a>                            time_embed_dim,</span>
<span id="cb7-729"><a href="#cb7-729" aria-hidden="true" tabindex="-1"></a>                            dropout,</span>
<span id="cb7-730"><a href="#cb7-730" aria-hidden="true" tabindex="-1"></a>                            out_channels<span class="op">=</span>out_ch,</span>
<span id="cb7-731"><a href="#cb7-731" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>dims,</span>
<span id="cb7-732"><a href="#cb7-732" aria-hidden="true" tabindex="-1"></a>                            use_checkpoint<span class="op">=</span>use_checkpoint,</span>
<span id="cb7-733"><a href="#cb7-733" aria-hidden="true" tabindex="-1"></a>                            use_scale_shift_norm<span class="op">=</span>use_scale_shift_norm,</span>
<span id="cb7-734"><a href="#cb7-734" aria-hidden="true" tabindex="-1"></a>                            up<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-735"><a href="#cb7-735" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb7-736"><a href="#cb7-736" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> resblock_updown</span>
<span id="cb7-737"><a href="#cb7-737" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span> Upsample(ch, conv_resample, dims<span class="op">=</span>dims, out_channels<span class="op">=</span>out_ch)</span>
<span id="cb7-738"><a href="#cb7-738" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb7-739"><a href="#cb7-739" aria-hidden="true" tabindex="-1"></a>                    ds <span class="op">//=</span> <span class="dv">2</span></span>
<span id="cb7-740"><a href="#cb7-740" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.output_blocks.append(TimestepEmbedSequential(<span class="op">*</span>layers))</span>
<span id="cb7-741"><a href="#cb7-741" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>._feature_size <span class="op">+=</span> ch</span>
<span id="cb7-742"><a href="#cb7-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-743"><a href="#cb7-743" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-744"><a href="#cb7-744" aria-hidden="true" tabindex="-1"></a>            normalization(ch),</span>
<span id="cb7-745"><a href="#cb7-745" aria-hidden="true" tabindex="-1"></a>            nn.SiLU(),</span>
<span id="cb7-746"><a href="#cb7-746" aria-hidden="true" tabindex="-1"></a>            zero_module(conv_nd(dims, input_ch, out_channels, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb7-747"><a href="#cb7-747" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-748"><a href="#cb7-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-749"><a href="#cb7-749" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, t, x, y<span class="op">=</span><span class="va">None</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb7-750"><a href="#cb7-750" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-751"><a href="#cb7-751" aria-hidden="true" tabindex="-1"></a><span class="co">        Apply the model to an input batch.</span></span>
<span id="cb7-752"><a href="#cb7-752" aria-hidden="true" tabindex="-1"></a><span class="co">        :param t: a 1-D batch of timesteps.</span></span>
<span id="cb7-753"><a href="#cb7-753" aria-hidden="true" tabindex="-1"></a><span class="co">        :param x: an [N x C x ...] Tensor of inputs.</span></span>
<span id="cb7-754"><a href="#cb7-754" aria-hidden="true" tabindex="-1"></a><span class="co">        :param y: an [N] Tensor of labels, if class-conditional.</span></span>
<span id="cb7-755"><a href="#cb7-755" aria-hidden="true" tabindex="-1"></a><span class="co">        :return: an [N x C x ...] Tensor of outputs.</span></span>
<span id="cb7-756"><a href="#cb7-756" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-757"><a href="#cb7-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-758"><a href="#cb7-758" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> (y <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>) <span class="op">==</span> (</span>
<span id="cb7-759"><a href="#cb7-759" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb7-760"><a href="#cb7-760" aria-hidden="true" tabindex="-1"></a>        ), <span class="st">"must specify y if and only if the model is class-conditional"</span></span>
<span id="cb7-761"><a href="#cb7-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-762"><a href="#cb7-762" aria-hidden="true" tabindex="-1"></a>        hs <span class="op">=</span> []</span>
<span id="cb7-763"><a href="#cb7-763" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> <span class="va">self</span>.time_embed(timestep_embedding(t, <span class="va">self</span>.model_channels))</span>
<span id="cb7-764"><a href="#cb7-764" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_classes <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-765"><a href="#cb7-765" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> y.shape <span class="op">==</span> (x.shape[<span class="dv">0</span>],)</span>
<span id="cb7-766"><a href="#cb7-766" aria-hidden="true" tabindex="-1"></a>            emb <span class="op">=</span> emb <span class="op">+</span> <span class="va">self</span>.label_emb(y)</span>
<span id="cb7-767"><a href="#cb7-767" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> x.<span class="bu">type</span>(<span class="va">self</span>.dtype)</span>
<span id="cb7-768"><a href="#cb7-768" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.input_blocks:</span>
<span id="cb7-769"><a href="#cb7-769" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> module(h, emb)</span>
<span id="cb7-770"><a href="#cb7-770" aria-hidden="true" tabindex="-1"></a>            hs.append(h)</span>
<span id="cb7-771"><a href="#cb7-771" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.middle_block(h, emb)</span>
<span id="cb7-772"><a href="#cb7-772" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.output_blocks:</span>
<span id="cb7-773"><a href="#cb7-773" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> th.cat([h, hs.pop()], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-774"><a href="#cb7-774" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> module(h, emb)</span>
<span id="cb7-775"><a href="#cb7-775" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> h.<span class="bu">type</span>(x.dtype)</span>
<span id="cb7-776"><a href="#cb7-776" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out(h)</span>
<span id="cb7-777"><a href="#cb7-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-778"><a href="#cb7-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-779"><a href="#cb7-779" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNetBig(</span>
<span id="cb7-780"><a href="#cb7-780" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb7-781"><a href="#cb7-781" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-782"><a href="#cb7-782" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-783"><a href="#cb7-783" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">192</span>,</span>
<span id="cb7-784"><a href="#cb7-784" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb7-785"><a href="#cb7-785" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb7-786"><a href="#cb7-786" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb7-787"><a href="#cb7-787" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb7-788"><a href="#cb7-788" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb7-789"><a href="#cb7-789" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb7-790"><a href="#cb7-790" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb7-791"><a href="#cb7-791" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-792"><a href="#cb7-792" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb7-793"><a href="#cb7-793" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-794"><a href="#cb7-794" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-795"><a href="#cb7-795" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-796"><a href="#cb7-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-797"><a href="#cb7-797" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb7-798"><a href="#cb7-798" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb7-799"><a href="#cb7-799" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb7-800"><a href="#cb7-800" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-801"><a href="#cb7-801" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb7-802"><a href="#cb7-802" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb7-803"><a href="#cb7-803" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb7-804"><a href="#cb7-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-805"><a href="#cb7-805" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb7-806"><a href="#cb7-806" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb7-807"><a href="#cb7-807" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb7-808"><a href="#cb7-808" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb7-809"><a href="#cb7-809" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb7-810"><a href="#cb7-810" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-811"><a href="#cb7-811" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb7-812"><a href="#cb7-812" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb7-813"><a href="#cb7-813" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb7-814"><a href="#cb7-814" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb7-815"><a href="#cb7-815" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-816"><a href="#cb7-816" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-817"><a href="#cb7-817" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-818"><a href="#cb7-818" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb7-819"><a href="#cb7-819" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-820"><a href="#cb7-820" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-821"><a href="#cb7-821" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-822"><a href="#cb7-822" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-823"><a href="#cb7-823" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-824"><a href="#cb7-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-825"><a href="#cb7-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-826"><a href="#cb7-826" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNet(</span>
<span id="cb7-827"><a href="#cb7-827" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb7-828"><a href="#cb7-828" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-829"><a href="#cb7-829" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-830"><a href="#cb7-830" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb7-831"><a href="#cb7-831" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb7-832"><a href="#cb7-832" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb7-833"><a href="#cb7-833" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb7-834"><a href="#cb7-834" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb7-835"><a href="#cb7-835" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb7-836"><a href="#cb7-836" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb7-837"><a href="#cb7-837" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb7-838"><a href="#cb7-838" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-839"><a href="#cb7-839" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb7-840"><a href="#cb7-840" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-841"><a href="#cb7-841" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-842"><a href="#cb7-842" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-843"><a href="#cb7-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-844"><a href="#cb7-844" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb7-845"><a href="#cb7-845" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb7-846"><a href="#cb7-846" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb7-847"><a href="#cb7-847" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-848"><a href="#cb7-848" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb7-849"><a href="#cb7-849" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb7-850"><a href="#cb7-850" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb7-851"><a href="#cb7-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-852"><a href="#cb7-852" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb7-853"><a href="#cb7-853" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb7-854"><a href="#cb7-854" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb7-855"><a href="#cb7-855" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb7-856"><a href="#cb7-856" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb7-857"><a href="#cb7-857" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-858"><a href="#cb7-858" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb7-859"><a href="#cb7-859" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb7-860"><a href="#cb7-860" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb7-861"><a href="#cb7-861" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb7-862"><a href="#cb7-862" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-863"><a href="#cb7-863" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-864"><a href="#cb7-864" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-865"><a href="#cb7-865" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb7-866"><a href="#cb7-866" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-867"><a href="#cb7-867" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-868"><a href="#cb7-868" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-869"><a href="#cb7-869" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-870"><a href="#cb7-870" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-871"><a href="#cb7-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-872"><a href="#cb7-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-873"><a href="#cb7-873" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> UNetSmall(</span>
<span id="cb7-874"><a href="#cb7-874" aria-hidden="true" tabindex="-1"></a>    image_size,</span>
<span id="cb7-875"><a href="#cb7-875" aria-hidden="true" tabindex="-1"></a>    in_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-876"><a href="#cb7-876" aria-hidden="true" tabindex="-1"></a>    out_channels<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-877"><a href="#cb7-877" aria-hidden="true" tabindex="-1"></a>    base_width<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb7-878"><a href="#cb7-878" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb7-879"><a href="#cb7-879" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb7-880"><a href="#cb7-880" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">128</span>:</span>
<span id="cb7-881"><a href="#cb7-881" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb7-882"><a href="#cb7-882" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">64</span>:</span>
<span id="cb7-883"><a href="#cb7-883" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb7-884"><a href="#cb7-884" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">32</span>:</span>
<span id="cb7-885"><a href="#cb7-885" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-886"><a href="#cb7-886" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb7-887"><a href="#cb7-887" aria-hidden="true" tabindex="-1"></a>        channel_mult <span class="op">=</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-888"><a href="#cb7-888" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-889"><a href="#cb7-889" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"unsupported image size: </span><span class="sc">{</span>image_size<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-890"><a href="#cb7-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-891"><a href="#cb7-891" aria-hidden="true" tabindex="-1"></a>    attention_ds <span class="op">=</span> []</span>
<span id="cb7-892"><a href="#cb7-892" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_size <span class="op">==</span> <span class="dv">28</span>:</span>
<span id="cb7-893"><a href="#cb7-893" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"28,14,7"</span></span>
<span id="cb7-894"><a href="#cb7-894" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-895"><a href="#cb7-895" aria-hidden="true" tabindex="-1"></a>        attention_resolutions <span class="op">=</span> <span class="st">"32,16,8"</span></span>
<span id="cb7-896"><a href="#cb7-896" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> attention_resolutions.split(<span class="st">","</span>):</span>
<span id="cb7-897"><a href="#cb7-897" aria-hidden="true" tabindex="-1"></a>        attention_ds.append(image_size <span class="op">//</span> <span class="bu">int</span>(res))</span>
<span id="cb7-898"><a href="#cb7-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-899"><a href="#cb7-899" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> UNetModel(</span>
<span id="cb7-900"><a href="#cb7-900" aria-hidden="true" tabindex="-1"></a>        image_size<span class="op">=</span>image_size,</span>
<span id="cb7-901"><a href="#cb7-901" aria-hidden="true" tabindex="-1"></a>        in_channels<span class="op">=</span>in_channels,</span>
<span id="cb7-902"><a href="#cb7-902" aria-hidden="true" tabindex="-1"></a>        model_channels<span class="op">=</span>base_width,</span>
<span id="cb7-903"><a href="#cb7-903" aria-hidden="true" tabindex="-1"></a>        out_channels<span class="op">=</span>out_channels,</span>
<span id="cb7-904"><a href="#cb7-904" aria-hidden="true" tabindex="-1"></a>        num_res_blocks<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-905"><a href="#cb7-905" aria-hidden="true" tabindex="-1"></a>        attention_resolutions<span class="op">=</span><span class="bu">tuple</span>(attention_ds),</span>
<span id="cb7-906"><a href="#cb7-906" aria-hidden="true" tabindex="-1"></a>        time_emb_factor<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-907"><a href="#cb7-907" aria-hidden="true" tabindex="-1"></a>        dropout<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb7-908"><a href="#cb7-908" aria-hidden="true" tabindex="-1"></a>        channel_mult<span class="op">=</span>channel_mult,</span>
<span id="cb7-909"><a href="#cb7-909" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes,</span>
<span id="cb7-910"><a href="#cb7-910" aria-hidden="true" tabindex="-1"></a>        use_checkpoint<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-911"><a href="#cb7-911" aria-hidden="true" tabindex="-1"></a>        use_fp16<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-912"><a href="#cb7-912" aria-hidden="true" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb7-913"><a href="#cb7-913" aria-hidden="true" tabindex="-1"></a>        num_head_channels<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb7-914"><a href="#cb7-914" aria-hidden="true" tabindex="-1"></a>        num_heads_upsample<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-915"><a href="#cb7-915" aria-hidden="true" tabindex="-1"></a>        use_scale_shift_norm<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-916"><a href="#cb7-916" aria-hidden="true" tabindex="-1"></a>        resblock_updown<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-917"><a href="#cb7-917" aria-hidden="true" tabindex="-1"></a>        use_new_attention_order<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-918"><a href="#cb7-918" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-model-the-user-logic" class="level3">
<h3 class="anchored" data-anchor-id="create-model-the-user-logic">Create model (the user logic)</h3>
<div id="cell-14" class="cell" data-outputid="135b45ea-0a39-4376-ec4e-84370866d498" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>denoising_model <span class="op">=</span> UNet(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    image_size<span class="op">=</span>config.resolution,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"model params: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> denoising_model.parameters()) <span class="op">/</span> <span class="fl">1e6</span><span class="sc">:.2f}</span><span class="ss"> M"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>model params: 14.42 M</code></pre>
</div>
</div>
</section>
<section id="optimizer" class="level3">
<h3 class="anchored" data-anchor-id="optimizer">Optimizer</h3>
<div id="cell-16" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.AdamW(denoising_model.parameters(), lr<span class="op">=</span>config.learning_rate, weight_decay<span class="op">=</span>config.weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train</h2>
<section id="forward-diffusion" class="level3">
<h3 class="anchored" data-anchor-id="forward-diffusion">Forward diffusion</h3>
<p>Forward diffusion can be considered as “data augmentation” in the training step. It adds noise to the data to challenge the model to be able to tell apart signal from noise. Diffusion is a particular way of adding noise, with a carefully designed noise schedule.</p>
<p>The forward diffusion defines a sequence of images:</p>
<p><span class="math display">\[x_0, x_1, x_2, ..., x_T\]</span></p>
<p>where T is the number of diffusion steps (e.g.&nbsp;1000).</p>
<p>Similar to an algebraic sequence with a common difference, the diffusion sequence has a common noise <span class="math inline">\(\mathbf\epsilon\)</span>. The recursive formula is:</p>
<p><span class="math display">\[
x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{\beta_t} \mathbf\epsilon
\]</span></p>
<p>where <span class="math inline">\(\beta_t = 1 - \alpha_t\)</span> is the variance of the noise at time <span class="math inline">\(t\)</span>. This relationship is primarily a design choice that simplifies the mathematics and makes the derivations more elegant and manageable.</p>
<p>One can then derive the explicit formula for <span class="math inline">\(x_t\)</span> expressed in terms of <span class="math inline">\(x_0\)</span> and <span class="math inline">\(\mathbf\epsilon\)</span>:</p>
<p><span class="math display">\[
x_t = \sqrt{\bar\alpha_t} x_0 + \sqrt{1 - \bar\alpha_t} \mathbf\epsilon
\]</span></p>
<p>where <span class="math inline">\(\bar\alpha_t = \prod_{i=1}^t \alpha_i\)</span> is the cumulative product of the variance of the noise at time <span class="math inline">\(t\)</span>.</p>
<p>The forward diffusion process is thus defined by this noise schedule: <span class="math inline">\(\beta_1, \beta_2, ..., \beta_T\)</span>.</p>
<div id="cell-19" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    _ts <span class="op">=</span> t.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> noise <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> torch.randn_like(x_0)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> _ts.<span class="bu">max</span>() <span class="op">&lt;</span> <span class="bu">len</span>(noise_schedule[<span class="st">"alphas_cumprod"</span>]), <span class="ss">f"t=</span><span class="sc">{</span>_ts<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss"> is larger than the length of noise_schedule: </span><span class="sc">{</span><span class="bu">len</span>(noise_schedule[<span class="st">'alphas_cumprod'</span>])<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][_ts]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (alpha_prod_t <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> x_0 <span class="op">+</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_prod_t) <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> noise</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t, noise</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="noise-schedule" class="level4">
<h4 class="anchored" data-anchor-id="noise-schedule">Noise schedule</h4>
<p>The range of <span class="math inline">\(\beta_t\)</span> is empirically chosen to be between 1e-4 and 0.02. We can plot the noise schedule curves to visualize the blending ratio between the clean data and the noise, and how it changes over “time” through the diffusion process.</p>
<div id="cell-21" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>beta_min, beta_max <span class="op">=</span> <span class="fl">1e-4</span>, <span class="fl">0.02</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_min, beta_max = 1e-4, 1</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_min, beta_max = 0, 0.02</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_noise_schedule(n_T: <span class="bu">int</span>, device: torch.device) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, torch.Tensor]:</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    betas <span class="op">=</span> torch.linspace(beta_min, beta_max, n_T).to(device)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> betas</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    alphas_cumprod <span class="op">=</span> torch.cumprod(alphas, axis<span class="op">=</span><span class="dv">0</span>).to(device)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    alphas_cumprod_prev <span class="op">=</span> torch.cat([torch.ones(<span class="dv">1</span>).to(device), alphas_cumprod[:<span class="op">-</span><span class="dv">1</span>].to(device)])</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    sqrt_recip_alphas <span class="op">=</span> torch.sqrt(<span class="fl">1.0</span> <span class="op">/</span> alphas).to(device)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    sqrt_alphas_cumprod <span class="op">=</span> torch.sqrt(alphas_cumprod).to(device)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    sqrt_one_minus_alphas_cumprod <span class="op">=</span> torch.sqrt(<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    posterior_variance <span class="op">=</span> betas <span class="op">*</span> (<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod_prev) <span class="op">/</span> (<span class="fl">1.</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"betas"</span>: betas,</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"alphas"</span>: alphas,</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"alphas_cumprod"</span>: alphas_cumprod,</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_recip_alphas"</span>: sqrt_recip_alphas,</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_alphas_cumprod"</span>: sqrt_alphas_cumprod,</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqrt_one_minus_alphas_cumprod"</span>: sqrt_one_minus_alphas_cumprod,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"posterior_variance"</span>: posterior_variance,</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>noise_schedule <span class="op">=</span> create_noise_schedule(config.num_denoising_steps, device)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the schedule</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"betas"</span>].cpu().numpy())</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"beta_t"</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"alphas_cumprod_t"</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"sqrt_alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"sqrt_alphas_cumprod_t"</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)<span class="op">;</span> plt.plot(<span class="bu">range</span>(<span class="dv">1000</span>), noise_schedule[<span class="st">"sqrt_one_minus_alphas_cumprod"</span>].cpu().numpy())</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.title(<span class="st">"sqrt_one_minus_alphas_cumprod_t"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="visualizing-forward-diffusion-on-an-image" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-forward-diffusion-on-an-image">Visualizing forward diffusion on an image</h3>
<div id="cell-23" class="cell" data-outputid="10c287ea-0fbb-450c-a9ac-cdb16bdfc9ac" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's see what forward diffusion does.</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>x_0, _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(val_dataloader))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>x_0 <span class="op">=</span> x_0.to(device)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>x_t_list <span class="op">=</span> []</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>common_noise <span class="op">=</span> torch.randn_like(x_0)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"x_0 std:", x_0[0].std().item())</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>noise_levels <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> noise_levels:</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  t <span class="op">=</span> torch.full((x_0.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>device)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  x_t_list.append(forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span>common_noise)[<span class="dv">0</span>])</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (t, x_t) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(noise_levels, x_t_list)):</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># print(x_t[0].min().item(), x_t[0].max().item())</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  plt.subplot(<span class="dv">1</span>, <span class="dv">10</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  plt.title(<span class="ss">f"t=</span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">, std=</span><span class="sc">{</span>x_t[<span class="dv">0</span>]<span class="sc">.</span>std()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> x_t[<span class="dv">0</span>].cpu().numpy().transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> (img <span class="op">-</span> img.<span class="bu">min</span>()) <span class="op">/</span> (img.<span class="bu">max</span>() <span class="op">-</span> img.<span class="bu">min</span>())</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> i <span class="op">&gt;=</span> <span class="dv">10</span>:</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Through forward diffusion, the image quality actually appears to degrade quickly. By the time <span class="math inline">\(t=100\)</span>, the cat is almost not recognizable. By <span class="math inline">\(t=500\)</span>, the image is almost completely noise to the eye. Much of the diffusion process is spent on the “noise-dominant” regime, where the structured image is lost and what remains is a Gaussian-like noisy pattern.</p>
<p>This is helpful for the model to learn to denoise the image.</p>
<ul>
<li><p>By including a long regime where the image is essentially noise, the model learns how to reconstruct a clean image from a broad range of noise levels. This comprehensive exposure helps the model become more robust and generalize better.</p></li>
<li><p>The final goal at sampling time is to start from pure noise (around <span class="math inline">\(x_T\)</span>) and iteratively denoise until reaching a plausible sample <span class="math inline">\(x_0\)</span>. If the model had fewer steps and tried to denoise a still somewhat structured image in fewer transitions, it might be harder to learn a smooth, stable backward trajectory. The long noise regime ensures the model is comfortable dealing with extremely noisy inputs and making small, incremental corrections. ​</p></li>
</ul>
</section>
</section>
<section id="training-loop" class="level2">
<h2 class="anchored" data-anchor-id="training-loop">Training loop</h2>
<p>The core training step can be implemented in under 10 lines of code.</p>
<p>We teach the model to predict the “common noise” <span class="math inline">\(\mathbf\epsilon\)</span> that produced the diffusion sequence, based on <span class="math inline">\(x_t\)</span> at any time <span class="math inline">\(t\)</span>. No matter where it is, the model needs to help the image get back to <span class="math inline">\(x_0\)</span>.</p>
<div id="cell-26" class="cell" data-outputid="5f8bbcb7-54a6-4bbf-ec87-362d0947b12c" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> MSELoss()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>denoising_model.train()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(denoising_model, steps<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Training on device:"</span>, device)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  max_train_steps <span class="op">=</span> steps</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  train_progress_bar <span class="op">=</span> tqdm(<span class="bu">enumerate</span>(itertools.cycle(train_dataloader)))</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  num_examples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> step, (x_0, _) <span class="kw">in</span> train_progress_bar:</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    x_0 <span class="op">=</span> x_0.to(device)  <span class="co"># x_0 is the clean data to teach the model to generate</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#######################################</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start of Core training step</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#######################################</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn(x_0.shape).to(device)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.randint(<span class="dv">0</span>, config.num_denoising_steps, (x_0.shape[<span class="dv">0</span>],), device<span class="op">=</span>device).<span class="bu">long</span>()</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    x_t, true_noise <span class="op">=</span> forward_diffusion(x_0, t, noise_schedule, noise<span class="op">=</span>noise)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    predicted_noise <span class="op">=</span> denoising_model(t<span class="op">=</span>t, x<span class="op">=</span>x_t)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(predicted_noise, true_noise)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    loss.backward()<span class="op">;</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># torch.nn.utils.clip_grad_norm_(denoising_model.parameters(), 1)  # try commenting it out</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">#######################################</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># End of Core training step</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">#######################################</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    train_progress_bar.set_postfix({<span class="st">"loss"</span>: loss.cpu().item()})</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    num_examples <span class="op">+=</span> <span class="bu">len</span>(x_0)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> step <span class="op">&gt;=</span> max_train_steps:</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f"Reached the max training steps:"</span>, max_train_steps)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="ss">f"Trained on </span><span class="sc">{</span>num_examples<span class="sc">}</span><span class="ss"> examples."</span>)</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> loss</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dd9275dd5aae4f7982343fd4459af324","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 100
Trained on 3232 examples.</code></pre>
</div>
</div>
</section>
<section id="generate" class="level2">
<h2 class="anchored" data-anchor-id="generate">Generate</h2>
<section id="the-sampling-algorithm-reversing-the-diffusion-process" class="level3">
<h3 class="anchored" data-anchor-id="the-sampling-algorithm-reversing-the-diffusion-process">The sampling algorithm: reversing the diffusion process</h3>
<p>The sampling algorithm is the reverse of the forward diffusion process. It starts from <span class="math inline">\(x_T\)</span>, a pure noise image, and iteratively denoise until reaching <span class="math inline">\(x_0\)</span>.</p>
<p>The formula for one “denoising” step is:</p>
<p><span class="math display">\[
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} (x_t - \frac{1-\alpha_t}{\sqrt{1 - \bar\alpha_t}} \mathbf\epsilon_{\theta}(\mathbf{x_t}, t)) + \sqrt{\tilde\beta_t} \mathbf z_t \tag{1}
\]</span></p>
<p>where <span class="math inline">\(z_t ~ \mathcal{N}(0, 1)\)</span> is Gaussian noise (independent from <span class="math inline">\(\mathbf\epsilon\)</span>) that is sampled at each denoising step, and <span class="math inline">\(\tilde\beta_t = \frac{1 - \bar\alpha_{t-1}}{1 - \bar\alpha_t} \beta_t\)</span> is the variance of the noise at time <span class="math inline">\(t\)</span>.</p>
</section>
<section id="the-clamping" class="level3">
<h3 class="anchored" data-anchor-id="the-clamping">The clamping</h3>
<p>If you compare the <code>denoising_step</code> function below with the implementation in the 2D point cloud tutorial, you will find that the one here to be more complex. It implements the following formula:</p>
<p><span class="math display">\[
\hat x_{0} = \frac{1}{\sqrt{\bar\alpha_t}} \left(x_t - \sqrt{1-\bar\alpha_t} \cdot \mathbf\epsilon_{\theta}(\mathbf{x_t}, t)\right) \tag{2}
\]</span></p>
<p>then</p>
<p><span class="math display">\[
x_{t-1} =  \frac{\beta_t\sqrt{\bar\alpha_{t-1}}}{1-\bar\alpha_t} \cdot \textrm{Clamp}(\hat x_{0}) + \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1-\bar\alpha_t} x_t  + \sqrt{\beta_t} \mathbf z_t \tag{3}
\]</span></p>
<p>where <span class="math inline">\(\textrm{Clamp}(\hat x_{0})\)</span> is the clamping function that limits the range of the predicted image to be within <span class="math inline">\([-1, 1]\)</span>.</p>
<p>If there is no clamping, equation (1) is mathematically equivalent to equations (2) and (3) combined (derivations <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">here</a>). However, clamping is found to be necessary to generate high quality and diverse images.</p>
<p>To see its effect, the more direct implementation <code>denoising_step_direct()</code> is also included for comparison. We will see why the new implementation with clamping is necessary.</p>
<div id="cell-29" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denoising_step(denoising_model, x_t, t, noise_schedule, thresholding<span class="op">=</span><span class="va">False</span>, clip_sample<span class="op">=</span><span class="va">True</span>, clip_sample_range<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the backward diffusion step, with the effect of denoising.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(t, <span class="bu">int</span>):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> torch.full((x_t.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>x_t.device)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> t</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> denoising_model(t<span class="op">=</span>t_tensor, x<span class="op">=</span>x_t)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(model_output, <span class="st">"sample"</span>):</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> model_output.sample</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract relevant values from noise_schedule</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor]</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># deal with t=0 case where t can be a tensor</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t_prev <span class="op">=</span> torch.where(t_tensor <span class="op">&gt;</span> <span class="dv">0</span>,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>                                    noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor <span class="op">-</span> <span class="dv">1</span>],</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>                                    torch.ones_like(t_tensor, device<span class="op">=</span>x_t.device))</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape alpha_prod_t_prev for proper broadcasting</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t <span class="op">=</span> alpha_prod_t.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    alpha_prod_t_prev <span class="op">=</span> alpha_prod_t_prev.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    beta_prod_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_prod_t</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    beta_prod_t_prev <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_prod_t_prev</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    current_alpha_t <span class="op">=</span> alpha_prod_t <span class="op">/</span> alpha_prod_t_prev</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    current_beta_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> current_alpha_t</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the previous sample mean</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    pred_original_sample <span class="op">=</span> (x_t <span class="op">-</span> beta_prod_t <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> model_output) <span class="op">/</span> alpha_prod_t <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clip_sample:</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>        pred_original_sample <span class="op">=</span> torch.clamp(pred_original_sample, <span class="op">-</span>clip_sample_range, clip_sample_range)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the coefficients for pred_original_sample and current sample</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>    pred_original_sample_coeff <span class="op">=</span> (alpha_prod_t_prev <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> current_beta_t) <span class="op">/</span> beta_prod_t</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    current_sample_coeff <span class="op">=</span> current_alpha_t <span class="op">**</span> <span class="fl">0.5</span> <span class="op">*</span> beta_prod_t_prev <span class="op">/</span> beta_prod_t</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the previous sample</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> pred_original_sample_coeff <span class="op">*</span> pred_original_sample <span class="op">+</span> current_sample_coeff <span class="op">*</span> x_t</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add noise</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.zeros_like(x_t)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    variance_noise <span class="op">=</span> torch.randn_like(x_t)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle t=0 case where t can be a tensor</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>    non_zero_mask <span class="op">=</span> (t_tensor <span class="op">!=</span> <span class="dv">0</span>).<span class="bu">float</span>().view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> non_zero_mask <span class="op">*</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_prod_t_prev) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_prod_t) <span class="op">*</span> current_beta_t)</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.clamp(variance, <span class="bu">min</span><span class="op">=</span><span class="fl">1e-20</span>)</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> pred_prev_sample <span class="op">+</span> (variance <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> variance_noise</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_prev_sample</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> denoising_step_direct(</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>    denoising_model,</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>    x_t,</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>    t,</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>    noise_schedule,</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>    clip_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>    clip_sample_range<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the backward diffusion step, with the effect of denoising.</span></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(t, <span class="bu">int</span>):</span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> torch.full((x_t.shape[<span class="dv">0</span>],), t, device<span class="op">=</span>x_t.device)</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>        t_tensor <span class="op">=</span> t</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>        eps_theta <span class="op">=</span> denoising_model(t<span class="op">=</span>t_tensor, x<span class="op">=</span>x_t)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(eps_theta, <span class="st">"sample"</span>):</span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>        eps_theta <span class="op">=</span> eps_theta.sample</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract alphas from noise schedule</span></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>    alpha_t <span class="op">=</span> noise_schedule[<span class="st">"alphas"</span>][t_tensor]</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a>    alpha_t_cumprod <span class="op">=</span> noise_schedule[<span class="st">"alphas_cumprod"</span>][t_tensor]</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reshape for broadcasting</span></span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a>    view_shape <span class="op">=</span> (<span class="op">-</span><span class="dv">1</span>,) <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">*</span> (x_t.ndim <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a>    alpha_t <span class="op">=</span> alpha_t.view(<span class="op">*</span>view_shape)</span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a>    alpha_t_cumprod <span class="op">=</span> alpha_t_cumprod.view(<span class="op">*</span>view_shape)</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate epsilon factor</span></span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a>    eps_factor <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod).sqrt()</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate mean for reverse process</span></span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> torch.sqrt(alpha_t)) <span class="op">*</span> (x_t <span class="op">-</span> eps_factor <span class="op">*</span> eps_theta)</span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add noise scaled by variance for non-zero timesteps</span></span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a>    noise <span class="op">=</span> torch.randn_like(x_t)</span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a>    beta_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> alpha_t</span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> beta_t <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod <span class="op">/</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_t_cumprod)</span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a>    variance <span class="op">=</span> torch.clamp(variance, <span class="bu">min</span><span class="op">=</span><span class="fl">1e-20</span>)  <span class="co"># Add clamp to prevent numerical instability</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mask out noise for t=0 timesteps</span></span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a>    non_zero_mask <span class="op">=</span> (t_tensor <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">float</span>().view(<span class="op">*</span>view_shape)</span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a>    noise_scale <span class="op">=</span> torch.sqrt(variance) <span class="op">*</span> non_zero_mask</span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a>    pred_prev_sample <span class="op">=</span> mean <span class="op">+</span> noise_scale <span class="op">*</span> noise</span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply clipping</span></span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> clip_sample:</span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a>        pred_prev_sample <span class="op">=</span> torch.clamp(pred_prev_sample, <span class="op">-</span>clip_sample_range, clip_sample_range)</span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pred_prev_sample</span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_samples_by_denoising(denoising_model, x_T, noise_schedule, n_T, device, thresholding<span class="op">=</span><span class="va">False</span>, clip_sample<span class="op">=</span><span class="va">True</span>, clip_sample_range<span class="op">=</span><span class="fl">1.0</span>, seed<span class="op">=</span><span class="dv">0</span>, method<span class="op">=</span><span class="st">"direct"</span>):</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a><span class="co">    This is the generation process.</span></span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> x_T.to(device)</span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a>    pbar <span class="op">=</span> tqdm(<span class="bu">range</span>(n_T <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> pbar:</span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> method <span class="op">==</span> <span class="st">"direct"</span>:</span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> denoising_step_direct(denoising_model, x_t, t, noise_schedule, clip_sample, clip_sample_range)</span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> denoising_step(denoising_model, x_t, t, noise_schedule, thresholding, clip_sample, clip_sample_range)</span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a>        pbar.set_postfix({<span class="st">"std"</span>: x_t.std().item()})</span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print("raw x_t range", x_t.min(), x_t.max())</span></span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (x_t <span class="op">/</span> <span class="dv">2</span> <span class="op">+</span> <span class="fl">0.5</span>).clamp(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print("after clamp", x_t.min(), x_t.max())</span></span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualize-sampled-images" class="level3">
<h3 class="anchored" data-anchor-id="visualize-sampled-images">Visualize sampled images</h3>
<div id="cell-31" class="cell" data-outputid="f8ea9e82-8f96-4cbf-8111-d3523a03523c" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the sampled images</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_sampled_images(method<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Loss of the denoising model:"</span>, loss.item())</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  x_T <span class="op">=</span> torch.randn(<span class="dv">16</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  x_sampled <span class="op">=</span> generate_samples_by_denoising(</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    denoising_model, x_T,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    noise_schedule, n_T<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    clip_sample<span class="op">=</span><span class="va">False</span> <span class="cf">if</span> method <span class="op">==</span> <span class="st">"direct"</span> <span class="cf">else</span> <span class="va">True</span>,</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    clip_sample_range<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span>method,</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  x_sampled <span class="op">=</span> x_sampled <span class="op">*</span> <span class="dv">255</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  sampled <span class="op">=</span> make_grid(x_sampled).permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).cpu().numpy().astype(np.uint8)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>  _ <span class="op">=</span> plt.imshow(sampled)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images(method<span class="op">=</span><span class="st">"direct"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.03703206777572632</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"775a6582fb41463eaa2e52b36b5e1dd8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-16-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-32" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.03703206777572632</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8c007b072c2a49b282cf0e3fc21a372c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-17-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-some-more" class="level3">
<h3 class="anchored" data-anchor-id="train-some-more">Train some more</h3>
<div id="cell-34" class="cell" data-outputid="f75a00c2-d5b8-40b8-cb76-f9ee9b153ff5" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train some more</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"34627135a3bf49f78d2829816e11c94b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 1000
Trained on 31998 examples.
loss: 0.028952330350875854</code></pre>
</div>
</div>
<div id="cell-35" class="cell" data-outputid="3fddfdf4-d80e-47f2-f4f9-2b8a515abe0f" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.028952330350875854</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e6d0eaf4c88b48908d473a86d43e8ef7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-19-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-36" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images(method<span class="op">=</span><span class="st">"direct"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss of the denoising model: 0.028952330350875854</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b6de59aa86f4433e877a7b99dcee10f5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-20-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-even-more" class="level3">
<h3 class="anchored" data-anchor-id="train-even-more">Train even more</h3>
<div id="cell-38" class="cell" data-outputid="4afee568-bdf9-430b-876e-1f2816e6e175" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> g <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    g[<span class="st">'lr'</span>] <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># reduce learning rate</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e3010dbc987d4de5bb1eef850f93c479","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
<section id="and-some-more" class="level3">
<h3 class="anchored" data-anchor-id="and-some-more">And, some more</h3>
<div id="cell-40" class="cell" data-outputid="d56c68d0-5586-4248-925f-0ae73056a1c6" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> g <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    g[<span class="st">'lr'</span>] <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># reduce learning rate</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5f39663da88c462b8306846b6b24f97e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Reached the max training steps: 10000
Trained on 319624 examples.
loss: 0.028765305876731873
Loss of the denoising model: 0.028765305876731873</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7a002b34284a407aa02734178c3c86fc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2_1_nano_diffusion_afhq_files/figure-html/cell-22-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-41" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> train(denoising_model, steps<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss:"</span>, loss.item())</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>visualize_sampled_images()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device: cuda</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e25a32e39bbc4ed4b88862c48ed44ea5","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"04a04e7642904704b091d55b75d7aafd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0511c75b13b24ac7a9b176df52129e07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"069b694b86394acf8f5faa461f5d3eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e4f9b259304302a261ec8764b3d72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c20bd7c5c644c3bce5ab928b8284be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"091762633712423c926d31d7420062fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a82f38232c74ae6beac08d705fbc240":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aec62e3c4544731a2780b65b62eb6a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_908d7b9ff8644df49b1c83ddb38f1e0f","placeholder":"​","style":"IPY_MODEL_0511c75b13b24ac7a9b176df52129e07","value":"100%"}},"0b984917930e4d2daa81be08ae4cb2e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bbd14d99c284ede80ec348ac6519076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ee3ed4db32b4e74aa27acd5c2cd506b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9df5ad68439e4a92994930f97f06463e","IPY_MODEL_eee89f8f48a54ac9b63df22a6036a3d3","IPY_MODEL_a1f2dd797f794d11b84b0b0faa73691e"],"layout":"IPY_MODEL_57b52910b9d84771b222292f22fb4c03"}},"116406195ae54436915610c992c7712d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11870333ac534f1bb948245b79f8ca5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11c93b786744467c9183fa4015cd6b76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4733482262f54e9ea9ed76fdb69bbaaa","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7e73e4ec0634cdfa66f0f6384896dc9","value":59}},"1325b49fca594dd0aa72c4917d044169":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_690142ae1d46418d854eaccd264f5a33","placeholder":"​","style":"IPY_MODEL_23a873f27f2b4fd3a754e621d88e0df1","value":""}},"15ddabb80b9d4d68a33cbf6eeb79f023":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bbdacaa845640118be28a222b614516":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a82f38232c74ae6beac08d705fbc240","placeholder":"​","style":"IPY_MODEL_37abc2a8c024497c833008eb0f4acdc5","value":" 59/1000 [00:02&lt;00:36, 25.48it/s, std=1]"}},"1d30484bd7af40d1bc9ef7f051a02aa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20af142079dd46348636f8be335bda81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23a873f27f2b4fd3a754e621d88e0df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24093408e2a14c3689c3a56c49b59eb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e4f9b259304302a261ec8764b3d72f","max":14630,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80927e843a5f4d8eb0ff014ecf79a16a","value":14630}},"2ce0dd3a7e704df8aa445338692f7820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31523e4acffc43379b965dd0729214cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"316b576e5513417c81d3bfde019cd94e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"323b40ae734847a5971df00030ffd202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aec62e3c4544731a2780b65b62eb6a9","IPY_MODEL_3efdd710357f4f1cb1c358e99dd99174","IPY_MODEL_3b136b9006674cffab93827f3ecf557e"],"layout":"IPY_MODEL_ec12eaff03404f5cb73019d439965362"}},"3358ed77dfe546ddaa66d33610c33b08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34019b31860f45f0920b74dd89dd3c9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3416498c265f4ab78d6c3afb3d34b208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_316b576e5513417c81d3bfde019cd94e","max":132588555,"min":0,"orientation":"horizontal","style":"IPY_MODEL_069b694b86394acf8f5faa461f5d3eb3","value":132588555}},"343c20931eed45078341f21e44bd8bed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3737b6c5fe7446ff9e79229cf7d1d6ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37abc2a8c024497c833008eb0f4acdc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"393703bd8fae4e02ac59936da8c9f59a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f41ba828156b41ba9b690c9e0bdbdea5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11870333ac534f1bb948245b79f8ca5c","value":1}},"3b136b9006674cffab93827f3ecf557e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70e3117594b4c6996897f5462383f3e","placeholder":"​","style":"IPY_MODEL_9849b3fe0b3c4e2baea1ce9791e5b63e","value":" 1000/1000 [00:48&lt;00:00, 18.41it/s, std=0.609]"}},"3b4dd3210aad4d1287329ca73acb3449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bef7665c9b14315b1479d605a7a9405":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c86d50c98ec4c6a92643a149b01ba0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e516edb99c048f696e08da2dfcc33ae","IPY_MODEL_efe15d8882b24e26981d9d88c94ce8a8","IPY_MODEL_ab6772c5f7794878bbb64306bc5af972"],"layout":"IPY_MODEL_8a69d7b1495a48a19dc9265de769af55"}},"3efdd710357f4f1cb1c358e99dd99174":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6828a915ee024b4e9619d97a73e0d53f","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20af142079dd46348636f8be335bda81","value":1000}},"45342bb8953d47a0941854fee6c23e4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46bd73d21fe04d85ac79b050efa2d348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4733482262f54e9ea9ed76fdb69bbaaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c7cc54c13144b61a137b2fa5b7434d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e516edb99c048f696e08da2dfcc33ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c6c547266245fda3b1443a18d9e960","placeholder":"​","style":"IPY_MODEL_31523e4acffc43379b965dd0729214cd","value":""}},"4eaed03beec6446e846a9ad191830ca7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a2df1e6ed940d5a7c48c4ed5077db4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c484507dbc16429f83191e2be1b77661","placeholder":"​","style":"IPY_MODEL_f0dbfe3d51f2453ca1cb4f8a83cd5ffd","value":" 100/? [00:20&lt;00:00,  5.77it/s, loss=0.0568]"}},"562e474564da4b1db302c573d86c5fc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"565489b7024045509b4f486228cbd812":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bac04a877244a5d9519b140560bbf46","placeholder":"​","style":"IPY_MODEL_2ce0dd3a7e704df8aa445338692f7820","value":"100%"}},"56b38e69c8984055909d72c8a112c495":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57b52910b9d84771b222292f22fb4c03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0d375601a14304baa35d08417e3d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf73b2b41d2e42cc8ad643c098de7b69","placeholder":"​","style":"IPY_MODEL_116406195ae54436915610c992c7712d","value":" 133M/133M [00:03&lt;00:00, 34.6MB/s]"}},"61d62a2ec60540969d2886143cbb5fb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6828a915ee024b4e9619d97a73e0d53f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"690142ae1d46418d854eaccd264f5a33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a5b3a68e9a441eafe984c868c994c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6bb12cdbe443b297cebc5c57b1d201":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cf20fee33b4fe4a3a13e18603923b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72105bbb98e94c529a92dd011395280a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"737f98f221974116917e83b8cbd6572f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c6c547266245fda3b1443a18d9e960":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab713c7e9344187bce06333a64a07b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9f4b079e2da49b2aa78eb827e97f17c","IPY_MODEL_f928cef14c724f1789733adbed20d7c7","IPY_MODEL_8ef5f869de0f43aaaf93eaebc6c2fc49"],"layout":"IPY_MODEL_f092fe6dd2234ff5ae9fd223087527c7"}},"7e3ef051d0884e5e9c31bf9af1285821":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec7943f2d6643f381405238b6a4d58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdfd015b50e8478db40df871a0e0760c","IPY_MODEL_ce6495b96c3541a0ae05c841ccfea5a2","IPY_MODEL_ee14c532db5946abb5b6bd8503c0987d"],"layout":"IPY_MODEL_34019b31860f45f0920b74dd89dd3c9f"}},"80927e843a5f4d8eb0ff014ecf79a16a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80935dc3f8844f0f92531b35d8274e0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836db012c54f4d1887d1ac5635b0bacf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1325b49fca594dd0aa72c4917d044169","IPY_MODEL_393703bd8fae4e02ac59936da8c9f59a","IPY_MODEL_55a2df1e6ed940d5a7c48c4ed5077db4"],"layout":"IPY_MODEL_a83ea576587e4be1b7188369f752e3a3"}},"83c9d9265843416d82e4c34afcde5f06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a69d7b1495a48a19dc9265de769af55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d19dac1130246eeb986253e30b29858":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8ef5f869de0f43aaaf93eaebc6c2fc49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7be0ede49164f8cb11494903dadc7ae","placeholder":"​","style":"IPY_MODEL_d545ee3a9e224b7fb8f3166dc2da9788","value":" 412/? [01:27&lt;00:00,  5.34it/s, loss=0.0537]"}},"908d7b9ff8644df49b1c83ddb38f1e0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911ad5c90fc84b9db9a6035ac22038aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94871be2b0af463c8d2d29e3eb11ab47","IPY_MODEL_11c93b786744467c9183fa4015cd6b76","IPY_MODEL_1bbdacaa845640118be28a222b614516"],"layout":"IPY_MODEL_6e6bb12cdbe443b297cebc5c57b1d201"}},"91566e775ba041e08bfdc9bf9bf9021b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3358ed77dfe546ddaa66d33610c33b08","max":13592289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c7cc54c13144b61a137b2fa5b7434d9","value":13592289}},"93d8b02d0438451f93d5d3285c042edf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94871be2b0af463c8d2d29e3eb11ab47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bef7665c9b14315b1479d605a7a9405","placeholder":"​","style":"IPY_MODEL_61d62a2ec60540969d2886143cbb5fb4","value":"  6%"}},"9636f001e46d44698f6b05b06a11aac2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97253397598a4ff88b3aea250f4ce488":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3d274cb6ca747aebe9b13d23f733456","placeholder":"​","style":"IPY_MODEL_3737b6c5fe7446ff9e79229cf7d1d6ab","value":" 14630/14630 [00:00&lt;00:00, 18920.39 examples/s]"}},"9849b3fe0b3c4e2baea1ce9791e5b63e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bac04a877244a5d9519b140560bbf46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df5ad68439e4a92994930f97f06463e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e540d95436da46db961958b2f95e470c","placeholder":"​","style":"IPY_MODEL_0b984917930e4d2daa81be08ae4cb2e3","value":"Generating val split: 100%"}},"a14abff04e6748f9abfaac60ba80491a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_565489b7024045509b4f486228cbd812","IPY_MODEL_d562f66e77a04fd0a21ec627ef4e836e","IPY_MODEL_b215ab2b7dc547c18243460f6bd03307"],"layout":"IPY_MODEL_d4dfc8e846764ff19157516af2efbbd6"}},"a1f2dd797f794d11b84b0b0faa73691e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc4b4c2d5f6474b82c0aa525da80963","placeholder":"​","style":"IPY_MODEL_80935dc3f8844f0f92531b35d8274e0e","value":" 1500/1500 [00:00&lt;00:00, 12587.71 examples/s]"}},"a83ea576587e4be1b7188369f752e3a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6772c5f7794878bbb64306bc5af972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_091762633712423c926d31d7420062fb","placeholder":"​","style":"IPY_MODEL_3b4dd3210aad4d1287329ca73acb3449","value":" 412/? [01:18&lt;00:00,  6.69it/s, loss=0.044]"}},"b03e0fb1e87b4f4da5fb310165796af2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b075ace4d49b412daa113baefb97e239":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b113bc4e41a24547ba07dbf8572e59d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e39266507dcd40ef97bcef22fae30c35","IPY_MODEL_91566e775ba041e08bfdc9bf9bf9021b","IPY_MODEL_b128b30c717047e9bf38c24a0262641c"],"layout":"IPY_MODEL_4eaed03beec6446e846a9ad191830ca7"}},"b128b30c717047e9bf38c24a0262641c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_343c20931eed45078341f21e44bd8bed","placeholder":"​","style":"IPY_MODEL_04a04e7642904704b091d55b75d7aafd","value":" 13.6M/13.6M [00:00&lt;00:00, 42.1MB/s]"}},"b215ab2b7dc547c18243460f6bd03307":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e3ef051d0884e5e9c31bf9af1285821","placeholder":"​","style":"IPY_MODEL_b8e58ba8119f4dbd8e692dc282721706","value":" 1000/1000 [00:42&lt;00:00, 22.90it/s, std=0.361]"}},"b2505de75cd7482c92889f8f5f8b77de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5341358005b4feab7743c3a31c83c13","placeholder":"​","style":"IPY_MODEL_fa5abb0d23ca4a0c907f11127603ef03","value":"train-00000-of-00001.parquet: 100%"}},"b8e58ba8119f4dbd8e692dc282721706":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f4b079e2da49b2aa78eb827e97f17c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_737f98f221974116917e83b8cbd6572f","placeholder":"​","style":"IPY_MODEL_dd7c2aea9730499ba392af981b35a13c","value":""}},"bcc4b4c2d5f6474b82c0aa525da80963":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf73b2b41d2e42cc8ad643c098de7b69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d274cb6ca747aebe9b13d23f733456":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c484507dbc16429f83191e2be1b77661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c94a6ad8365d4bdab01059e8a807129d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc739e8196da4fa78d6510461487947e","IPY_MODEL_24093408e2a14c3689c3a56c49b59eb1","IPY_MODEL_97253397598a4ff88b3aea250f4ce488"],"layout":"IPY_MODEL_9636f001e46d44698f6b05b06a11aac2"}},"ce6495b96c3541a0ae05c841ccfea5a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54e6d1e22c24345b67b0f88e2e0f3e9","max":646,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83c9d9265843416d82e4c34afcde5f06","value":646}},"d4dfc8e846764ff19157516af2efbbd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d545ee3a9e224b7fb8f3166dc2da9788":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d562f66e77a04fd0a21ec627ef4e836e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f4c2d247d14135ade949074143a5bf","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93d8b02d0438451f93d5d3285c042edf","value":1000}},"d70e3117594b4c6996897f5462383f3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93e07d9cd22454e9551d8b069bbd1ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc0be83354814b1fb516faef5de175e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2505de75cd7482c92889f8f5f8b77de","IPY_MODEL_3416498c265f4ab78d6c3afb3d34b208","IPY_MODEL_5a0d375601a14304baa35d08417e3d64"],"layout":"IPY_MODEL_69a5b3a68e9a441eafe984c868c994c8"}},"dc739e8196da4fa78d6510461487947e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b075ace4d49b412daa113baefb97e239","placeholder":"​","style":"IPY_MODEL_46bd73d21fe04d85ac79b050efa2d348","value":"Generating train split: 100%"}},"dd7c2aea9730499ba392af981b35a13c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e39266507dcd40ef97bcef22fae30c35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b03e0fb1e87b4f4da5fb310165796af2","placeholder":"​","style":"IPY_MODEL_56b38e69c8984055909d72c8a112c495","value":"val-00000-of-00001.parquet: 100%"}},"e5341358005b4feab7743c3a31c83c13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e540d95436da46db961958b2f95e470c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7be0ede49164f8cb11494903dadc7ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec12eaff03404f5cb73019d439965362":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee14c532db5946abb5b6bd8503c0987d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c20bd7c5c644c3bce5ab928b8284be","placeholder":"​","style":"IPY_MODEL_d93e07d9cd22454e9551d8b069bbd1ee","value":" 646/646 [00:00&lt;00:00, 17.5kB/s]"}},"eee89f8f48a54ac9b63df22a6036a3d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d30484bd7af40d1bc9ef7f051a02aa9","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_562e474564da4b1db302c573d86c5fc3","value":1500}},"efe15d8882b24e26981d9d88c94ce8a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72105bbb98e94c529a92dd011395280a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15ddabb80b9d4d68a33cbf6eeb79f023","value":1}},"f092fe6dd2234ff5ae9fd223087527c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0dbfe3d51f2453ca1cb4f8a83cd5ffd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f41ba828156b41ba9b690c9e0bdbdea5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f54e6d1e22c24345b67b0f88e2e0f3e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e73e4ec0634cdfa66f0f6384896dc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8f4c2d247d14135ade949074143a5bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f928cef14c724f1789733adbed20d7c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d19dac1130246eeb986253e30b29858","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bbd14d99c284ede80ec348ac6519076","value":1}},"fa5abb0d23ca4a0c907f11127603ef03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdfd015b50e8478db40df871a0e0760c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45342bb8953d47a0941854fee6c23e4c","placeholder":"​","style":"IPY_MODEL_71cf20fee33b4fe4a3a13e18603923b7","value":"README.md: 100%"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kungfuai\.github\.io\/nano-diffusion\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>